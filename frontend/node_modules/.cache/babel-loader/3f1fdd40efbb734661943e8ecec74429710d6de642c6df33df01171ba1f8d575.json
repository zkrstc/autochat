{"ast":null,"code":"import _defineProperty from \"C:/Users/ASUS/Desktop/autochat/frontend/node_modules/@babel/runtime/helpers/esm/defineProperty.js\";\nvar _Class3;\nimport \"core-js/modules/es.array.push.js\";\nimport \"core-js/modules/es.iterator.constructor.js\";\nimport \"core-js/modules/es.iterator.filter.js\";\nimport \"core-js/modules/es.iterator.for-each.js\";\nimport \"core-js/modules/es.iterator.map.js\";\nimport \"core-js/modules/es.iterator.some.js\";\nimport \"core-js/modules/es.set.difference.v2.js\";\nimport \"core-js/modules/es.set.intersection.v2.js\";\nimport \"core-js/modules/es.set.is-disjoint-from.v2.js\";\nimport \"core-js/modules/es.set.is-subset-of.v2.js\";\nimport \"core-js/modules/es.set.is-superset-of.v2.js\";\nimport \"core-js/modules/es.set.symmetric-difference.v2.js\";\nimport \"core-js/modules/es.set.union.v2.js\";\n/**\n * marked v15.0.12 - a markdown parser\n * Copyright (c) 2011-2025, Christopher Jeffrey. (MIT Licensed)\n * https://github.com/markedjs/marked\n */\n\n/**\n * DO NOT EDIT THIS FILE\n * The code in this file is generated from files in ./src/\n */\n\n// src/defaults.ts\nfunction _getDefaults() {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null\n  };\n}\nvar _defaults = _getDefaults();\nfunction changeDefaults(newDefaults) {\n  _defaults = newDefaults;\n}\n\n// src/rules.ts\nvar noopTest = {\n  exec: () => null\n};\nfunction edit(regex, opt = \"\") {\n  let source = typeof regex === \"string\" ? regex : regex.source;\n  const obj = {\n    replace: (name, val) => {\n      let valSource = typeof val === \"string\" ? val : val.source;\n      valSource = valSource.replace(other.caret, \"$1\");\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    }\n  };\n  return obj;\n}\nvar other = {\n  codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n  outputLinkReplace: /\\\\([\\[\\]])/g,\n  indentCodeCompensation: /^(\\s+)(?:```)/,\n  beginningSpace: /^\\s+/,\n  endingHash: /#$/,\n  startingSpaceChar: /^ /,\n  endingSpaceChar: / $/,\n  nonSpaceChar: /[^ ]/,\n  newLineCharGlobal: /\\n/g,\n  tabCharGlobal: /\\t/g,\n  multipleSpaceGlobal: /\\s+/g,\n  blankLine: /^[ \\t]*$/,\n  doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n  blockquoteStart: /^ {0,3}>/,\n  blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n  blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n  listReplaceTabs: /^\\t+/,\n  listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n  listIsTask: /^\\[[ xX]\\] /,\n  listReplaceTask: /^\\[[ xX]\\] +/,\n  anyLine: /\\n.*\\n/,\n  hrefBrackets: /^<(.*)>$/,\n  tableDelimiter: /[:|]/,\n  tableAlignChars: /^\\||\\| *$/g,\n  tableRowBlankLine: /\\n[ \\t]*$/,\n  tableAlignRight: /^ *-+: *$/,\n  tableAlignCenter: /^ *:-+: *$/,\n  tableAlignLeft: /^ *:-+ *$/,\n  startATag: /^<a /i,\n  endATag: /^<\\/a>/i,\n  startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n  endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n  startAngleBracket: /^</,\n  endAngleBracket: />$/,\n  pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n  unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n  escapeTest: /[&<>\"']/,\n  escapeReplace: /[&<>\"']/g,\n  escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n  escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n  unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n  caret: /(^|[^\\[])\\^/g,\n  percentDecode: /%25/g,\n  findPipe: /\\|/g,\n  splitPipe: / \\|/,\n  slashPipe: /\\\\\\|/g,\n  carriageReturn: /\\r\\n|\\r/g,\n  spaceLine: /^ +$/gm,\n  notSpaceStart: /^\\S*/,\n  endingNewline: /\\n$/,\n  listItemRegex: bull => new RegExp(`^( {0,3}${bull})((?:[\t ][^\\\\n]*)?(?:\\\\n|$))`),\n  nextBulletRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \t][^\\\\n]*)?(?:\\\\n|$))`),\n  hrRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n  fencesBeginRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`),\n  headingBeginRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`),\n  htmlBeginRegex: indent => new RegExp(`^ {0,${Math.min(3, indent - 1)}}<(?:[a-z].*>|!--)`, \"i\")\n};\nvar newline = /^(?:[ \\t]*(?:\\n|$))+/;\nvar blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nvar fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nvar hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nvar heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nvar bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nvar lheadingCore = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/;\nvar lheading = edit(lheadingCore).replace(/bull/g, bullet).replace(/blockCode/g, /(?: {4}| {0,3}\\t)/).replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g, / {0,3}>/).replace(/heading/g, / {0,3}#{1,6}/).replace(/html/g, / {0,3}<[^\\n>]+>\\n/).replace(/\\|table/g, \"\").getRegex();\nvar lheadingGfm = edit(lheadingCore).replace(/bull/g, bullet).replace(/blockCode/g, /(?: {4}| {0,3}\\t)/).replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/).replace(/blockquote/g, / {0,3}>/).replace(/heading/g, / {0,3}#{1,6}/).replace(/html/g, / {0,3}<[^\\n>]+>\\n/).replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/).getRegex();\nvar _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nvar blockText = /^[^\\n]+/;\nvar _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nvar def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/).replace(\"label\", _blockLabel).replace(\"title\", /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/).getRegex();\nvar list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/).replace(/bull/g, bullet).getRegex();\nvar _tag = \"address|article|aside|base|basefont|blockquote|body|caption|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title|tr|track|ul\";\nvar _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nvar html = edit(\"^ {0,3}(?:<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)|comment[^\\\\n]*(\\\\n+|$)|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$)|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \t]*)+\\\\n|$))\", \"i\").replace(\"comment\", _comment).replace(\"tag\", _tag).replace(\"attribute\", / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/).getRegex();\nvar paragraph = edit(_paragraph).replace(\"hr\", hr).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\", \"\").replace(\"|table\", \"\").replace(\"blockquote\", \" {0,3}>\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", _tag).getRegex();\nvar blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/).replace(\"paragraph\", paragraph).getRegex();\nvar blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText\n};\nvar gfmTable = edit(\"^ *([^\\\\n ].*)\\\\n {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)\").replace(\"hr\", hr).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"blockquote\", \" {0,3}>\").replace(\"code\", \"(?: {4}| {0,3}\t)[^\\\\n]\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", _tag).getRegex();\nvar blockGfm = {\n  ...blockNormal,\n  lheading: lheadingGfm,\n  table: gfmTable,\n  paragraph: edit(_paragraph).replace(\"hr\", hr).replace(\"heading\", \" {0,3}#{1,6}(?:\\\\s|$)\").replace(\"|lheading\", \"\").replace(\"table\", gfmTable).replace(\"blockquote\", \" {0,3}>\").replace(\"fences\", \" {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n\").replace(\"list\", \" {0,3}(?:[*+-]|1[.)]) \").replace(\"html\", \"</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)\").replace(\"tag\", _tag).getRegex()\n};\nvar blockPedantic = {\n  ...blockNormal,\n  html: edit(`^ *(?:comment *(?:\\\\n|\\\\s*$)|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)|<tag(?:\"[^\"]*\"|'[^']*'|\\\\s[^'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))`).replace(\"comment\", _comment).replace(/tag/g, \"(?!(?:a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b\").getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest,\n  // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph).replace(\"hr\", hr).replace(\"heading\", \" *#{1,6} *[^\\n]\").replace(\"lheading\", lheading).replace(\"|table\", \"\").replace(\"blockquote\", \" {0,3}>\").replace(\"|fences\", \"\").replace(\"|list\", \"\").replace(\"|html\", \"\").replace(\"|tag\", \"\").getRegex()\n};\nvar escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nvar inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nvar br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nvar inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\nvar _punctuation = /[\\p{P}\\p{S}]/u;\nvar _punctuationOrSpace = /[\\s\\p{P}\\p{S}]/u;\nvar _notPunctuationOrSpace = /[^\\s\\p{P}\\p{S}]/u;\nvar punctuation = edit(/^((?![*_])punctSpace)/, \"u\").replace(/punctSpace/g, _punctuationOrSpace).getRegex();\nvar _punctuationGfmStrongEm = /(?!~)[\\p{P}\\p{S}]/u;\nvar _punctuationOrSpaceGfmStrongEm = /(?!~)[\\s\\p{P}\\p{S}]/u;\nvar _notPunctuationOrSpaceGfmStrongEm = /(?:[^\\s\\p{P}\\p{S}]|~)/u;\nvar blockSkip = /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\nvar emStrongLDelimCore = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/;\nvar emStrongLDelim = edit(emStrongLDelimCore, \"u\").replace(/punct/g, _punctuation).getRegex();\nvar emStrongLDelimGfm = edit(emStrongLDelimCore, \"u\").replace(/punct/g, _punctuationGfmStrongEm).getRegex();\nvar emStrongRDelimAstCore = \"^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)|[^*]+(?=[^*])|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)|notPunctSpace(\\\\*+)(?=notPunctSpace)\";\nvar emStrongRDelimAst = edit(emStrongRDelimAstCore, \"gu\").replace(/notPunctSpace/g, _notPunctuationOrSpace).replace(/punctSpace/g, _punctuationOrSpace).replace(/punct/g, _punctuation).getRegex();\nvar emStrongRDelimAstGfm = edit(emStrongRDelimAstCore, \"gu\").replace(/notPunctSpace/g, _notPunctuationOrSpaceGfmStrongEm).replace(/punctSpace/g, _punctuationOrSpaceGfmStrongEm).replace(/punct/g, _punctuationGfmStrongEm).getRegex();\nvar emStrongRDelimUnd = edit(\"^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)|[^_]+(?=[^_])|(?!_)punct(_+)(?=[\\\\s]|$)|notPunctSpace(_+)(?!_)(?=punctSpace|$)|(?!_)punctSpace(_+)(?=notPunctSpace)|[\\\\s](_+)(?!_)(?=punct)|(?!_)punct(_+)(?!_)(?=punct)\", \"gu\").replace(/notPunctSpace/g, _notPunctuationOrSpace).replace(/punctSpace/g, _punctuationOrSpace).replace(/punct/g, _punctuation).getRegex();\nvar anyPunctuation = edit(/\\\\(punct)/, \"gu\").replace(/punct/g, _punctuation).getRegex();\nvar autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/).replace(\"scheme\", /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/).replace(\"email\", /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/).getRegex();\nvar _inlineComment = edit(_comment).replace(\"(?:-->|$)\", \"-->\").getRegex();\nvar tag = edit(\"^comment|^</[a-zA-Z][\\\\w:-]*\\\\s*>|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>|^<\\\\?[\\\\s\\\\S]*?\\\\?>|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>\").replace(\"comment\", _inlineComment).replace(\"attribute\", /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/).getRegex();\nvar _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\nvar link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/).replace(\"label\", _inlineLabel).replace(\"href\", /<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/).replace(\"title\", /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/).getRegex();\nvar reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/).replace(\"label\", _inlineLabel).replace(\"ref\", _blockLabel).getRegex();\nvar nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/).replace(\"ref\", _blockLabel).getRegex();\nvar reflinkSearch = edit(\"reflink|nolink(?!\\\\()\", \"g\").replace(\"reflink\", reflink).replace(\"nolink\", nolink).getRegex();\nvar inlineNormal = {\n  _backpedal: noopTest,\n  // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest\n};\nvar inlinePedantic = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/).replace(\"label\", _inlineLabel).getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/).replace(\"label\", _inlineLabel).getRegex()\n};\nvar inlineGfm = {\n  ...inlineNormal,\n  emStrongRDelimAst: emStrongRDelimAstGfm,\n  emStrongLDelim: emStrongLDelimGfm,\n  url: edit(/^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/, \"i\").replace(\"email\", /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/).getRegex(),\n  _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])((?:\\\\.|[^\\\\])*?(?:\\\\.|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/\n};\nvar inlineBreaks = {\n  ...inlineGfm,\n  br: edit(br).replace(\"{2,}\", \"*\").getRegex(),\n  text: edit(inlineGfm.text).replace(\"\\\\b_\", \"\\\\b_| {2,}\\\\n\").replace(/\\{2,\\}/g, \"*\").getRegex()\n};\nvar block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic\n};\nvar inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic\n};\n\n// src/helpers.ts\nvar escapeReplacements = {\n  \"&\": \"&amp;\",\n  \"<\": \"&lt;\",\n  \">\": \"&gt;\",\n  '\"': \"&quot;\",\n  \"'\": \"&#39;\"\n};\nvar getEscapeReplacement = ch => escapeReplacements[ch];\nfunction escape2(html2, encode) {\n  if (encode) {\n    if (other.escapeTest.test(html2)) {\n      return html2.replace(other.escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (other.escapeTestNoEncode.test(html2)) {\n      return html2.replace(other.escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n  return html2;\n}\nfunction cleanUrl(href) {\n  try {\n    href = encodeURI(href).replace(other.percentDecode, \"%\");\n  } catch {\n    return null;\n  }\n  return href;\n}\nfunction splitCells(tableRow, count) {\n  const row = tableRow.replace(other.findPipe, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === \"\\\\\") escaped = !escaped;\n      if (escaped) {\n        return \"|\";\n      } else {\n        return \" |\";\n      }\n    }),\n    cells = row.split(other.splitPipe);\n  let i = 0;\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells.at(-1)?.trim()) {\n    cells.pop();\n  }\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push(\"\");\n    }\n  }\n  for (; i < cells.length; i++) {\n    cells[i] = cells[i].trim().replace(other.slashPipe, \"|\");\n  }\n  return cells;\n}\nfunction rtrim(str, c, invert) {\n  const l = str.length;\n  if (l === 0) {\n    return \"\";\n  }\n  let suffLen = 0;\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n  return str.slice(0, l - suffLen);\n}\nfunction findClosingBracket(str, b) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === \"\\\\\") {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  if (level > 0) {\n    return -2;\n  }\n  return -1;\n}\n\n// src/Tokenizer.ts\nfunction outputLink(cap, link2, raw, lexer2, rules) {\n  const href = link2.href;\n  const title = link2.title || null;\n  const text = cap[1].replace(rules.other.outputLinkReplace, \"$1\");\n  lexer2.state.inLink = true;\n  const token = {\n    type: cap[0].charAt(0) === \"!\" ? \"image\" : \"link\",\n    raw,\n    href,\n    title,\n    text,\n    tokens: lexer2.inlineTokens(text)\n  };\n  lexer2.state.inLink = false;\n  return token;\n}\nfunction indentCodeCompensation(raw, text, rules) {\n  const matchIndentToCode = raw.match(rules.other.indentCodeCompensation);\n  if (matchIndentToCode === null) {\n    return text;\n  }\n  const indentToCode = matchIndentToCode[1];\n  return text.split(\"\\n\").map(node => {\n    const matchIndentInNode = node.match(rules.other.beginningSpace);\n    if (matchIndentInNode === null) {\n      return node;\n    }\n    const [indentInNode] = matchIndentInNode;\n    if (indentInNode.length >= indentToCode.length) {\n      return node.slice(indentToCode.length);\n    }\n    return node;\n  }).join(\"\\n\");\n}\nvar _Tokenizer = class _Tokenizer {\n  // set by the lexer\n  constructor(options2) {\n    _defineProperty(this, \"options\", void 0);\n    _defineProperty(this, \"rules\", void 0);\n    // set by the lexer\n    _defineProperty(this, \"lexer\", void 0);\n    this.options = options2 || _defaults;\n  }\n  space(src) {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: \"space\",\n        raw: cap[0]\n      };\n    }\n  }\n  code(src) {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(this.rules.other.codeRemoveIndent, \"\");\n      return {\n        type: \"code\",\n        raw: cap[0],\n        codeBlockStyle: \"indented\",\n        text: !this.options.pedantic ? rtrim(text, \"\\n\") : text\n      };\n    }\n  }\n  fences(src) {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || \"\", this.rules);\n      return {\n        type: \"code\",\n        raw,\n        lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, \"$1\") : cap[2],\n        text\n      };\n    }\n  }\n  heading(src) {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n      if (this.rules.other.endingHash.test(text)) {\n        const trimmed = rtrim(text, \"#\");\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || this.rules.other.endingSpaceChar.test(trimmed)) {\n          text = trimmed.trim();\n        }\n      }\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text)\n      };\n    }\n  }\n  hr(src) {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: \"hr\",\n        raw: rtrim(cap[0], \"\\n\")\n      };\n    }\n  }\n  blockquote(src) {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], \"\\n\").split(\"\\n\");\n      let raw = \"\";\n      let text = \"\";\n      const tokens = [];\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          if (this.rules.other.blockquoteStart.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n        const currentRaw = currentLines.join(\"\\n\");\n        const currentText = currentRaw.replace(this.rules.other.blockquoteSetextReplace, \"\\n    $1\").replace(this.rules.other.blockquoteSetextReplace2, \"\");\n        raw = raw ? `${raw}\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\n${currentText}` : currentText;\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n        if (lines.length === 0) {\n          break;\n        }\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"code\") {\n          break;\n        } else if (lastToken?.type === \"blockquote\") {\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.blockquote(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw = raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.text.length) + newToken.text;\n          break;\n        } else if (lastToken?.type === \"list\") {\n          const oldToken = lastToken;\n          const newText = oldToken.raw + \"\\n\" + lines.join(\"\\n\");\n          const newToken = this.list(newText);\n          tokens[tokens.length - 1] = newToken;\n          raw = raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText.substring(tokens.at(-1).raw.length).split(\"\\n\");\n          continue;\n        }\n      }\n      return {\n        type: \"blockquote\",\n        raw,\n        tokens,\n        text\n      };\n    }\n  }\n  list(src) {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n      const list2 = {\n        type: \"list\",\n        raw: \"\",\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : \"\",\n        loose: false,\n        items: []\n      };\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n      if (this.options.pedantic) {\n        bull = isordered ? bull : \"[*+-]\";\n      }\n      const itemRegex = this.rules.other.listItemRegex(bull);\n      let endsWithBlankLine = false;\n      while (src) {\n        let endEarly = false;\n        let raw = \"\";\n        let itemContents = \"\";\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n        if (this.rules.block.hr.test(src)) {\n          break;\n        }\n        raw = cap[0];\n        src = src.substring(raw.length);\n        let line = cap[2].split(\"\\n\", 1)[0].replace(this.rules.other.listReplaceTabs, t => \" \".repeat(3 * t.length));\n        let nextLine = src.split(\"\\n\", 1)[0];\n        let blankLine = !line.trim();\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(this.rules.other.nonSpaceChar);\n          indent = indent > 4 ? 1 : indent;\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n        if (blankLine && this.rules.other.blankLine.test(nextLine)) {\n          raw += nextLine + \"\\n\";\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n        if (!endEarly) {\n          const nextBulletRegex = this.rules.other.nextBulletRegex(indent);\n          const hrRegex = this.rules.other.hrRegex(indent);\n          const fencesBeginRegex = this.rules.other.fencesBeginRegex(indent);\n          const headingBeginRegex = this.rules.other.headingBeginRegex(indent);\n          const htmlBeginRegex = this.rules.other.htmlBeginRegex(indent);\n          while (src) {\n            const rawLine = src.split(\"\\n\", 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(this.rules.other.listReplaceNesting, \"  \");\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(this.rules.other.tabCharGlobal, \"    \");\n            }\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n            if (nextLineWithoutTabs.search(this.rules.other.nonSpaceChar) >= indent || !nextLine.trim()) {\n              itemContents += \"\\n\" + nextLineWithoutTabs.slice(indent);\n            } else {\n              if (blankLine) {\n                break;\n              }\n              if (line.replace(this.rules.other.tabCharGlobal, \"    \").search(this.rules.other.nonSpaceChar) >= 4) {\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n              itemContents += \"\\n\" + nextLine;\n            }\n            if (!blankLine && !nextLine.trim()) {\n              blankLine = true;\n            }\n            raw += rawLine + \"\\n\";\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n        if (!list2.loose) {\n          if (endsWithBlankLine) {\n            list2.loose = true;\n          } else if (this.rules.other.doubleBlankLine.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n        let istask = null;\n        let ischecked;\n        if (this.options.gfm) {\n          istask = this.rules.other.listIsTask.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== \"[ ] \";\n            itemContents = itemContents.replace(this.rules.other.listReplaceTask, \"\");\n          }\n        }\n        list2.items.push({\n          type: \"list_item\",\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: []\n        });\n        list2.raw += raw;\n      }\n      const lastItem = list2.items.at(-1);\n      if (lastItem) {\n        lastItem.raw = lastItem.raw.trimEnd();\n        lastItem.text = lastItem.text.trimEnd();\n      } else {\n        return;\n      }\n      list2.raw = list2.raw.trimEnd();\n      for (let i = 0; i < list2.items.length; i++) {\n        this.lexer.state.top = false;\n        list2.items[i].tokens = this.lexer.blockTokens(list2.items[i].text, []);\n        if (!list2.loose) {\n          const spacers = list2.items[i].tokens.filter(t => t.type === \"space\");\n          const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => this.rules.other.anyLine.test(t.raw));\n          list2.loose = hasMultipleLineBreaks;\n        }\n      }\n      if (list2.loose) {\n        for (let i = 0; i < list2.items.length; i++) {\n          list2.items[i].loose = true;\n        }\n      }\n      return list2;\n    }\n  }\n  html(src) {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token = {\n        type: \"html\",\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === \"pre\" || cap[1] === \"script\" || cap[1] === \"style\",\n        text: cap[0]\n      };\n      return token;\n    }\n  }\n  def(src) {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag2 = cap[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, \" \");\n      const href = cap[2] ? cap[2].replace(this.rules.other.hrefBrackets, \"$1\").replace(this.rules.inline.anyPunctuation, \"$1\") : \"\";\n      const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, \"$1\") : cap[3];\n      return {\n        type: \"def\",\n        tag: tag2,\n        raw: cap[0],\n        href,\n        title\n      };\n    }\n  }\n  table(src) {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n    if (!this.rules.other.tableDelimiter.test(cap[2])) {\n      return;\n    }\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(this.rules.other.tableAlignChars, \"\").split(\"|\");\n    const rows = cap[3]?.trim() ? cap[3].replace(this.rules.other.tableRowBlankLine, \"\").split(\"\\n\") : [];\n    const item = {\n      type: \"table\",\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: []\n    };\n    if (headers.length !== aligns.length) {\n      return;\n    }\n    for (const align of aligns) {\n      if (this.rules.other.tableAlignRight.test(align)) {\n        item.align.push(\"right\");\n      } else if (this.rules.other.tableAlignCenter.test(align)) {\n        item.align.push(\"center\");\n      } else if (this.rules.other.tableAlignLeft.test(align)) {\n        item.align.push(\"left\");\n      } else {\n        item.align.push(null);\n      }\n    }\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i]\n      });\n    }\n    for (const row of rows) {\n      item.rows.push(splitCells(row, item.header.length).map((cell, i) => {\n        return {\n          text: cell,\n          tokens: this.lexer.inline(cell),\n          header: false,\n          align: item.align[i]\n        };\n      }));\n    }\n    return item;\n  }\n  lheading(src) {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: \"heading\",\n        raw: cap[0],\n        depth: cap[2].charAt(0) === \"=\" ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1])\n      };\n    }\n  }\n  paragraph(src) {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text = cap[1].charAt(cap[1].length - 1) === \"\\n\" ? cap[1].slice(0, -1) : cap[1];\n      return {\n        type: \"paragraph\",\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text)\n      };\n    }\n  }\n  text(src) {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0])\n      };\n    }\n  }\n  escape(src) {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: \"escape\",\n        raw: cap[0],\n        text: cap[1]\n      };\n    }\n  }\n  tag(src) {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && this.rules.other.startATag.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && this.rules.other.endATag.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (!this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = true;\n      } else if (this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = false;\n      }\n      return {\n        type: \"html\",\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0]\n      };\n    }\n  }\n  link(src) {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && this.rules.other.startAngleBracket.test(trimmedUrl)) {\n        if (!this.rules.other.endAngleBracket.test(trimmedUrl)) {\n          return;\n        }\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), \"\\\\\");\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        const lastParenIndex = findClosingBracket(cap[2], \"()\");\n        if (lastParenIndex === -2) {\n          return;\n        }\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf(\"!\") === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = \"\";\n        }\n      }\n      let href = cap[2];\n      let title = \"\";\n      if (this.options.pedantic) {\n        const link2 = this.rules.other.pedanticHrefTitle.exec(href);\n        if (link2) {\n          href = link2[1];\n          title = link2[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : \"\";\n      }\n      href = href.trim();\n      if (this.rules.other.startAngleBracket.test(href)) {\n        if (this.options.pedantic && !this.rules.other.endAngleBracket.test(trimmedUrl)) {\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(cap, {\n        href: href ? href.replace(this.rules.inline.anyPunctuation, \"$1\") : href,\n        title: title ? title.replace(this.rules.inline.anyPunctuation, \"$1\") : title\n      }, cap[0], this.lexer, this.rules);\n    }\n  }\n  reflink(src, links) {\n    let cap;\n    if ((cap = this.rules.inline.reflink.exec(src)) || (cap = this.rules.inline.nolink.exec(src))) {\n      const linkString = (cap[2] || cap[1]).replace(this.rules.other.multipleSpaceGlobal, \" \");\n      const link2 = links[linkString.toLowerCase()];\n      if (!link2) {\n        const text = cap[0].charAt(0);\n        return {\n          type: \"text\",\n          raw: text,\n          text\n        };\n      }\n      return outputLink(cap, link2, cap[0], this.lexer, this.rules);\n    }\n  }\n  emStrong(src, maskedSrc, prevChar = \"\") {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n    if (match[3] && prevChar.match(this.rules.other.unicodeAlphaNumeric)) return;\n    const nextChar = match[1] || match[2] || \"\";\n    if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n      const lLength = [...match[0]].length - 1;\n      let rDelim,\n        rLength,\n        delimTotal = lLength,\n        midDelimTotal = 0;\n      const endReg = match[0][0] === \"*\" ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n        if (!rDelim) continue;\n        rLength = [...rDelim].length;\n        if (match[3] || match[4]) {\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) {\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue;\n          }\n        }\n        delimTotal -= rLength;\n        if (delimTotal > 0) continue;\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n        if (Math.min(lLength, rLength) % 2) {\n          const text2 = raw.slice(1, -1);\n          return {\n            type: \"em\",\n            raw,\n            text: text2,\n            tokens: this.lexer.inlineTokens(text2)\n          };\n        }\n        const text = raw.slice(2, -2);\n        return {\n          type: \"strong\",\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text)\n        };\n      }\n    }\n  }\n  codespan(src) {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(this.rules.other.newLineCharGlobal, \" \");\n      const hasNonSpaceChars = this.rules.other.nonSpaceChar.test(text);\n      const hasSpaceCharsOnBothEnds = this.rules.other.startingSpaceChar.test(text) && this.rules.other.endingSpaceChar.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      return {\n        type: \"codespan\",\n        raw: cap[0],\n        text\n      };\n    }\n  }\n  br(src) {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: \"br\",\n        raw: cap[0]\n      };\n    }\n  }\n  del(src) {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: \"del\",\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2])\n      };\n    }\n  }\n  autolink(src) {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = cap[1];\n        href = \"mailto:\" + text;\n      } else {\n        text = cap[1];\n        href = text;\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [{\n          type: \"text\",\n          raw: text,\n          text\n        }]\n      };\n    }\n  }\n  url(src) {\n    let cap;\n    if (cap = this.rules.inline.url.exec(src)) {\n      let text, href;\n      if (cap[2] === \"@\") {\n        text = cap[0];\n        href = \"mailto:\" + text;\n      } else {\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? \"\";\n        } while (prevCapZero !== cap[0]);\n        text = cap[0];\n        if (cap[1] === \"www.\") {\n          href = \"http://\" + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: \"link\",\n        raw: cap[0],\n        text,\n        href,\n        tokens: [{\n          type: \"text\",\n          raw: text,\n          text\n        }]\n      };\n    }\n  }\n  inlineText(src) {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      const escaped = this.lexer.state.inRawBlock;\n      return {\n        type: \"text\",\n        raw: cap[0],\n        text: cap[0],\n        escaped\n      };\n    }\n  }\n};\n\n// src/Lexer.ts\nvar _Lexer = class __Lexer {\n  constructor(options2) {\n    _defineProperty(this, \"tokens\", void 0);\n    _defineProperty(this, \"options\", void 0);\n    _defineProperty(this, \"state\", void 0);\n    _defineProperty(this, \"tokenizer\", void 0);\n    _defineProperty(this, \"inlineQueue\", void 0);\n    this.tokens = [];\n    this.tokens.links = /* @__PURE__ */Object.create(null);\n    this.options = options2 || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true\n    };\n    const rules = {\n      other,\n      block: block.normal,\n      inline: inline.normal\n    };\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline\n    };\n  }\n  /**\n   * Static Lex Method\n   */\n  static lex(src, options2) {\n    const lexer2 = new __Lexer(options2);\n    return lexer2.lex(src);\n  }\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src, options2) {\n    const lexer2 = new __Lexer(options2);\n    return lexer2.inlineTokens(src);\n  }\n  /**\n   * Preprocessing\n   */\n  lex(src) {\n    src = src.replace(other.carriageReturn, \"\\n\");\n    this.blockTokens(src, this.tokens);\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n    return this.tokens;\n  }\n  blockTokens(src, tokens = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(other.tabCharGlobal, \"    \").replace(other.spaceLine, \"\");\n    }\n    while (src) {\n      let token;\n      if (this.options.extensions?.block?.some(extTokenizer => {\n        if (token = extTokenizer.call({\n          lexer: this\n        }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n      if (token = this.tokenizer.space(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.raw.length === 1 && lastToken !== void 0) {\n          lastToken.raw += \"\\n\";\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (token = this.tokenizer.code(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"paragraph\" || lastToken?.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (token = this.tokenizer.fences(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.heading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.hr(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.blockquote(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.list(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.html(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.def(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"paragraph\" || lastToken?.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.raw;\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title\n          };\n        }\n        continue;\n      }\n      if (token = this.tokenizer.table(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.lheading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      let cutSrc = src;\n      if (this.options.extensions?.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach(getStartIndex => {\n          tempStart = getStartIndex.call({\n            lexer: this\n          }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        const lastToken = tokens.at(-1);\n        if (lastParagraphClipped && lastToken?.type === \"paragraph\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n      if (token = this.tokenizer.text(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"text\") {\n          lastToken.raw += \"\\n\" + token.raw;\n          lastToken.text += \"\\n\" + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1).src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    this.state.top = true;\n    return tokens;\n  }\n  inline(src, tokens = []) {\n    this.inlineQueue.push({\n      src,\n      tokens\n    });\n    return tokens;\n  }\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src, tokens = []) {\n    let maskedSrc = src;\n    let match = null;\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n          if (links.includes(match[0].slice(match[0].lastIndexOf(\"[\") + 1, -1))) {\n            maskedSrc = maskedSrc.slice(0, match.index) + \"[\" + \"a\".repeat(match[0].length - 2) + \"]\" + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n          }\n        }\n      }\n    }\n    while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + \"++\" + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + \"[\" + \"a\".repeat(match[0].length - 2) + \"]\" + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n    let keepPrevChar = false;\n    let prevChar = \"\";\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = \"\";\n      }\n      keepPrevChar = false;\n      let token;\n      if (this.options.extensions?.inline?.some(extTokenizer => {\n        if (token = extTokenizer.call({\n          lexer: this\n        }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n      if (token = this.tokenizer.escape(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.tag(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.link(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.type === \"text\" && lastToken?.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.codespan(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.br(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.del(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (token = this.tokenizer.autolink(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n      let cutSrc = src;\n      if (this.options.extensions?.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach(getStartIndex => {\n          tempStart = getStartIndex.call({\n            lexer: this\n          }, tempSrc);\n          if (typeof tempStart === \"number\" && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (token = this.tokenizer.inlineText(cutSrc)) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== \"_\") {\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === \"text\") {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n      if (src) {\n        const errMsg = \"Infinite loop on byte: \" + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n    return tokens;\n  }\n};\n\n// src/Renderer.ts\nvar _Renderer = class _Renderer {\n  // set by the parser\n  constructor(options2) {\n    _defineProperty(this, \"options\", void 0);\n    _defineProperty(this, \"parser\", void 0);\n    this.options = options2 || _defaults;\n  }\n  space(token) {\n    return \"\";\n  }\n  code({\n    text,\n    lang,\n    escaped\n  }) {\n    const langString = (lang || \"\").match(other.notSpaceStart)?.[0];\n    const code = text.replace(other.endingNewline, \"\") + \"\\n\";\n    if (!langString) {\n      return \"<pre><code>\" + (escaped ? code : escape2(code, true)) + \"</code></pre>\\n\";\n    }\n    return '<pre><code class=\"language-' + escape2(langString) + '\">' + (escaped ? code : escape2(code, true)) + \"</code></pre>\\n\";\n  }\n  blockquote({\n    tokens\n  }) {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\n${body}</blockquote>\n`;\n  }\n  html({\n    text\n  }) {\n    return text;\n  }\n  heading({\n    tokens,\n    depth\n  }) {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\n`;\n  }\n  hr(token) {\n    return \"<hr>\\n\";\n  }\n  list(token) {\n    const ordered = token.ordered;\n    const start = token.start;\n    let body = \"\";\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n    const type = ordered ? \"ol\" : \"ul\";\n    const startAttr = ordered && start !== 1 ? ' start=\"' + start + '\"' : \"\";\n    return \"<\" + type + startAttr + \">\\n\" + body + \"</\" + type + \">\\n\";\n  }\n  listitem(item) {\n    let itemBody = \"\";\n    if (item.task) {\n      const checkbox = this.checkbox({\n        checked: !!item.checked\n      });\n      if (item.loose) {\n        if (item.tokens[0]?.type === \"paragraph\") {\n          item.tokens[0].text = checkbox + \" \" + item.tokens[0].text;\n          if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === \"text\") {\n            item.tokens[0].tokens[0].text = checkbox + \" \" + escape2(item.tokens[0].tokens[0].text);\n            item.tokens[0].tokens[0].escaped = true;\n          }\n        } else {\n          item.tokens.unshift({\n            type: \"text\",\n            raw: checkbox + \" \",\n            text: checkbox + \" \",\n            escaped: true\n          });\n        }\n      } else {\n        itemBody += checkbox + \" \";\n      }\n    }\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n    return `<li>${itemBody}</li>\n`;\n  }\n  checkbox({\n    checked\n  }) {\n    return \"<input \" + (checked ? 'checked=\"\" ' : \"\") + 'disabled=\"\" type=\"checkbox\">';\n  }\n  paragraph({\n    tokens\n  }) {\n    return `<p>${this.parser.parseInline(tokens)}</p>\n`;\n  }\n  table(token) {\n    let header = \"\";\n    let cell = \"\";\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({\n      text: cell\n    });\n    let body = \"\";\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n      cell = \"\";\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n      body += this.tablerow({\n        text: cell\n      });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n    return \"<table>\\n<thead>\\n\" + header + \"</thead>\\n\" + body + \"</table>\\n\";\n  }\n  tablerow({\n    text\n  }) {\n    return `<tr>\n${text}</tr>\n`;\n  }\n  tablecell(token) {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? \"th\" : \"td\";\n    const tag2 = token.align ? `<${type} align=\"${token.align}\">` : `<${type}>`;\n    return tag2 + content + `</${type}>\n`;\n  }\n  /**\n   * span level renderer\n   */\n  strong({\n    tokens\n  }) {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n  em({\n    tokens\n  }) {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n  codespan({\n    text\n  }) {\n    return `<code>${escape2(text, true)}</code>`;\n  }\n  br(token) {\n    return \"<br>\";\n  }\n  del({\n    tokens\n  }) {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n  link({\n    href,\n    title,\n    tokens\n  }) {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + escape2(title) + '\"';\n    }\n    out += \">\" + text + \"</a>\";\n    return out;\n  }\n  image({\n    href,\n    title,\n    text,\n    tokens\n  }) {\n    if (tokens) {\n      text = this.parser.parseInline(tokens, this.parser.textRenderer);\n    }\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return escape2(text);\n    }\n    href = cleanHref;\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${escape2(title)}\"`;\n    }\n    out += \">\";\n    return out;\n  }\n  text(token) {\n    return \"tokens\" in token && token.tokens ? this.parser.parseInline(token.tokens) : \"escaped\" in token && token.escaped ? token.text : escape2(token.text);\n  }\n};\n\n// src/TextRenderer.ts\nvar _TextRenderer = class {\n  // no need for block level renderers\n  strong({\n    text\n  }) {\n    return text;\n  }\n  em({\n    text\n  }) {\n    return text;\n  }\n  codespan({\n    text\n  }) {\n    return text;\n  }\n  del({\n    text\n  }) {\n    return text;\n  }\n  html({\n    text\n  }) {\n    return text;\n  }\n  text({\n    text\n  }) {\n    return text;\n  }\n  link({\n    text\n  }) {\n    return \"\" + text;\n  }\n  image({\n    text\n  }) {\n    return \"\" + text;\n  }\n  br() {\n    return \"\";\n  }\n};\n\n// src/Parser.ts\nvar _Parser = class __Parser {\n  constructor(options2) {\n    _defineProperty(this, \"options\", void 0);\n    _defineProperty(this, \"renderer\", void 0);\n    _defineProperty(this, \"textRenderer\", void 0);\n    this.options = options2 || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens, options2) {\n    const parser2 = new __Parser(options2);\n    return parser2.parse(tokens);\n  }\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens, options2) {\n    const parser2 = new __Parser(options2);\n    return parser2.parseInline(tokens);\n  }\n  /**\n   * Parse Loop\n   */\n  parse(tokens, top = true) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const genericToken = anyToken;\n        const ret = this.options.extensions.renderers[genericToken.type].call({\n          parser: this\n        }, genericToken);\n        if (ret !== false || ![\"space\", \"hr\", \"heading\", \"code\", \"table\", \"blockquote\", \"list\", \"html\", \"paragraph\", \"text\"].includes(genericToken.type)) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"space\":\n          {\n            out += this.renderer.space(token);\n            continue;\n          }\n        case \"hr\":\n          {\n            out += this.renderer.hr(token);\n            continue;\n          }\n        case \"heading\":\n          {\n            out += this.renderer.heading(token);\n            continue;\n          }\n        case \"code\":\n          {\n            out += this.renderer.code(token);\n            continue;\n          }\n        case \"table\":\n          {\n            out += this.renderer.table(token);\n            continue;\n          }\n        case \"blockquote\":\n          {\n            out += this.renderer.blockquote(token);\n            continue;\n          }\n        case \"list\":\n          {\n            out += this.renderer.list(token);\n            continue;\n          }\n        case \"html\":\n          {\n            out += this.renderer.html(token);\n            continue;\n          }\n        case \"paragraph\":\n          {\n            out += this.renderer.paragraph(token);\n            continue;\n          }\n        case \"text\":\n          {\n            let textToken = token;\n            let body = this.renderer.text(textToken);\n            while (i + 1 < tokens.length && tokens[i + 1].type === \"text\") {\n              textToken = tokens[++i];\n              body += \"\\n\" + this.renderer.text(textToken);\n            }\n            if (top) {\n              out += this.renderer.paragraph({\n                type: \"paragraph\",\n                raw: body,\n                text: body,\n                tokens: [{\n                  type: \"text\",\n                  raw: body,\n                  text: body,\n                  escaped: true\n                }]\n              });\n            } else {\n              out += body;\n            }\n            continue;\n          }\n        default:\n          {\n            const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n            if (this.options.silent) {\n              console.error(errMsg);\n              return \"\";\n            } else {\n              throw new Error(errMsg);\n            }\n          }\n      }\n    }\n    return out;\n  }\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens, renderer = this.renderer) {\n    let out = \"\";\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const ret = this.options.extensions.renderers[anyToken.type].call({\n          parser: this\n        }, anyToken);\n        if (ret !== false || ![\"escape\", \"html\", \"link\", \"image\", \"strong\", \"em\", \"codespan\", \"br\", \"del\", \"text\"].includes(anyToken.type)) {\n          out += ret || \"\";\n          continue;\n        }\n      }\n      const token = anyToken;\n      switch (token.type) {\n        case \"escape\":\n          {\n            out += renderer.text(token);\n            break;\n          }\n        case \"html\":\n          {\n            out += renderer.html(token);\n            break;\n          }\n        case \"link\":\n          {\n            out += renderer.link(token);\n            break;\n          }\n        case \"image\":\n          {\n            out += renderer.image(token);\n            break;\n          }\n        case \"strong\":\n          {\n            out += renderer.strong(token);\n            break;\n          }\n        case \"em\":\n          {\n            out += renderer.em(token);\n            break;\n          }\n        case \"codespan\":\n          {\n            out += renderer.codespan(token);\n            break;\n          }\n        case \"br\":\n          {\n            out += renderer.br(token);\n            break;\n          }\n        case \"del\":\n          {\n            out += renderer.del(token);\n            break;\n          }\n        case \"text\":\n          {\n            out += renderer.text(token);\n            break;\n          }\n        default:\n          {\n            const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n            if (this.options.silent) {\n              console.error(errMsg);\n              return \"\";\n            } else {\n              throw new Error(errMsg);\n            }\n          }\n      }\n    }\n    return out;\n  }\n};\n\n// src/Hooks.ts\nvar _Hooks = (_Class3 = class _Hooks {\n  constructor(options2) {\n    _defineProperty(this, \"options\", void 0);\n    _defineProperty(this, \"block\", void 0);\n    this.options = options2 || _defaults;\n  }\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown) {\n    return markdown;\n  }\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html2) {\n    return html2;\n  }\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens) {\n    return tokens;\n  }\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}, _defineProperty(_Class3, \"passThroughHooks\", /* @__PURE__ */new Set([\"preprocess\", \"postprocess\", \"processAllTokens\"])), _Class3);\n\n// src/Instance.ts\nvar Marked = class Marked {\n  constructor(...args) {\n    _defineProperty(this, \"defaults\", _getDefaults());\n    _defineProperty(this, \"options\", this.setOptions);\n    _defineProperty(this, \"parse\", this.parseMarkdown(true));\n    _defineProperty(this, \"parseInline\", this.parseMarkdown(false));\n    _defineProperty(this, \"Parser\", _Parser);\n    _defineProperty(this, \"Renderer\", _Renderer);\n    _defineProperty(this, \"TextRenderer\", _TextRenderer);\n    _defineProperty(this, \"Lexer\", _Lexer);\n    _defineProperty(this, \"Tokenizer\", _Tokenizer);\n    _defineProperty(this, \"Hooks\", _Hooks);\n    this.use(...args);\n  }\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens, callback) {\n    let values = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case \"table\":\n          {\n            const tableToken = token;\n            for (const cell of tableToken.header) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n            for (const row of tableToken.rows) {\n              for (const cell of row) {\n                values = values.concat(this.walkTokens(cell.tokens, callback));\n              }\n            }\n            break;\n          }\n        case \"list\":\n          {\n            const listToken = token;\n            values = values.concat(this.walkTokens(listToken.items, callback));\n            break;\n          }\n        default:\n          {\n            const genericToken = token;\n            if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n              this.defaults.extensions.childTokens[genericToken.type].forEach(childTokens => {\n                const tokens2 = genericToken[childTokens].flat(Infinity);\n                values = values.concat(this.walkTokens(tokens2, callback));\n              });\n            } else if (genericToken.tokens) {\n              values = values.concat(this.walkTokens(genericToken.tokens, callback));\n            }\n          }\n      }\n    }\n    return values;\n  }\n  use(...args) {\n    const extensions = this.defaults.extensions || {\n      renderers: {},\n      childTokens: {}\n    };\n    args.forEach(pack => {\n      const opts = {\n        ...pack\n      };\n      opts.async = this.defaults.async || opts.async || false;\n      if (pack.extensions) {\n        pack.extensions.forEach(ext => {\n          if (!ext.name) {\n            throw new Error(\"extension name required\");\n          }\n          if (\"renderer\" in ext) {\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              extensions.renderers[ext.name] = function (...args2) {\n                let ret = ext.renderer.apply(this, args2);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args2);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if (\"tokenizer\" in ext) {\n            if (!ext.level || ext.level !== \"block\" && ext.level !== \"inline\") {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) {\n              if (ext.level === \"block\") {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === \"inline\") {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if (\"childTokens\" in ext && ext.childTokens) {\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"parser\"].includes(prop)) {\n            continue;\n          }\n          const rendererProp = prop;\n          const rendererFunc = pack.renderer[rendererProp];\n          const prevRenderer = renderer[rendererProp];\n          renderer[rendererProp] = (...args2) => {\n            let ret = rendererFunc.apply(renderer, args2);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args2);\n            }\n            return ret || \"\";\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer = this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if ([\"options\", \"rules\", \"lexer\"].includes(prop)) {\n            continue;\n          }\n          const tokenizerProp = prop;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp];\n          const prevTokenizer = tokenizer[tokenizerProp];\n          tokenizer[tokenizerProp] = (...args2) => {\n            let ret = tokenizerFunc.apply(tokenizer, args2);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args2);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if ([\"options\", \"block\"].includes(prop)) {\n            continue;\n          }\n          const hooksProp = prop;\n          const hooksFunc = pack.hooks[hooksProp];\n          const prevHook = hooks[hooksProp];\n          if (_Hooks.passThroughHooks.has(prop)) {\n            hooks[hooksProp] = arg => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(ret2 => {\n                  return prevHook.call(hooks, ret2);\n                });\n              }\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            hooks[hooksProp] = (...args2) => {\n              let ret = hooksFunc.apply(hooks, args2);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args2);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n      if (pack.walkTokens) {\n        const walkTokens2 = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function (token) {\n          let values = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens2) {\n            values = values.concat(walkTokens2.call(this, token));\n          }\n          return values;\n        };\n      }\n      this.defaults = {\n        ...this.defaults,\n        ...opts\n      };\n    });\n    return this;\n  }\n  setOptions(opt) {\n    this.defaults = {\n      ...this.defaults,\n      ...opt\n    };\n    return this;\n  }\n  lexer(src, options2) {\n    return _Lexer.lex(src, options2 ?? this.defaults);\n  }\n  parser(tokens, options2) {\n    return _Parser.parse(tokens, options2 ?? this.defaults);\n  }\n  parseMarkdown(blockType) {\n    const parse2 = (src, options2) => {\n      const origOpt = {\n        ...options2\n      };\n      const opt = {\n        ...this.defaults,\n        ...origOpt\n      };\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(new Error(\"marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.\"));\n      }\n      if (typeof src === \"undefined\" || src === null) {\n        return throwError(new Error(\"marked(): input parameter is undefined or null\"));\n      }\n      if (typeof src !== \"string\") {\n        return throwError(new Error(\"marked(): input parameter is of type \" + Object.prototype.toString.call(src) + \", string expected\"));\n      }\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n      const lexer2 = opt.hooks ? opt.hooks.provideLexer() : blockType ? _Lexer.lex : _Lexer.lexInline;\n      const parser2 = opt.hooks ? opt.hooks.provideParser() : blockType ? _Parser.parse : _Parser.parseInline;\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src).then(src2 => lexer2(src2, opt)).then(tokens => opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens).then(tokens => opt.walkTokens ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(() => tokens) : tokens).then(tokens => parser2(tokens, opt)).then(html2 => opt.hooks ? opt.hooks.postprocess(html2) : html2).catch(throwError);\n      }\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src);\n        }\n        let tokens = lexer2(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html2 = parser2(tokens, opt);\n        if (opt.hooks) {\n          html2 = opt.hooks.postprocess(html2);\n        }\n        return html2;\n      } catch (e) {\n        return throwError(e);\n      }\n    };\n    return parse2;\n  }\n  onError(silent, async) {\n    return e => {\n      e.message += \"\\nPlease report this to https://github.com/markedjs/marked.\";\n      if (silent) {\n        const msg = \"<p>An error occurred:</p><pre>\" + escape2(e.message + \"\", true) + \"</pre>\";\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n};\n\n// src/marked.ts\nvar markedInstance = new Marked();\nfunction marked(src, opt) {\n  return markedInstance.parse(src, opt);\n}\nmarked.options = marked.setOptions = function (options2) {\n  markedInstance.setOptions(options2);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\nmarked.getDefaults = _getDefaults;\nmarked.defaults = _defaults;\nmarked.use = function (...args) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\nmarked.walkTokens = function (tokens, callback) {\n  return markedInstance.walkTokens(tokens, callback);\n};\nmarked.parseInline = markedInstance.parseInline;\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\nvar options = marked.options;\nvar setOptions = marked.setOptions;\nvar use = marked.use;\nvar walkTokens = marked.walkTokens;\nvar parseInline = marked.parseInline;\nvar parse = marked;\nvar parser = _Parser.parse;\nvar lexer = _Lexer.lex;\nexport { _Hooks as Hooks, _Lexer as Lexer, Marked, _Parser as Parser, _Renderer as Renderer, _TextRenderer as TextRenderer, _Tokenizer as Tokenizer, _defaults as defaults, _getDefaults as getDefaults, lexer, marked, options, parse, parseInline, parser, setOptions, use, walkTokens };","map":{"version":3,"names":["_getDefaults","async","breaks","extensions","gfm","hooks","pedantic","renderer","silent","tokenizer","walkTokens","_defaults","changeDefaults","newDefaults","noopTest","exec","edit","regex","opt","source","obj","replace","name","val","valSource","other","caret","getRegex","RegExp","codeRemoveIndent","outputLinkReplace","indentCodeCompensation","beginningSpace","endingHash","startingSpaceChar","endingSpaceChar","nonSpaceChar","newLineCharGlobal","tabCharGlobal","multipleSpaceGlobal","blankLine","doubleBlankLine","blockquoteStart","blockquoteSetextReplace","blockquoteSetextReplace2","listReplaceTabs","listReplaceNesting","listIsTask","listReplaceTask","anyLine","hrefBrackets","tableDelimiter","tableAlignChars","tableRowBlankLine","tableAlignRight","tableAlignCenter","tableAlignLeft","startATag","endATag","startPreScriptTag","endPreScriptTag","startAngleBracket","endAngleBracket","pedanticHrefTitle","unicodeAlphaNumeric","escapeTest","escapeReplace","escapeTestNoEncode","escapeReplaceNoEncode","unescapeTest","percentDecode","findPipe","splitPipe","slashPipe","carriageReturn","spaceLine","notSpaceStart","endingNewline","listItemRegex","bull","nextBulletRegex","indent","Math","min","hrRegex","fencesBeginRegex","headingBeginRegex","htmlBeginRegex","newline","blockCode","fences","hr","heading","bullet","lheadingCore","lheading","lheadingGfm","_paragraph","blockText","_blockLabel","def","list","_tag","_comment","html","paragraph","blockquote","blockNormal","code","table","text","gfmTable","blockGfm","blockPedantic","escape","inlineCode","br","inlineText","_punctuation","_punctuationOrSpace","_notPunctuationOrSpace","punctuation","_punctuationGfmStrongEm","_punctuationOrSpaceGfmStrongEm","_notPunctuationOrSpaceGfmStrongEm","blockSkip","emStrongLDelimCore","emStrongLDelim","emStrongLDelimGfm","emStrongRDelimAstCore","emStrongRDelimAst","emStrongRDelimAstGfm","emStrongRDelimUnd","anyPunctuation","autolink","_inlineComment","tag","_inlineLabel","link","reflink","nolink","reflinkSearch","inlineNormal","_backpedal","del","url","inlinePedantic","inlineGfm","inlineBreaks","block","normal","inline","escapeReplacements","getEscapeReplacement","ch","escape2","html2","encode","test","cleanUrl","href","encodeURI","splitCells","tableRow","count","row","match","offset","str","escaped","curr","cells","split","i","trim","shift","length","at","pop","splice","push","rtrim","c","invert","l","suffLen","currChar","charAt","slice","findClosingBracket","b","indexOf","level","outputLink","cap","link2","raw","lexer2","rules","title","state","inLink","token","type","tokens","inlineTokens","matchIndentToCode","indentToCode","map","node","matchIndentInNode","indentInNode","join","_Tokenizer","constructor","options2","_defineProperty","options","space","src","codeBlockStyle","lang","trimmed","depth","lexer","lines","inBlockquote","currentLines","currentRaw","currentText","top","blockTokens","lastToken","oldToken","newText","newToken","substring","isordered","list2","ordered","start","loose","items","itemRegex","endsWithBlankLine","endEarly","itemContents","line","t","repeat","nextLine","trimStart","search","rawLine","nextLineWithoutTabs","istask","ischecked","task","checked","lastItem","trimEnd","spacers","filter","hasMultipleLineBreaks","some","pre","tag2","toLowerCase","headers","aligns","rows","item","header","align","cell","inRawBlock","trimmedUrl","rtrimSlash","lastParenIndex","linkLen","links","linkString","emStrong","maskedSrc","prevChar","nextChar","lLength","rDelim","rLength","delimTotal","midDelimTotal","endReg","lastIndex","lastCharLength","index","text2","codespan","hasNonSpaceChars","hasSpaceCharsOnBothEnds","prevCapZero","_Lexer","__Lexer","Object","create","inlineQueue","lex","lexInline","next","lastParagraphClipped","extTokenizer","call","cutSrc","startBlock","startIndex","Infinity","tempSrc","tempStart","forEach","getStartIndex","errMsg","charCodeAt","console","error","Error","keys","includes","lastIndexOf","keepPrevChar","startInline","_Renderer","langString","body","parser","parse","parseInline","j","listitem","startAttr","itemBody","checkbox","unshift","tablecell","tablerow","k","content","strong","em","cleanHref","out","image","textRenderer","_TextRenderer","_Parser","__Parser","parser2","anyToken","renderers","genericToken","ret","textToken","_Hooks","_Class3","preprocess","markdown","postprocess","processAllTokens","provideLexer","provideParser","Set","Marked","args","setOptions","parseMarkdown","use","callback","values","concat","tableToken","listToken","defaults","childTokens","tokens2","flat","pack","opts","ext","prevRenderer","args2","apply","extLevel","prop","rendererProp","rendererFunc","tokenizerProp","tokenizerFunc","prevTokenizer","hooksProp","hooksFunc","prevHook","passThroughHooks","has","arg","Promise","resolve","then","ret2","walkTokens2","packWalktokens","blockType","parse2","origOpt","throwError","onError","prototype","toString","src2","all","catch","e","message","msg","reject","markedInstance","marked","getDefaults","Parser","Renderer","TextRenderer","Lexer","Tokenizer","Hooks"],"sources":["../src/defaults.ts","../src/rules.ts","../src/helpers.ts","../src/Tokenizer.ts","../src/Lexer.ts","../src/Renderer.ts","../src/TextRenderer.ts","../src/Parser.ts","../src/Hooks.ts","../src/Instance.ts","../src/marked.ts"],"sourcesContent":["import type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Gets the original marked default options.\n */\nexport function _getDefaults(): MarkedOptions {\n  return {\n    async: false,\n    breaks: false,\n    extensions: null,\n    gfm: true,\n    hooks: null,\n    pedantic: false,\n    renderer: null,\n    silent: false,\n    tokenizer: null,\n    walkTokens: null,\n  };\n}\n\nexport let _defaults = _getDefaults();\n\nexport function changeDefaults(newDefaults: MarkedOptions) {\n  _defaults = newDefaults;\n}\n","const noopTest = { exec: () => null } as unknown as RegExp;\n\nfunction edit(regex: string | RegExp, opt = '') {\n  let source = typeof regex === 'string' ? regex : regex.source;\n  const obj = {\n    replace: (name: string | RegExp, val: string | RegExp) => {\n      let valSource = typeof val === 'string' ? val : val.source;\n      valSource = valSource.replace(other.caret, '$1');\n      source = source.replace(name, valSource);\n      return obj;\n    },\n    getRegex: () => {\n      return new RegExp(source, opt);\n    },\n  };\n  return obj;\n}\n\nexport const other = {\n  codeRemoveIndent: /^(?: {1,4}| {0,3}\\t)/gm,\n  outputLinkReplace: /\\\\([\\[\\]])/g,\n  indentCodeCompensation: /^(\\s+)(?:```)/,\n  beginningSpace: /^\\s+/,\n  endingHash: /#$/,\n  startingSpaceChar: /^ /,\n  endingSpaceChar: / $/,\n  nonSpaceChar: /[^ ]/,\n  newLineCharGlobal: /\\n/g,\n  tabCharGlobal: /\\t/g,\n  multipleSpaceGlobal: /\\s+/g,\n  blankLine: /^[ \\t]*$/,\n  doubleBlankLine: /\\n[ \\t]*\\n[ \\t]*$/,\n  blockquoteStart: /^ {0,3}>/,\n  blockquoteSetextReplace: /\\n {0,3}((?:=+|-+) *)(?=\\n|$)/g,\n  blockquoteSetextReplace2: /^ {0,3}>[ \\t]?/gm,\n  listReplaceTabs: /^\\t+/,\n  listReplaceNesting: /^ {1,4}(?=( {4})*[^ ])/g,\n  listIsTask: /^\\[[ xX]\\] /,\n  listReplaceTask: /^\\[[ xX]\\] +/,\n  anyLine: /\\n.*\\n/,\n  hrefBrackets: /^<(.*)>$/,\n  tableDelimiter: /[:|]/,\n  tableAlignChars: /^\\||\\| *$/g,\n  tableRowBlankLine: /\\n[ \\t]*$/,\n  tableAlignRight: /^ *-+: *$/,\n  tableAlignCenter: /^ *:-+: *$/,\n  tableAlignLeft: /^ *:-+ *$/,\n  startATag: /^<a /i,\n  endATag: /^<\\/a>/i,\n  startPreScriptTag: /^<(pre|code|kbd|script)(\\s|>)/i,\n  endPreScriptTag: /^<\\/(pre|code|kbd|script)(\\s|>)/i,\n  startAngleBracket: /^</,\n  endAngleBracket: />$/,\n  pedanticHrefTitle: /^([^'\"]*[^\\s])\\s+(['\"])(.*)\\2/,\n  unicodeAlphaNumeric: /[\\p{L}\\p{N}]/u,\n  escapeTest: /[&<>\"']/,\n  escapeReplace: /[&<>\"']/g,\n  escapeTestNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/,\n  escapeReplaceNoEncode: /[<>\"']|&(?!(#\\d{1,7}|#[Xx][a-fA-F0-9]{1,6}|\\w+);)/g,\n  unescapeTest: /&(#(?:\\d+)|(?:#x[0-9A-Fa-f]+)|(?:\\w+));?/ig,\n  caret: /(^|[^\\[])\\^/g,\n  percentDecode: /%25/g,\n  findPipe: /\\|/g,\n  splitPipe: / \\|/,\n  slashPipe: /\\\\\\|/g,\n  carriageReturn: /\\r\\n|\\r/g,\n  spaceLine: /^ +$/gm,\n  notSpaceStart: /^\\S*/,\n  endingNewline: /\\n$/,\n  listItemRegex: (bull: string) => new RegExp(`^( {0,3}${bull})((?:[\\t ][^\\\\n]*)?(?:\\\\n|$))`),\n  nextBulletRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:[*+-]|\\\\d{1,9}[.)])((?:[ \\t][^\\\\n]*)?(?:\\\\n|$))`),\n  hrRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}((?:- *){3,}|(?:_ *){3,}|(?:\\\\* *){3,})(?:\\\\n+|$)`),\n  fencesBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}(?:\\`\\`\\`|~~~)`),\n  headingBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}#`),\n  htmlBeginRegex: (indent: number) => new RegExp(`^ {0,${Math.min(3, indent - 1)}}<(?:[a-z].*>|!--)`, 'i'),\n};\n\n/**\n * Block-Level Grammar\n */\n\nconst newline = /^(?:[ \\t]*(?:\\n|$))+/;\nconst blockCode = /^((?: {4}| {0,3}\\t)[^\\n]+(?:\\n(?:[ \\t]*(?:\\n|$))*)?)+/;\nconst fences = /^ {0,3}(`{3,}(?=[^`\\n]*(?:\\n|$))|~{3,})([^\\n]*)(?:\\n|$)(?:|([\\s\\S]*?)(?:\\n|$))(?: {0,3}\\1[~`]* *(?=\\n|$)|$)/;\nconst hr = /^ {0,3}((?:-[\\t ]*){3,}|(?:_[ \\t]*){3,}|(?:\\*[ \\t]*){3,})(?:\\n+|$)/;\nconst heading = /^ {0,3}(#{1,6})(?=\\s|$)(.*)(?:\\n+|$)/;\nconst bullet = /(?:[*+-]|\\d{1,9}[.)])/;\nconst lheadingCore = /^(?!bull |blockCode|fences|blockquote|heading|html|table)((?:.|\\n(?!\\s*?\\n|bull |blockCode|fences|blockquote|heading|html|table))+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/;\nconst lheading = edit(lheadingCore)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .replace(/\\|table/g, '') // table not in commonmark\n  .getRegex();\nconst lheadingGfm = edit(lheadingCore)\n  .replace(/bull/g, bullet) // lists can interrupt\n  .replace(/blockCode/g, /(?: {4}| {0,3}\\t)/) // indented code blocks can interrupt\n  .replace(/fences/g, / {0,3}(?:`{3,}|~{3,})/) // fenced code blocks can interrupt\n  .replace(/blockquote/g, / {0,3}>/) // blockquote can interrupt\n  .replace(/heading/g, / {0,3}#{1,6}/) // ATX heading can interrupt\n  .replace(/html/g, / {0,3}<[^\\n>]+>\\n/) // block html can interrupt\n  .replace(/table/g, / {0,3}\\|?(?:[:\\- ]*\\|)+[\\:\\- ]*\\n/) // table can interrupt\n  .getRegex();\nconst _paragraph = /^([^\\n]+(?:\\n(?!hr|heading|lheading|blockquote|fences|list|html|table| +\\n)[^\\n]+)*)/;\nconst blockText = /^[^\\n]+/;\nconst _blockLabel = /(?!\\s*\\])(?:\\\\.|[^\\[\\]\\\\])+/;\nconst def = edit(/^ {0,3}\\[(label)\\]: *(?:\\n[ \\t]*)?([^<\\s][^\\s]*|<.*?>)(?:(?: +(?:\\n[ \\t]*)?| *\\n[ \\t]*)(title))? *(?:\\n+|$)/)\n  .replace('label', _blockLabel)\n  .replace('title', /(?:\"(?:\\\\\"?|[^\"\\\\])*\"|'[^'\\n]*(?:\\n[^'\\n]+)*\\n?'|\\([^()]*\\))/)\n  .getRegex();\n\nconst list = edit(/^( {0,3}bull)([ \\t][^\\n]+?)?(?:\\n|$)/)\n  .replace(/bull/g, bullet)\n  .getRegex();\n\nconst _tag = 'address|article|aside|base|basefont|blockquote|body|caption'\n  + '|center|col|colgroup|dd|details|dialog|dir|div|dl|dt|fieldset|figcaption'\n  + '|figure|footer|form|frame|frameset|h[1-6]|head|header|hr|html|iframe'\n  + '|legend|li|link|main|menu|menuitem|meta|nav|noframes|ol|optgroup|option'\n  + '|p|param|search|section|summary|table|tbody|td|tfoot|th|thead|title'\n  + '|tr|track|ul';\nconst _comment = /<!--(?:-?>|[\\s\\S]*?(?:-->|$))/;\nconst html = edit(\n  '^ {0,3}(?:' // optional indentation\n+ '<(script|pre|style|textarea)[\\\\s>][\\\\s\\\\S]*?(?:</\\\\1>[^\\\\n]*\\\\n+|$)' // (1)\n+ '|comment[^\\\\n]*(\\\\n+|$)' // (2)\n+ '|<\\\\?[\\\\s\\\\S]*?(?:\\\\?>\\\\n*|$)' // (3)\n+ '|<![A-Z][\\\\s\\\\S]*?(?:>\\\\n*|$)' // (4)\n+ '|<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?(?:\\\\]\\\\]>\\\\n*|$)' // (5)\n+ '|</?(tag)(?: +|\\\\n|/?>)[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (6)\n+ '|<(?!script|pre|style|textarea)([a-z][\\\\w-]*)(?:attribute)*? */?>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) open tag\n+ '|</(?!script|pre|style|textarea)[a-z][\\\\w-]*\\\\s*>(?=[ \\\\t]*(?:\\\\n|$))[\\\\s\\\\S]*?(?:(?:\\\\n[ \\t]*)+\\\\n|$)' // (7) closing tag\n+ ')', 'i')\n  .replace('comment', _comment)\n  .replace('tag', _tag)\n  .replace('attribute', / +[a-zA-Z:_][\\w.:-]*(?: *= *\"[^\"\\n]*\"| *= *'[^'\\n]*'| *= *[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nconst paragraph = edit(_paragraph)\n  .replace('hr', hr)\n  .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n  .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n  .replace('|table', '')\n  .replace('blockquote', ' {0,3}>')\n  .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n  .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n  .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n  .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n  .getRegex();\n\nconst blockquote = edit(/^( {0,3}> ?(paragraph|[^\\n]*)(?:\\n|$))+/)\n  .replace('paragraph', paragraph)\n  .getRegex();\n\n/**\n * Normal Block Grammar\n */\n\nconst blockNormal = {\n  blockquote,\n  code: blockCode,\n  def,\n  fences,\n  heading,\n  hr,\n  html,\n  lheading,\n  list,\n  newline,\n  paragraph,\n  table: noopTest,\n  text: blockText,\n};\n\ntype BlockKeys = keyof typeof blockNormal;\n\n/**\n * GFM Block Grammar\n */\n\nconst gfmTable = edit(\n  '^ *([^\\\\n ].*)\\\\n' // Header\n+ ' {0,3}((?:\\\\| *)?:?-+:? *(?:\\\\| *:?-+:? *)*(?:\\\\| *)?)' // Align\n+ '(?:\\\\n((?:(?! *\\\\n|hr|heading|blockquote|code|fences|list|html).*(?:\\\\n|$))*)\\\\n*|$)') // Cells\n  .replace('hr', hr)\n  .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n  .replace('blockquote', ' {0,3}>')\n  .replace('code', '(?: {4}| {0,3}\\t)[^\\\\n]')\n  .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n  .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n  .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n  .replace('tag', _tag) // tables can be interrupted by type (6) html blocks\n  .getRegex();\n\nconst blockGfm: Record<BlockKeys, RegExp> = {\n  ...blockNormal,\n  lheading: lheadingGfm,\n  table: gfmTable,\n  paragraph: edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' {0,3}#{1,6}(?:\\\\s|$)')\n    .replace('|lheading', '') // setext headings don't interrupt commonmark paragraphs\n    .replace('table', gfmTable) // interrupt paragraphs with table\n    .replace('blockquote', ' {0,3}>')\n    .replace('fences', ' {0,3}(?:`{3,}(?=[^`\\\\n]*\\\\n)|~{3,})[^\\\\n]*\\\\n')\n    .replace('list', ' {0,3}(?:[*+-]|1[.)]) ') // only lists starting from 1 can interrupt\n    .replace('html', '</?(?:tag)(?: +|\\\\n|/?>)|<(?:script|pre|style|textarea|!--)')\n    .replace('tag', _tag) // pars can be interrupted by type (6) html blocks\n    .getRegex(),\n};\n\n/**\n * Pedantic grammar (original John Gruber's loose markdown specification)\n */\n\nconst blockPedantic: Record<BlockKeys, RegExp> = {\n  ...blockNormal,\n  html: edit(\n    '^ *(?:comment *(?:\\\\n|\\\\s*$)'\n    + '|<(tag)[\\\\s\\\\S]+?</\\\\1> *(?:\\\\n{2,}|\\\\s*$)' // closed tag\n    + '|<tag(?:\"[^\"]*\"|\\'[^\\']*\\'|\\\\s[^\\'\"/>\\\\s]*)*?/?> *(?:\\\\n{2,}|\\\\s*$))')\n    .replace('comment', _comment)\n    .replace(/tag/g, '(?!(?:'\n      + 'a|em|strong|small|s|cite|q|dfn|abbr|data|time|code|var|samp|kbd|sub'\n      + '|sup|i|b|u|mark|ruby|rt|rp|bdi|bdo|span|br|wbr|ins|del|img)'\n      + '\\\\b)\\\\w+(?!:|[^\\\\w\\\\s@]*@)\\\\b')\n    .getRegex(),\n  def: /^ *\\[([^\\]]+)\\]: *<?([^\\s>]+)>?(?: +([\"(][^\\n]+[\")]))? *(?:\\n+|$)/,\n  heading: /^(#{1,6})(.*)(?:\\n+|$)/,\n  fences: noopTest, // fences not supported\n  lheading: /^(.+?)\\n {0,3}(=+|-+) *(?:\\n+|$)/,\n  paragraph: edit(_paragraph)\n    .replace('hr', hr)\n    .replace('heading', ' *#{1,6} *[^\\n]')\n    .replace('lheading', lheading)\n    .replace('|table', '')\n    .replace('blockquote', ' {0,3}>')\n    .replace('|fences', '')\n    .replace('|list', '')\n    .replace('|html', '')\n    .replace('|tag', '')\n    .getRegex(),\n};\n\n/**\n * Inline-Level Grammar\n */\n\nconst escape = /^\\\\([!\"#$%&'()*+,\\-./:;<=>?@\\[\\]\\\\^_`{|}~])/;\nconst inlineCode = /^(`+)([^`]|[^`][\\s\\S]*?[^`])\\1(?!`)/;\nconst br = /^( {2,}|\\\\)\\n(?!\\s*$)/;\nconst inlineText = /^(`+|[^`])(?:(?= {2,}\\n)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*_]|\\b_|$)|[^ ](?= {2,}\\n)))/;\n\n// list of unicode punctuation marks, plus any missing characters from CommonMark spec\nconst _punctuation = /[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpace = /[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpace = /[^\\s\\p{P}\\p{S}]/u;\nconst punctuation = edit(/^((?![*_])punctSpace)/, 'u')\n  .replace(/punctSpace/g, _punctuationOrSpace).getRegex();\n\n// GFM allows ~ inside strong and em for strikethrough\nconst _punctuationGfmStrongEm = /(?!~)[\\p{P}\\p{S}]/u;\nconst _punctuationOrSpaceGfmStrongEm = /(?!~)[\\s\\p{P}\\p{S}]/u;\nconst _notPunctuationOrSpaceGfmStrongEm = /(?:[^\\s\\p{P}\\p{S}]|~)/u;\n\n// sequences em should skip over [title](link), `code`, <html>\nconst blockSkip = /\\[[^[\\]]*?\\]\\((?:\\\\.|[^\\\\\\(\\)]|\\((?:\\\\.|[^\\\\\\(\\)])*\\))*\\)|`[^`]*?`|<[^<>]*?>/g;\n\nconst emStrongLDelimCore = /^(?:\\*+(?:((?!\\*)punct)|[^\\s*]))|^_+(?:((?!_)punct)|([^\\s_]))/;\n\nconst emStrongLDelim = edit(emStrongLDelimCore, 'u')\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst emStrongLDelimGfm = edit(emStrongLDelimCore, 'u')\n  .replace(/punct/g, _punctuationGfmStrongEm)\n  .getRegex();\n\nconst emStrongRDelimAstCore =\n  '^[^_*]*?__[^_*]*?\\\\*[^_*]*?(?=__)' // Skip orphan inside strong\n+ '|[^*]+(?=[^*])' // Consume to delim\n+ '|(?!\\\\*)punct(\\\\*+)(?=[\\\\s]|$)' // (1) #*** can only be a Right Delimiter\n+ '|notPunctSpace(\\\\*+)(?!\\\\*)(?=punctSpace|$)' // (2) a***#, a*** can only be a Right Delimiter\n+ '|(?!\\\\*)punctSpace(\\\\*+)(?=notPunctSpace)' // (3) #***a, ***a can only be Left Delimiter\n+ '|[\\\\s](\\\\*+)(?!\\\\*)(?=punct)' // (4) ***# can only be Left Delimiter\n+ '|(?!\\\\*)punct(\\\\*+)(?!\\\\*)(?=punct)' // (5) #***# can be either Left or Right Delimiter\n+ '|notPunctSpace(\\\\*+)(?=notPunctSpace)'; // (6) a***a can be either Left or Right Delimiter\n\nconst emStrongRDelimAst = edit(emStrongRDelimAstCore, 'gu')\n  .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n  .replace(/punctSpace/g, _punctuationOrSpace)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst emStrongRDelimAstGfm = edit(emStrongRDelimAstCore, 'gu')\n  .replace(/notPunctSpace/g, _notPunctuationOrSpaceGfmStrongEm)\n  .replace(/punctSpace/g, _punctuationOrSpaceGfmStrongEm)\n  .replace(/punct/g, _punctuationGfmStrongEm)\n  .getRegex();\n\n// (6) Not allowed for _\nconst emStrongRDelimUnd = edit(\n  '^[^_*]*?\\\\*\\\\*[^_*]*?_[^_*]*?(?=\\\\*\\\\*)' // Skip orphan inside strong\n+ '|[^_]+(?=[^_])' // Consume to delim\n+ '|(?!_)punct(_+)(?=[\\\\s]|$)' // (1) #___ can only be a Right Delimiter\n+ '|notPunctSpace(_+)(?!_)(?=punctSpace|$)' // (2) a___#, a___ can only be a Right Delimiter\n+ '|(?!_)punctSpace(_+)(?=notPunctSpace)' // (3) #___a, ___a can only be Left Delimiter\n+ '|[\\\\s](_+)(?!_)(?=punct)' // (4) ___# can only be Left Delimiter\n+ '|(?!_)punct(_+)(?!_)(?=punct)', 'gu') // (5) #___# can be either Left or Right Delimiter\n  .replace(/notPunctSpace/g, _notPunctuationOrSpace)\n  .replace(/punctSpace/g, _punctuationOrSpace)\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst anyPunctuation = edit(/\\\\(punct)/, 'gu')\n  .replace(/punct/g, _punctuation)\n  .getRegex();\n\nconst autolink = edit(/^<(scheme:[^\\s\\x00-\\x1f<>]*|email)>/)\n  .replace('scheme', /[a-zA-Z][a-zA-Z0-9+.-]{1,31}/)\n  .replace('email', /[a-zA-Z0-9.!#$%&'*+/=?^_`{|}~-]+(@)[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)+(?![-_])/)\n  .getRegex();\n\nconst _inlineComment = edit(_comment).replace('(?:-->|$)', '-->').getRegex();\nconst tag = edit(\n  '^comment'\n    + '|^</[a-zA-Z][\\\\w:-]*\\\\s*>' // self-closing tag\n    + '|^<[a-zA-Z][\\\\w-]*(?:attribute)*?\\\\s*/?>' // open tag\n    + '|^<\\\\?[\\\\s\\\\S]*?\\\\?>' // processing instruction, e.g. <?php ?>\n    + '|^<![a-zA-Z]+\\\\s[\\\\s\\\\S]*?>' // declaration, e.g. <!DOCTYPE html>\n    + '|^<!\\\\[CDATA\\\\[[\\\\s\\\\S]*?\\\\]\\\\]>') // CDATA section\n  .replace('comment', _inlineComment)\n  .replace('attribute', /\\s+[a-zA-Z:_][\\w.:-]*(?:\\s*=\\s*\"[^\"]*\"|\\s*=\\s*'[^']*'|\\s*=\\s*[^\\s\"'=<>`]+)?/)\n  .getRegex();\n\nconst _inlineLabel = /(?:\\[(?:\\\\.|[^\\[\\]\\\\])*\\]|\\\\.|`[^`]*`|[^\\[\\]\\\\`])*?/;\n\nconst link = edit(/^!?\\[(label)\\]\\(\\s*(href)(?:(?:[ \\t]*(?:\\n[ \\t]*)?)(title))?\\s*\\)/)\n  .replace('label', _inlineLabel)\n  .replace('href', /<(?:\\\\.|[^\\n<>\\\\])+>|[^ \\t\\n\\x00-\\x1f]*/)\n  .replace('title', /\"(?:\\\\\"?|[^\"\\\\])*\"|'(?:\\\\'?|[^'\\\\])*'|\\((?:\\\\\\)?|[^)\\\\])*\\)/)\n  .getRegex();\n\nconst reflink = edit(/^!?\\[(label)\\]\\[(ref)\\]/)\n  .replace('label', _inlineLabel)\n  .replace('ref', _blockLabel)\n  .getRegex();\n\nconst nolink = edit(/^!?\\[(ref)\\](?:\\[\\])?/)\n  .replace('ref', _blockLabel)\n  .getRegex();\n\nconst reflinkSearch = edit('reflink|nolink(?!\\\\()', 'g')\n  .replace('reflink', reflink)\n  .replace('nolink', nolink)\n  .getRegex();\n\n/**\n * Normal Inline Grammar\n */\n\nconst inlineNormal = {\n  _backpedal: noopTest, // only used for GFM url\n  anyPunctuation,\n  autolink,\n  blockSkip,\n  br,\n  code: inlineCode,\n  del: noopTest,\n  emStrongLDelim,\n  emStrongRDelimAst,\n  emStrongRDelimUnd,\n  escape,\n  link,\n  nolink,\n  punctuation,\n  reflink,\n  reflinkSearch,\n  tag,\n  text: inlineText,\n  url: noopTest,\n};\n\ntype InlineKeys = keyof typeof inlineNormal;\n\n/**\n * Pedantic Inline Grammar\n */\n\nconst inlinePedantic: Record<InlineKeys, RegExp> = {\n  ...inlineNormal,\n  link: edit(/^!?\\[(label)\\]\\((.*?)\\)/)\n    .replace('label', _inlineLabel)\n    .getRegex(),\n  reflink: edit(/^!?\\[(label)\\]\\s*\\[([^\\]]*)\\]/)\n    .replace('label', _inlineLabel)\n    .getRegex(),\n};\n\n/**\n * GFM Inline Grammar\n */\n\nconst inlineGfm: Record<InlineKeys, RegExp> = {\n  ...inlineNormal,\n  emStrongRDelimAst: emStrongRDelimAstGfm,\n  emStrongLDelim: emStrongLDelimGfm,\n  url: edit(/^((?:ftp|https?):\\/\\/|www\\.)(?:[a-zA-Z0-9\\-]+\\.?)+[^\\s<]*|^email/, 'i')\n    .replace('email', /[A-Za-z0-9._+-]+(@)[a-zA-Z0-9-_]+(?:\\.[a-zA-Z0-9-_]*[a-zA-Z0-9])+(?![-_])/)\n    .getRegex(),\n  _backpedal: /(?:[^?!.,:;*_'\"~()&]+|\\([^)]*\\)|&(?![a-zA-Z0-9]+;$)|[?!.,:;*_'\"~)]+(?!$))+/,\n  del: /^(~~?)(?=[^\\s~])((?:\\\\.|[^\\\\])*?(?:\\\\.|[^\\s~\\\\]))\\1(?=[^~]|$)/,\n  text: /^([`~]+|[^`~])(?:(?= {2,}\\n)|(?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)|[\\s\\S]*?(?:(?=[\\\\<!\\[`*~_]|\\b_|https?:\\/\\/|ftp:\\/\\/|www\\.|$)|[^ ](?= {2,}\\n)|[^a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-](?=[a-zA-Z0-9.!#$%&'*+\\/=?_`{\\|}~-]+@)))/,\n};\n\n/**\n * GFM + Line Breaks Inline Grammar\n */\n\nconst inlineBreaks: Record<InlineKeys, RegExp> = {\n  ...inlineGfm,\n  br: edit(br).replace('{2,}', '*').getRegex(),\n  text: edit(inlineGfm.text)\n    .replace('\\\\b_', '\\\\b_| {2,}\\\\n')\n    .replace(/\\{2,\\}/g, '*')\n    .getRegex(),\n};\n\n/**\n * exports\n */\n\nexport const block = {\n  normal: blockNormal,\n  gfm: blockGfm,\n  pedantic: blockPedantic,\n};\n\nexport const inline = {\n  normal: inlineNormal,\n  gfm: inlineGfm,\n  breaks: inlineBreaks,\n  pedantic: inlinePedantic,\n};\n\nexport interface Rules {\n  other: typeof other\n  block: Record<BlockKeys, RegExp>\n  inline: Record<InlineKeys, RegExp>\n}\n","import { other } from './rules.ts';\n\n/**\n * Helpers\n */\nconst escapeReplacements: { [index: string]: string } = {\n  '&': '&amp;',\n  '<': '&lt;',\n  '>': '&gt;',\n  '\"': '&quot;',\n  \"'\": '&#39;',\n};\nconst getEscapeReplacement = (ch: string) => escapeReplacements[ch];\n\nexport function escape(html: string, encode?: boolean) {\n  if (encode) {\n    if (other.escapeTest.test(html)) {\n      return html.replace(other.escapeReplace, getEscapeReplacement);\n    }\n  } else {\n    if (other.escapeTestNoEncode.test(html)) {\n      return html.replace(other.escapeReplaceNoEncode, getEscapeReplacement);\n    }\n  }\n\n  return html;\n}\n\nexport function unescape(html: string) {\n  // explicitly match decimal, hex, and named HTML entities\n  return html.replace(other.unescapeTest, (_, n) => {\n    n = n.toLowerCase();\n    if (n === 'colon') return ':';\n    if (n.charAt(0) === '#') {\n      return n.charAt(1) === 'x'\n        ? String.fromCharCode(parseInt(n.substring(2), 16))\n        : String.fromCharCode(+n.substring(1));\n    }\n    return '';\n  });\n}\n\nexport function cleanUrl(href: string) {\n  try {\n    href = encodeURI(href).replace(other.percentDecode, '%');\n  } catch {\n    return null;\n  }\n  return href;\n}\n\nexport function splitCells(tableRow: string, count?: number) {\n  // ensure that every cell-delimiting pipe has a space\n  // before it to distinguish it from an escaped pipe\n  const row = tableRow.replace(other.findPipe, (match, offset, str) => {\n      let escaped = false;\n      let curr = offset;\n      while (--curr >= 0 && str[curr] === '\\\\') escaped = !escaped;\n      if (escaped) {\n        // odd number of slashes means | is escaped\n        // so we leave it alone\n        return '|';\n      } else {\n        // add space before unescaped |\n        return ' |';\n      }\n    }),\n    cells = row.split(other.splitPipe);\n  let i = 0;\n\n  // First/last cell in a row cannot be empty if it has no leading/trailing pipe\n  if (!cells[0].trim()) {\n    cells.shift();\n  }\n  if (cells.length > 0 && !cells.at(-1)?.trim()) {\n    cells.pop();\n  }\n\n  if (count) {\n    if (cells.length > count) {\n      cells.splice(count);\n    } else {\n      while (cells.length < count) cells.push('');\n    }\n  }\n\n  for (; i < cells.length; i++) {\n    // leading or trailing whitespace is ignored per the gfm spec\n    cells[i] = cells[i].trim().replace(other.slashPipe, '|');\n  }\n  return cells;\n}\n\n/**\n * Remove trailing 'c's. Equivalent to str.replace(/c*$/, '').\n * /c*$/ is vulnerable to REDOS.\n *\n * @param str\n * @param c\n * @param invert Remove suffix of non-c chars instead. Default falsey.\n */\nexport function rtrim(str: string, c: string, invert?: boolean) {\n  const l = str.length;\n  if (l === 0) {\n    return '';\n  }\n\n  // Length of suffix matching the invert condition.\n  let suffLen = 0;\n\n  // Step left until we fail to match the invert condition.\n  while (suffLen < l) {\n    const currChar = str.charAt(l - suffLen - 1);\n    if (currChar === c && !invert) {\n      suffLen++;\n    } else if (currChar !== c && invert) {\n      suffLen++;\n    } else {\n      break;\n    }\n  }\n\n  return str.slice(0, l - suffLen);\n}\n\nexport function findClosingBracket(str: string, b: string) {\n  if (str.indexOf(b[1]) === -1) {\n    return -1;\n  }\n\n  let level = 0;\n  for (let i = 0; i < str.length; i++) {\n    if (str[i] === '\\\\') {\n      i++;\n    } else if (str[i] === b[0]) {\n      level++;\n    } else if (str[i] === b[1]) {\n      level--;\n      if (level < 0) {\n        return i;\n      }\n    }\n  }\n  if (level > 0) {\n    return -2;\n  }\n\n  return -1;\n}\n","import { _defaults } from './defaults.ts';\nimport {\n  rtrim,\n  splitCells,\n  findClosingBracket,\n} from './helpers.ts';\nimport type { Rules } from './rules.ts';\nimport type { _Lexer } from './Lexer.ts';\nimport type { Links, Tokens, Token } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\nfunction outputLink(cap: string[], link: Pick<Tokens.Link, 'href' | 'title'>, raw: string, lexer: _Lexer, rules: Rules): Tokens.Link | Tokens.Image {\n  const href = link.href;\n  const title = link.title || null;\n  const text = cap[1].replace(rules.other.outputLinkReplace, '$1');\n\n  lexer.state.inLink = true;\n  const token: Tokens.Link | Tokens.Image = {\n    type: cap[0].charAt(0) === '!' ? 'image' : 'link',\n    raw,\n    href,\n    title,\n    text,\n    tokens: lexer.inlineTokens(text),\n  };\n  lexer.state.inLink = false;\n  return token;\n}\n\nfunction indentCodeCompensation(raw: string, text: string, rules: Rules) {\n  const matchIndentToCode = raw.match(rules.other.indentCodeCompensation);\n\n  if (matchIndentToCode === null) {\n    return text;\n  }\n\n  const indentToCode = matchIndentToCode[1];\n\n  return text\n    .split('\\n')\n    .map(node => {\n      const matchIndentInNode = node.match(rules.other.beginningSpace);\n      if (matchIndentInNode === null) {\n        return node;\n      }\n\n      const [indentInNode] = matchIndentInNode;\n\n      if (indentInNode.length >= indentToCode.length) {\n        return node.slice(indentToCode.length);\n      }\n\n      return node;\n    })\n    .join('\\n');\n}\n\n/**\n * Tokenizer\n */\nexport class _Tokenizer {\n  options: MarkedOptions;\n  rules!: Rules; // set by the lexer\n  lexer!: _Lexer; // set by the lexer\n\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n  }\n\n  space(src: string): Tokens.Space | undefined {\n    const cap = this.rules.block.newline.exec(src);\n    if (cap && cap[0].length > 0) {\n      return {\n        type: 'space',\n        raw: cap[0],\n      };\n    }\n  }\n\n  code(src: string): Tokens.Code | undefined {\n    const cap = this.rules.block.code.exec(src);\n    if (cap) {\n      const text = cap[0].replace(this.rules.other.codeRemoveIndent, '');\n      return {\n        type: 'code',\n        raw: cap[0],\n        codeBlockStyle: 'indented',\n        text: !this.options.pedantic\n          ? rtrim(text, '\\n')\n          : text,\n      };\n    }\n  }\n\n  fences(src: string): Tokens.Code | undefined {\n    const cap = this.rules.block.fences.exec(src);\n    if (cap) {\n      const raw = cap[0];\n      const text = indentCodeCompensation(raw, cap[3] || '', this.rules);\n\n      return {\n        type: 'code',\n        raw,\n        lang: cap[2] ? cap[2].trim().replace(this.rules.inline.anyPunctuation, '$1') : cap[2],\n        text,\n      };\n    }\n  }\n\n  heading(src: string): Tokens.Heading | undefined {\n    const cap = this.rules.block.heading.exec(src);\n    if (cap) {\n      let text = cap[2].trim();\n\n      // remove trailing #s\n      if (this.rules.other.endingHash.test(text)) {\n        const trimmed = rtrim(text, '#');\n        if (this.options.pedantic) {\n          text = trimmed.trim();\n        } else if (!trimmed || this.rules.other.endingSpaceChar.test(trimmed)) {\n          // CommonMark requires space before trailing #s\n          text = trimmed.trim();\n        }\n      }\n\n      return {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[1].length,\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n\n  hr(src: string): Tokens.Hr | undefined {\n    const cap = this.rules.block.hr.exec(src);\n    if (cap) {\n      return {\n        type: 'hr',\n        raw: rtrim(cap[0], '\\n'),\n      };\n    }\n  }\n\n  blockquote(src: string): Tokens.Blockquote | undefined {\n    const cap = this.rules.block.blockquote.exec(src);\n    if (cap) {\n      let lines = rtrim(cap[0], '\\n').split('\\n');\n      let raw = '';\n      let text = '';\n      const tokens: Token[] = [];\n\n      while (lines.length > 0) {\n        let inBlockquote = false;\n        const currentLines = [];\n\n        let i;\n        for (i = 0; i < lines.length; i++) {\n          // get lines up to a continuation\n          if (this.rules.other.blockquoteStart.test(lines[i])) {\n            currentLines.push(lines[i]);\n            inBlockquote = true;\n          } else if (!inBlockquote) {\n            currentLines.push(lines[i]);\n          } else {\n            break;\n          }\n        }\n        lines = lines.slice(i);\n\n        const currentRaw = currentLines.join('\\n');\n        const currentText = currentRaw\n          // precede setext continuation with 4 spaces so it isn't a setext\n          .replace(this.rules.other.blockquoteSetextReplace, '\\n    $1')\n          .replace(this.rules.other.blockquoteSetextReplace2, '');\n        raw = raw ? `${raw}\\n${currentRaw}` : currentRaw;\n        text = text ? `${text}\\n${currentText}` : currentText;\n\n        // parse blockquote lines as top level tokens\n        // merge paragraphs if this is a continuation\n        const top = this.lexer.state.top;\n        this.lexer.state.top = true;\n        this.lexer.blockTokens(currentText, tokens, true);\n        this.lexer.state.top = top;\n\n        // if there is no continuation then we are done\n        if (lines.length === 0) {\n          break;\n        }\n\n        const lastToken = tokens.at(-1);\n\n        if (lastToken?.type === 'code') {\n          // blockquote continuation cannot be preceded by a code block\n          break;\n        } else if (lastToken?.type === 'blockquote') {\n          // include continuation in nested blockquote\n          const oldToken = lastToken as Tokens.Blockquote;\n          const newText = oldToken.raw + '\\n' + lines.join('\\n');\n          const newToken = this.blockquote(newText)!;\n          tokens[tokens.length - 1] = newToken;\n\n          raw = raw.substring(0, raw.length - oldToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.text.length) + newToken.text;\n          break;\n        } else if (lastToken?.type === 'list') {\n          // include continuation in nested list\n          const oldToken = lastToken as Tokens.List;\n          const newText = oldToken.raw + '\\n' + lines.join('\\n');\n          const newToken = this.list(newText)!;\n          tokens[tokens.length - 1] = newToken;\n\n          raw = raw.substring(0, raw.length - lastToken.raw.length) + newToken.raw;\n          text = text.substring(0, text.length - oldToken.raw.length) + newToken.raw;\n          lines = newText.substring(tokens.at(-1)!.raw.length).split('\\n');\n          continue;\n        }\n      }\n\n      return {\n        type: 'blockquote',\n        raw,\n        tokens,\n        text,\n      };\n    }\n  }\n\n  list(src: string): Tokens.List | undefined {\n    let cap = this.rules.block.list.exec(src);\n    if (cap) {\n      let bull = cap[1].trim();\n      const isordered = bull.length > 1;\n\n      const list: Tokens.List = {\n        type: 'list',\n        raw: '',\n        ordered: isordered,\n        start: isordered ? +bull.slice(0, -1) : '',\n        loose: false,\n        items: [],\n      };\n\n      bull = isordered ? `\\\\d{1,9}\\\\${bull.slice(-1)}` : `\\\\${bull}`;\n\n      if (this.options.pedantic) {\n        bull = isordered ? bull : '[*+-]';\n      }\n\n      // Get next list item\n      const itemRegex = this.rules.other.listItemRegex(bull);\n      let endsWithBlankLine = false;\n      // Check if current bullet point can start a new List Item\n      while (src) {\n        let endEarly = false;\n        let raw = '';\n        let itemContents = '';\n        if (!(cap = itemRegex.exec(src))) {\n          break;\n        }\n\n        if (this.rules.block.hr.test(src)) { // End list if bullet was actually HR (possibly move into itemRegex?)\n          break;\n        }\n\n        raw = cap[0];\n        src = src.substring(raw.length);\n\n        let line = cap[2].split('\\n', 1)[0].replace(this.rules.other.listReplaceTabs, (t: string) => ' '.repeat(3 * t.length));\n        let nextLine = src.split('\\n', 1)[0];\n        let blankLine = !line.trim();\n\n        let indent = 0;\n        if (this.options.pedantic) {\n          indent = 2;\n          itemContents = line.trimStart();\n        } else if (blankLine) {\n          indent = cap[1].length + 1;\n        } else {\n          indent = cap[2].search(this.rules.other.nonSpaceChar); // Find first non-space char\n          indent = indent > 4 ? 1 : indent; // Treat indented code blocks (> 4 spaces) as having only 1 indent\n          itemContents = line.slice(indent);\n          indent += cap[1].length;\n        }\n\n        if (blankLine && this.rules.other.blankLine.test(nextLine)) { // Items begin with at most one blank line\n          raw += nextLine + '\\n';\n          src = src.substring(nextLine.length + 1);\n          endEarly = true;\n        }\n\n        if (!endEarly) {\n          const nextBulletRegex = this.rules.other.nextBulletRegex(indent);\n          const hrRegex = this.rules.other.hrRegex(indent);\n          const fencesBeginRegex = this.rules.other.fencesBeginRegex(indent);\n          const headingBeginRegex = this.rules.other.headingBeginRegex(indent);\n          const htmlBeginRegex = this.rules.other.htmlBeginRegex(indent);\n\n          // Check if following lines should be included in List Item\n          while (src) {\n            const rawLine = src.split('\\n', 1)[0];\n            let nextLineWithoutTabs;\n            nextLine = rawLine;\n\n            // Re-align to follow commonmark nesting rules\n            if (this.options.pedantic) {\n              nextLine = nextLine.replace(this.rules.other.listReplaceNesting, '  ');\n              nextLineWithoutTabs = nextLine;\n            } else {\n              nextLineWithoutTabs = nextLine.replace(this.rules.other.tabCharGlobal, '    ');\n            }\n\n            // End list item if found code fences\n            if (fencesBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of new heading\n            if (headingBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of html block\n            if (htmlBeginRegex.test(nextLine)) {\n              break;\n            }\n\n            // End list item if found start of new bullet\n            if (nextBulletRegex.test(nextLine)) {\n              break;\n            }\n\n            // Horizontal rule found\n            if (hrRegex.test(nextLine)) {\n              break;\n            }\n\n            if (nextLineWithoutTabs.search(this.rules.other.nonSpaceChar) >= indent || !nextLine.trim()) { // Dedent if possible\n              itemContents += '\\n' + nextLineWithoutTabs.slice(indent);\n            } else {\n              // not enough indentation\n              if (blankLine) {\n                break;\n              }\n\n              // paragraph continuation unless last line was a different block level element\n              if (line.replace(this.rules.other.tabCharGlobal, '    ').search(this.rules.other.nonSpaceChar) >= 4) { // indented code block\n                break;\n              }\n              if (fencesBeginRegex.test(line)) {\n                break;\n              }\n              if (headingBeginRegex.test(line)) {\n                break;\n              }\n              if (hrRegex.test(line)) {\n                break;\n              }\n\n              itemContents += '\\n' + nextLine;\n            }\n\n            if (!blankLine && !nextLine.trim()) { // Check if current line is blank\n              blankLine = true;\n            }\n\n            raw += rawLine + '\\n';\n            src = src.substring(rawLine.length + 1);\n            line = nextLineWithoutTabs.slice(indent);\n          }\n        }\n\n        if (!list.loose) {\n          // If the previous item ended with a blank line, the list is loose\n          if (endsWithBlankLine) {\n            list.loose = true;\n          } else if (this.rules.other.doubleBlankLine.test(raw)) {\n            endsWithBlankLine = true;\n          }\n        }\n\n        let istask: RegExpExecArray | null = null;\n        let ischecked: boolean | undefined;\n        // Check for task list items\n        if (this.options.gfm) {\n          istask = this.rules.other.listIsTask.exec(itemContents);\n          if (istask) {\n            ischecked = istask[0] !== '[ ] ';\n            itemContents = itemContents.replace(this.rules.other.listReplaceTask, '');\n          }\n        }\n\n        list.items.push({\n          type: 'list_item',\n          raw,\n          task: !!istask,\n          checked: ischecked,\n          loose: false,\n          text: itemContents,\n          tokens: [],\n        });\n\n        list.raw += raw;\n      }\n\n      // Do not consume newlines at end of final item. Alternatively, make itemRegex *start* with any newlines to simplify/speed up endsWithBlankLine logic\n      const lastItem = list.items.at(-1);\n      if (lastItem) {\n        lastItem.raw = lastItem.raw.trimEnd();\n        lastItem.text = lastItem.text.trimEnd();\n      } else {\n        // not a list since there were no items\n        return;\n      }\n      list.raw = list.raw.trimEnd();\n\n      // Item child tokens handled here at end because we needed to have the final item to trim it first\n      for (let i = 0; i < list.items.length; i++) {\n        this.lexer.state.top = false;\n        list.items[i].tokens = this.lexer.blockTokens(list.items[i].text, []);\n\n        if (!list.loose) {\n          // Check if list should be loose\n          const spacers = list.items[i].tokens.filter(t => t.type === 'space');\n          const hasMultipleLineBreaks = spacers.length > 0 && spacers.some(t => this.rules.other.anyLine.test(t.raw));\n\n          list.loose = hasMultipleLineBreaks;\n        }\n      }\n\n      // Set all items to loose if list is loose\n      if (list.loose) {\n        for (let i = 0; i < list.items.length; i++) {\n          list.items[i].loose = true;\n        }\n      }\n\n      return list;\n    }\n  }\n\n  html(src: string): Tokens.HTML | undefined {\n    const cap = this.rules.block.html.exec(src);\n    if (cap) {\n      const token: Tokens.HTML = {\n        type: 'html',\n        block: true,\n        raw: cap[0],\n        pre: cap[1] === 'pre' || cap[1] === 'script' || cap[1] === 'style',\n        text: cap[0],\n      };\n      return token;\n    }\n  }\n\n  def(src: string): Tokens.Def | undefined {\n    const cap = this.rules.block.def.exec(src);\n    if (cap) {\n      const tag = cap[1].toLowerCase().replace(this.rules.other.multipleSpaceGlobal, ' ');\n      const href = cap[2] ? cap[2].replace(this.rules.other.hrefBrackets, '$1').replace(this.rules.inline.anyPunctuation, '$1') : '';\n      const title = cap[3] ? cap[3].substring(1, cap[3].length - 1).replace(this.rules.inline.anyPunctuation, '$1') : cap[3];\n      return {\n        type: 'def',\n        tag,\n        raw: cap[0],\n        href,\n        title,\n      };\n    }\n  }\n\n  table(src: string): Tokens.Table | undefined {\n    const cap = this.rules.block.table.exec(src);\n    if (!cap) {\n      return;\n    }\n\n    if (!this.rules.other.tableDelimiter.test(cap[2])) {\n      // delimiter row must have a pipe (|) or colon (:) otherwise it is a setext heading\n      return;\n    }\n\n    const headers = splitCells(cap[1]);\n    const aligns = cap[2].replace(this.rules.other.tableAlignChars, '').split('|');\n    const rows = cap[3]?.trim() ? cap[3].replace(this.rules.other.tableRowBlankLine, '').split('\\n') : [];\n\n    const item: Tokens.Table = {\n      type: 'table',\n      raw: cap[0],\n      header: [],\n      align: [],\n      rows: [],\n    };\n\n    if (headers.length !== aligns.length) {\n      // header and align columns must be equal, rows can be different.\n      return;\n    }\n\n    for (const align of aligns) {\n      if (this.rules.other.tableAlignRight.test(align)) {\n        item.align.push('right');\n      } else if (this.rules.other.tableAlignCenter.test(align)) {\n        item.align.push('center');\n      } else if (this.rules.other.tableAlignLeft.test(align)) {\n        item.align.push('left');\n      } else {\n        item.align.push(null);\n      }\n    }\n\n    for (let i = 0; i < headers.length; i++) {\n      item.header.push({\n        text: headers[i],\n        tokens: this.lexer.inline(headers[i]),\n        header: true,\n        align: item.align[i],\n      });\n    }\n\n    for (const row of rows) {\n      item.rows.push(splitCells(row, item.header.length).map((cell, i) => {\n        return {\n          text: cell,\n          tokens: this.lexer.inline(cell),\n          header: false,\n          align: item.align[i],\n        };\n      }));\n    }\n\n    return item;\n  }\n\n  lheading(src: string): Tokens.Heading | undefined {\n    const cap = this.rules.block.lheading.exec(src);\n    if (cap) {\n      return {\n        type: 'heading',\n        raw: cap[0],\n        depth: cap[2].charAt(0) === '=' ? 1 : 2,\n        text: cap[1],\n        tokens: this.lexer.inline(cap[1]),\n      };\n    }\n  }\n\n  paragraph(src: string): Tokens.Paragraph | undefined {\n    const cap = this.rules.block.paragraph.exec(src);\n    if (cap) {\n      const text = cap[1].charAt(cap[1].length - 1) === '\\n'\n        ? cap[1].slice(0, -1)\n        : cap[1];\n      return {\n        type: 'paragraph',\n        raw: cap[0],\n        text,\n        tokens: this.lexer.inline(text),\n      };\n    }\n  }\n\n  text(src: string): Tokens.Text | undefined {\n    const cap = this.rules.block.text.exec(src);\n    if (cap) {\n      return {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        tokens: this.lexer.inline(cap[0]),\n      };\n    }\n  }\n\n  escape(src: string): Tokens.Escape | undefined {\n    const cap = this.rules.inline.escape.exec(src);\n    if (cap) {\n      return {\n        type: 'escape',\n        raw: cap[0],\n        text: cap[1],\n      };\n    }\n  }\n\n  tag(src: string): Tokens.Tag | undefined {\n    const cap = this.rules.inline.tag.exec(src);\n    if (cap) {\n      if (!this.lexer.state.inLink && this.rules.other.startATag.test(cap[0])) {\n        this.lexer.state.inLink = true;\n      } else if (this.lexer.state.inLink && this.rules.other.endATag.test(cap[0])) {\n        this.lexer.state.inLink = false;\n      }\n      if (!this.lexer.state.inRawBlock && this.rules.other.startPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = true;\n      } else if (this.lexer.state.inRawBlock && this.rules.other.endPreScriptTag.test(cap[0])) {\n        this.lexer.state.inRawBlock = false;\n      }\n\n      return {\n        type: 'html',\n        raw: cap[0],\n        inLink: this.lexer.state.inLink,\n        inRawBlock: this.lexer.state.inRawBlock,\n        block: false,\n        text: cap[0],\n      };\n    }\n  }\n\n  link(src: string): Tokens.Link | Tokens.Image | undefined {\n    const cap = this.rules.inline.link.exec(src);\n    if (cap) {\n      const trimmedUrl = cap[2].trim();\n      if (!this.options.pedantic && this.rules.other.startAngleBracket.test(trimmedUrl)) {\n        // commonmark requires matching angle brackets\n        if (!(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n          return;\n        }\n\n        // ending angle bracket cannot be escaped\n        const rtrimSlash = rtrim(trimmedUrl.slice(0, -1), '\\\\');\n        if ((trimmedUrl.length - rtrimSlash.length) % 2 === 0) {\n          return;\n        }\n      } else {\n        // find closing parenthesis\n        const lastParenIndex = findClosingBracket(cap[2], '()');\n        if (lastParenIndex === -2) {\n          // more open parens than closed\n          return;\n        }\n\n        if (lastParenIndex > -1) {\n          const start = cap[0].indexOf('!') === 0 ? 5 : 4;\n          const linkLen = start + cap[1].length + lastParenIndex;\n          cap[2] = cap[2].substring(0, lastParenIndex);\n          cap[0] = cap[0].substring(0, linkLen).trim();\n          cap[3] = '';\n        }\n      }\n      let href = cap[2];\n      let title = '';\n      if (this.options.pedantic) {\n        // split pedantic href and title\n        const link = this.rules.other.pedanticHrefTitle.exec(href);\n\n        if (link) {\n          href = link[1];\n          title = link[3];\n        }\n      } else {\n        title = cap[3] ? cap[3].slice(1, -1) : '';\n      }\n\n      href = href.trim();\n      if (this.rules.other.startAngleBracket.test(href)) {\n        if (this.options.pedantic && !(this.rules.other.endAngleBracket.test(trimmedUrl))) {\n          // pedantic allows starting angle bracket without ending angle bracket\n          href = href.slice(1);\n        } else {\n          href = href.slice(1, -1);\n        }\n      }\n      return outputLink(cap, {\n        href: href ? href.replace(this.rules.inline.anyPunctuation, '$1') : href,\n        title: title ? title.replace(this.rules.inline.anyPunctuation, '$1') : title,\n      }, cap[0], this.lexer, this.rules);\n    }\n  }\n\n  reflink(src: string, links: Links): Tokens.Link | Tokens.Image | Tokens.Text | undefined {\n    let cap;\n    if ((cap = this.rules.inline.reflink.exec(src))\n      || (cap = this.rules.inline.nolink.exec(src))) {\n      const linkString = (cap[2] || cap[1]).replace(this.rules.other.multipleSpaceGlobal, ' ');\n      const link = links[linkString.toLowerCase()];\n      if (!link) {\n        const text = cap[0].charAt(0);\n        return {\n          type: 'text',\n          raw: text,\n          text,\n        };\n      }\n      return outputLink(cap, link, cap[0], this.lexer, this.rules);\n    }\n  }\n\n  emStrong(src: string, maskedSrc: string, prevChar = ''): Tokens.Em | Tokens.Strong | undefined {\n    let match = this.rules.inline.emStrongLDelim.exec(src);\n    if (!match) return;\n\n    // _ can't be between two alphanumerics. \\p{L}\\p{N} includes non-english alphabet/numbers as well\n    if (match[3] && prevChar.match(this.rules.other.unicodeAlphaNumeric)) return;\n\n    const nextChar = match[1] || match[2] || '';\n\n    if (!nextChar || !prevChar || this.rules.inline.punctuation.exec(prevChar)) {\n      // unicode Regex counts emoji as 1 char; spread into array for proper count (used multiple times below)\n      const lLength = [...match[0]].length - 1;\n      let rDelim, rLength, delimTotal = lLength, midDelimTotal = 0;\n\n      const endReg = match[0][0] === '*' ? this.rules.inline.emStrongRDelimAst : this.rules.inline.emStrongRDelimUnd;\n      endReg.lastIndex = 0;\n\n      // Clip maskedSrc to same section of string as src (move to lexer?)\n      maskedSrc = maskedSrc.slice(-1 * src.length + lLength);\n\n      while ((match = endReg.exec(maskedSrc)) != null) {\n        rDelim = match[1] || match[2] || match[3] || match[4] || match[5] || match[6];\n\n        if (!rDelim) continue; // skip single * in __abc*abc__\n\n        rLength = [...rDelim].length;\n\n        if (match[3] || match[4]) { // found another Left Delim\n          delimTotal += rLength;\n          continue;\n        } else if (match[5] || match[6]) { // either Left or Right Delim\n          if (lLength % 3 && !((lLength + rLength) % 3)) {\n            midDelimTotal += rLength;\n            continue; // CommonMark Emphasis Rules 9-10\n          }\n        }\n\n        delimTotal -= rLength;\n\n        if (delimTotal > 0) continue; // Haven't found enough closing delimiters\n\n        // Remove extra characters. *a*** -> *a*\n        rLength = Math.min(rLength, rLength + delimTotal + midDelimTotal);\n        // char length can be >1 for unicode characters;\n        const lastCharLength = [...match[0]][0].length;\n        const raw = src.slice(0, lLength + match.index + lastCharLength + rLength);\n\n        // Create `em` if smallest delimiter has odd char count. *a***\n        if (Math.min(lLength, rLength) % 2) {\n          const text = raw.slice(1, -1);\n          return {\n            type: 'em',\n            raw,\n            text,\n            tokens: this.lexer.inlineTokens(text),\n          };\n        }\n\n        // Create 'strong' if smallest delimiter has even char count. **a***\n        const text = raw.slice(2, -2);\n        return {\n          type: 'strong',\n          raw,\n          text,\n          tokens: this.lexer.inlineTokens(text),\n        };\n      }\n    }\n  }\n\n  codespan(src: string): Tokens.Codespan | undefined {\n    const cap = this.rules.inline.code.exec(src);\n    if (cap) {\n      let text = cap[2].replace(this.rules.other.newLineCharGlobal, ' ');\n      const hasNonSpaceChars = this.rules.other.nonSpaceChar.test(text);\n      const hasSpaceCharsOnBothEnds = this.rules.other.startingSpaceChar.test(text) && this.rules.other.endingSpaceChar.test(text);\n      if (hasNonSpaceChars && hasSpaceCharsOnBothEnds) {\n        text = text.substring(1, text.length - 1);\n      }\n      return {\n        type: 'codespan',\n        raw: cap[0],\n        text,\n      };\n    }\n  }\n\n  br(src: string): Tokens.Br | undefined {\n    const cap = this.rules.inline.br.exec(src);\n    if (cap) {\n      return {\n        type: 'br',\n        raw: cap[0],\n      };\n    }\n  }\n\n  del(src: string): Tokens.Del | undefined {\n    const cap = this.rules.inline.del.exec(src);\n    if (cap) {\n      return {\n        type: 'del',\n        raw: cap[0],\n        text: cap[2],\n        tokens: this.lexer.inlineTokens(cap[2]),\n      };\n    }\n  }\n\n  autolink(src: string): Tokens.Link | undefined {\n    const cap = this.rules.inline.autolink.exec(src);\n    if (cap) {\n      let text, href;\n      if (cap[2] === '@') {\n        text = cap[1];\n        href = 'mailto:' + text;\n      } else {\n        text = cap[1];\n        href = text;\n      }\n\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: 'text',\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n\n  url(src: string): Tokens.Link | undefined {\n    let cap;\n    if (cap = this.rules.inline.url.exec(src)) {\n      let text, href;\n      if (cap[2] === '@') {\n        text = cap[0];\n        href = 'mailto:' + text;\n      } else {\n        // do extended autolink path validation\n        let prevCapZero;\n        do {\n          prevCapZero = cap[0];\n          cap[0] = this.rules.inline._backpedal.exec(cap[0])?.[0] ?? '';\n        } while (prevCapZero !== cap[0]);\n        text = cap[0];\n        if (cap[1] === 'www.') {\n          href = 'http://' + cap[0];\n        } else {\n          href = cap[0];\n        }\n      }\n      return {\n        type: 'link',\n        raw: cap[0],\n        text,\n        href,\n        tokens: [\n          {\n            type: 'text',\n            raw: text,\n            text,\n          },\n        ],\n      };\n    }\n  }\n\n  inlineText(src: string): Tokens.Text | undefined {\n    const cap = this.rules.inline.text.exec(src);\n    if (cap) {\n      const escaped = this.lexer.state.inRawBlock;\n      return {\n        type: 'text',\n        raw: cap[0],\n        text: cap[0],\n        escaped,\n      };\n    }\n  }\n}\n","import { _Tokenizer } from './Tokenizer.ts';\nimport { _defaults } from './defaults.ts';\nimport { other, block, inline } from './rules.ts';\nimport type { Token, TokensList, Tokens } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Block Lexer\n */\nexport class _Lexer {\n  tokens: TokensList;\n  options: MarkedOptions;\n  state: {\n    inLink: boolean;\n    inRawBlock: boolean;\n    top: boolean;\n  };\n\n  private tokenizer: _Tokenizer;\n  private inlineQueue: { src: string, tokens: Token[] }[];\n\n  constructor(options?: MarkedOptions) {\n    // TokenList cannot be created in one go\n    this.tokens = [] as unknown as TokensList;\n    this.tokens.links = Object.create(null);\n    this.options = options || _defaults;\n    this.options.tokenizer = this.options.tokenizer || new _Tokenizer();\n    this.tokenizer = this.options.tokenizer;\n    this.tokenizer.options = this.options;\n    this.tokenizer.lexer = this;\n    this.inlineQueue = [];\n    this.state = {\n      inLink: false,\n      inRawBlock: false,\n      top: true,\n    };\n\n    const rules = {\n      other,\n      block: block.normal,\n      inline: inline.normal,\n    };\n\n    if (this.options.pedantic) {\n      rules.block = block.pedantic;\n      rules.inline = inline.pedantic;\n    } else if (this.options.gfm) {\n      rules.block = block.gfm;\n      if (this.options.breaks) {\n        rules.inline = inline.breaks;\n      } else {\n        rules.inline = inline.gfm;\n      }\n    }\n    this.tokenizer.rules = rules;\n  }\n\n  /**\n   * Expose Rules\n   */\n  static get rules() {\n    return {\n      block,\n      inline,\n    };\n  }\n\n  /**\n   * Static Lex Method\n   */\n  static lex(src: string, options?: MarkedOptions) {\n    const lexer = new _Lexer(options);\n    return lexer.lex(src);\n  }\n\n  /**\n   * Static Lex Inline Method\n   */\n  static lexInline(src: string, options?: MarkedOptions) {\n    const lexer = new _Lexer(options);\n    return lexer.inlineTokens(src);\n  }\n\n  /**\n   * Preprocessing\n   */\n  lex(src: string) {\n    src = src.replace(other.carriageReturn, '\\n');\n\n    this.blockTokens(src, this.tokens);\n\n    for (let i = 0; i < this.inlineQueue.length; i++) {\n      const next = this.inlineQueue[i];\n      this.inlineTokens(next.src, next.tokens);\n    }\n    this.inlineQueue = [];\n\n    return this.tokens;\n  }\n\n  /**\n   * Lexing\n   */\n  blockTokens(src: string, tokens?: Token[], lastParagraphClipped?: boolean): Token[];\n  blockTokens(src: string, tokens?: TokensList, lastParagraphClipped?: boolean): TokensList;\n  blockTokens(src: string, tokens: Token[] = [], lastParagraphClipped = false) {\n    if (this.options.pedantic) {\n      src = src.replace(other.tabCharGlobal, '    ').replace(other.spaceLine, '');\n    }\n\n    while (src) {\n      let token: Tokens.Generic | undefined;\n\n      if (this.options.extensions?.block?.some((extTokenizer) => {\n        if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n\n      // newline\n      if (token = this.tokenizer.space(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.raw.length === 1 && lastToken !== undefined) {\n          // if there's a single \\n as a spacer, it's terminating the last line,\n          // so move it there so that we don't get unnecessary paragraph tags\n          lastToken.raw += '\\n';\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // code\n      if (token = this.tokenizer.code(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        // An indented code block cannot interrupt a paragraph.\n        if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // fences\n      if (token = this.tokenizer.fences(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // heading\n      if (token = this.tokenizer.heading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // hr\n      if (token = this.tokenizer.hr(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // blockquote\n      if (token = this.tokenizer.blockquote(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // list\n      if (token = this.tokenizer.list(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // html\n      if (token = this.tokenizer.html(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // def\n      if (token = this.tokenizer.def(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'paragraph' || lastToken?.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.raw;\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else if (!this.tokens.links[token.tag]) {\n          this.tokens.links[token.tag] = {\n            href: token.href,\n            title: token.title,\n          };\n        }\n        continue;\n      }\n\n      // table (gfm)\n      if (token = this.tokenizer.table(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // lheading\n      if (token = this.tokenizer.lheading(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // top-level paragraph\n      // prevent paragraph consuming extensions by clipping 'src' to extension start\n      let cutSrc = src;\n      if (this.options.extensions?.startBlock) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startBlock.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (this.state.top && (token = this.tokenizer.paragraph(cutSrc))) {\n        const lastToken = tokens.at(-1);\n        if (lastParagraphClipped && lastToken?.type === 'paragraph') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        lastParagraphClipped = cutSrc.length !== src.length;\n        src = src.substring(token.raw.length);\n        continue;\n      }\n\n      // text\n      if (token = this.tokenizer.text(src)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'text') {\n          lastToken.raw += '\\n' + token.raw;\n          lastToken.text += '\\n' + token.text;\n          this.inlineQueue.pop();\n          this.inlineQueue.at(-1)!.src = lastToken.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    this.state.top = true;\n    return tokens;\n  }\n\n  inline(src: string, tokens: Token[] = []) {\n    this.inlineQueue.push({ src, tokens });\n    return tokens;\n  }\n\n  /**\n   * Lexing/Compiling\n   */\n  inlineTokens(src: string, tokens: Token[] = []): Token[] {\n    // String with links masked to avoid interference with em and strong\n    let maskedSrc = src;\n    let match: RegExpExecArray | null = null;\n\n    // Mask out reflinks\n    if (this.tokens.links) {\n      const links = Object.keys(this.tokens.links);\n      if (links.length > 0) {\n        while ((match = this.tokenizer.rules.inline.reflinkSearch.exec(maskedSrc)) != null) {\n          if (links.includes(match[0].slice(match[0].lastIndexOf('[') + 1, -1))) {\n            maskedSrc = maskedSrc.slice(0, match.index)\n              + '[' + 'a'.repeat(match[0].length - 2) + ']'\n              + maskedSrc.slice(this.tokenizer.rules.inline.reflinkSearch.lastIndex);\n          }\n        }\n      }\n    }\n\n    // Mask out escaped characters\n    while ((match = this.tokenizer.rules.inline.anyPunctuation.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '++' + maskedSrc.slice(this.tokenizer.rules.inline.anyPunctuation.lastIndex);\n    }\n\n    // Mask out other blocks\n    while ((match = this.tokenizer.rules.inline.blockSkip.exec(maskedSrc)) != null) {\n      maskedSrc = maskedSrc.slice(0, match.index) + '[' + 'a'.repeat(match[0].length - 2) + ']' + maskedSrc.slice(this.tokenizer.rules.inline.blockSkip.lastIndex);\n    }\n\n    let keepPrevChar = false;\n    let prevChar = '';\n    while (src) {\n      if (!keepPrevChar) {\n        prevChar = '';\n      }\n      keepPrevChar = false;\n\n      let token: Tokens.Generic | undefined;\n\n      // extensions\n      if (this.options.extensions?.inline?.some((extTokenizer) => {\n        if (token = extTokenizer.call({ lexer: this }, src, tokens)) {\n          src = src.substring(token.raw.length);\n          tokens.push(token);\n          return true;\n        }\n        return false;\n      })) {\n        continue;\n      }\n\n      // escape\n      if (token = this.tokenizer.escape(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // tag\n      if (token = this.tokenizer.tag(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // link\n      if (token = this.tokenizer.link(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // reflink, nolink\n      if (token = this.tokenizer.reflink(src, this.tokens.links)) {\n        src = src.substring(token.raw.length);\n        const lastToken = tokens.at(-1);\n        if (token.type === 'text' && lastToken?.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      // em & strong\n      if (token = this.tokenizer.emStrong(src, maskedSrc, prevChar)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // code\n      if (token = this.tokenizer.codespan(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // br\n      if (token = this.tokenizer.br(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // del (gfm)\n      if (token = this.tokenizer.del(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // autolink\n      if (token = this.tokenizer.autolink(src)) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // url (gfm)\n      if (!this.state.inLink && (token = this.tokenizer.url(src))) {\n        src = src.substring(token.raw.length);\n        tokens.push(token);\n        continue;\n      }\n\n      // text\n      // prevent inlineText consuming extensions by clipping 'src' to extension start\n      let cutSrc = src;\n      if (this.options.extensions?.startInline) {\n        let startIndex = Infinity;\n        const tempSrc = src.slice(1);\n        let tempStart;\n        this.options.extensions.startInline.forEach((getStartIndex) => {\n          tempStart = getStartIndex.call({ lexer: this }, tempSrc);\n          if (typeof tempStart === 'number' && tempStart >= 0) {\n            startIndex = Math.min(startIndex, tempStart);\n          }\n        });\n        if (startIndex < Infinity && startIndex >= 0) {\n          cutSrc = src.substring(0, startIndex + 1);\n        }\n      }\n      if (token = this.tokenizer.inlineText(cutSrc)) {\n        src = src.substring(token.raw.length);\n        if (token.raw.slice(-1) !== '_') { // Track prevChar before string of ____ started\n          prevChar = token.raw.slice(-1);\n        }\n        keepPrevChar = true;\n        const lastToken = tokens.at(-1);\n        if (lastToken?.type === 'text') {\n          lastToken.raw += token.raw;\n          lastToken.text += token.text;\n        } else {\n          tokens.push(token);\n        }\n        continue;\n      }\n\n      if (src) {\n        const errMsg = 'Infinite loop on byte: ' + src.charCodeAt(0);\n        if (this.options.silent) {\n          console.error(errMsg);\n          break;\n        } else {\n          throw new Error(errMsg);\n        }\n      }\n    }\n\n    return tokens;\n  }\n}\n","import { _defaults } from './defaults.ts';\nimport {\n  cleanUrl,\n  escape,\n} from './helpers.ts';\nimport { other } from './rules.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\nimport type { Tokens } from './Tokens.ts';\nimport type { _Parser } from './Parser.ts';\n\n/**\n * Renderer\n */\nexport class _Renderer {\n  options: MarkedOptions;\n  parser!: _Parser; // set by the parser\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n  }\n\n  space(token: Tokens.Space): string {\n    return '';\n  }\n\n  code({ text, lang, escaped }: Tokens.Code): string {\n    const langString = (lang || '').match(other.notSpaceStart)?.[0];\n\n    const code = text.replace(other.endingNewline, '') + '\\n';\n\n    if (!langString) {\n      return '<pre><code>'\n        + (escaped ? code : escape(code, true))\n        + '</code></pre>\\n';\n    }\n\n    return '<pre><code class=\"language-'\n      + escape(langString)\n      + '\">'\n      + (escaped ? code : escape(code, true))\n      + '</code></pre>\\n';\n  }\n\n  blockquote({ tokens }: Tokens.Blockquote): string {\n    const body = this.parser.parse(tokens);\n    return `<blockquote>\\n${body}</blockquote>\\n`;\n  }\n\n  html({ text }: Tokens.HTML | Tokens.Tag) : string {\n    return text;\n  }\n\n  heading({ tokens, depth }: Tokens.Heading): string {\n    return `<h${depth}>${this.parser.parseInline(tokens)}</h${depth}>\\n`;\n  }\n\n  hr(token: Tokens.Hr): string {\n    return '<hr>\\n';\n  }\n\n  list(token: Tokens.List): string {\n    const ordered = token.ordered;\n    const start = token.start;\n\n    let body = '';\n    for (let j = 0; j < token.items.length; j++) {\n      const item = token.items[j];\n      body += this.listitem(item);\n    }\n\n    const type = ordered ? 'ol' : 'ul';\n    const startAttr = (ordered && start !== 1) ? (' start=\"' + start + '\"') : '';\n    return '<' + type + startAttr + '>\\n' + body + '</' + type + '>\\n';\n  }\n\n  listitem(item: Tokens.ListItem): string {\n    let itemBody = '';\n    if (item.task) {\n      const checkbox = this.checkbox({ checked: !!item.checked });\n      if (item.loose) {\n        if (item.tokens[0]?.type === 'paragraph') {\n          item.tokens[0].text = checkbox + ' ' + item.tokens[0].text;\n          if (item.tokens[0].tokens && item.tokens[0].tokens.length > 0 && item.tokens[0].tokens[0].type === 'text') {\n            item.tokens[0].tokens[0].text = checkbox + ' ' + escape(item.tokens[0].tokens[0].text);\n            item.tokens[0].tokens[0].escaped = true;\n          }\n        } else {\n          item.tokens.unshift({\n            type: 'text',\n            raw: checkbox + ' ',\n            text: checkbox + ' ',\n            escaped: true,\n          });\n        }\n      } else {\n        itemBody += checkbox + ' ';\n      }\n    }\n\n    itemBody += this.parser.parse(item.tokens, !!item.loose);\n\n    return `<li>${itemBody}</li>\\n`;\n  }\n\n  checkbox({ checked }: Tokens.Checkbox): string {\n    return '<input '\n      + (checked ? 'checked=\"\" ' : '')\n      + 'disabled=\"\" type=\"checkbox\">';\n  }\n\n  paragraph({ tokens }: Tokens.Paragraph): string {\n    return `<p>${this.parser.parseInline(tokens)}</p>\\n`;\n  }\n\n  table(token: Tokens.Table): string {\n    let header = '';\n\n    // header\n    let cell = '';\n    for (let j = 0; j < token.header.length; j++) {\n      cell += this.tablecell(token.header[j]);\n    }\n    header += this.tablerow({ text: cell });\n\n    let body = '';\n    for (let j = 0; j < token.rows.length; j++) {\n      const row = token.rows[j];\n\n      cell = '';\n      for (let k = 0; k < row.length; k++) {\n        cell += this.tablecell(row[k]);\n      }\n\n      body += this.tablerow({ text: cell });\n    }\n    if (body) body = `<tbody>${body}</tbody>`;\n\n    return '<table>\\n'\n      + '<thead>\\n'\n      + header\n      + '</thead>\\n'\n      + body\n      + '</table>\\n';\n  }\n\n  tablerow({ text }: Tokens.TableRow): string {\n    return `<tr>\\n${text}</tr>\\n`;\n  }\n\n  tablecell(token: Tokens.TableCell): string {\n    const content = this.parser.parseInline(token.tokens);\n    const type = token.header ? 'th' : 'td';\n    const tag = token.align\n      ? `<${type} align=\"${token.align}\">`\n      : `<${type}>`;\n    return tag + content + `</${type}>\\n`;\n  }\n\n  /**\n   * span level renderer\n   */\n  strong({ tokens }: Tokens.Strong): string {\n    return `<strong>${this.parser.parseInline(tokens)}</strong>`;\n  }\n\n  em({ tokens }: Tokens.Em): string {\n    return `<em>${this.parser.parseInline(tokens)}</em>`;\n  }\n\n  codespan({ text }: Tokens.Codespan): string {\n    return `<code>${escape(text, true)}</code>`;\n  }\n\n  br(token: Tokens.Br): string {\n    return '<br>';\n  }\n\n  del({ tokens }: Tokens.Del): string {\n    return `<del>${this.parser.parseInline(tokens)}</del>`;\n  }\n\n  link({ href, title, tokens }: Tokens.Link): string {\n    const text = this.parser.parseInline(tokens);\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return text;\n    }\n    href = cleanHref;\n    let out = '<a href=\"' + href + '\"';\n    if (title) {\n      out += ' title=\"' + (escape(title)) + '\"';\n    }\n    out += '>' + text + '</a>';\n    return out;\n  }\n\n  image({ href, title, text, tokens }: Tokens.Image): string {\n    if (tokens) {\n      text = this.parser.parseInline(tokens, this.parser.textRenderer);\n    }\n    const cleanHref = cleanUrl(href);\n    if (cleanHref === null) {\n      return escape(text);\n    }\n    href = cleanHref;\n\n    let out = `<img src=\"${href}\" alt=\"${text}\"`;\n    if (title) {\n      out += ` title=\"${escape(title)}\"`;\n    }\n    out += '>';\n    return out;\n  }\n\n  text(token: Tokens.Text | Tokens.Escape) : string {\n    return 'tokens' in token && token.tokens\n      ? this.parser.parseInline(token.tokens)\n      : ('escaped' in token && token.escaped ? token.text : escape(token.text));\n  }\n}\n","import type { Tokens } from './Tokens.ts';\n\n/**\n * TextRenderer\n * returns only the textual part of the token\n */\nexport class _TextRenderer {\n  // no need for block level renderers\n  strong({ text }: Tokens.Strong) {\n    return text;\n  }\n\n  em({ text }: Tokens.Em) {\n    return text;\n  }\n\n  codespan({ text }: Tokens.Codespan) {\n    return text;\n  }\n\n  del({ text }: Tokens.Del) {\n    return text;\n  }\n\n  html({ text }: Tokens.HTML | Tokens.Tag) {\n    return text;\n  }\n\n  text({ text }: Tokens.Text | Tokens.Escape | Tokens.Tag) {\n    return text;\n  }\n\n  link({ text }: Tokens.Link) {\n    return '' + text;\n  }\n\n  image({ text }: Tokens.Image) {\n    return '' + text;\n  }\n\n  br() {\n    return '';\n  }\n}\n","import { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _defaults } from './defaults.ts';\nimport type { MarkedToken, Token, Tokens } from './Tokens.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\n\n/**\n * Parsing & Compiling\n */\nexport class _Parser {\n  options: MarkedOptions;\n  renderer: _Renderer;\n  textRenderer: _TextRenderer;\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n    this.options.renderer = this.options.renderer || new _Renderer();\n    this.renderer = this.options.renderer;\n    this.renderer.options = this.options;\n    this.renderer.parser = this;\n    this.textRenderer = new _TextRenderer();\n  }\n\n  /**\n   * Static Parse Method\n   */\n  static parse(tokens: Token[], options?: MarkedOptions) {\n    const parser = new _Parser(options);\n    return parser.parse(tokens);\n  }\n\n  /**\n   * Static Parse Inline Method\n   */\n  static parseInline(tokens: Token[], options?: MarkedOptions) {\n    const parser = new _Parser(options);\n    return parser.parseInline(tokens);\n  }\n\n  /**\n   * Parse Loop\n   */\n  parse(tokens: Token[], top = true): string {\n    let out = '';\n\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n\n      // Run any renderer extensions\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const genericToken = anyToken as Tokens.Generic;\n        const ret = this.options.extensions.renderers[genericToken.type].call({ parser: this }, genericToken);\n        if (ret !== false || !['space', 'hr', 'heading', 'code', 'table', 'blockquote', 'list', 'html', 'paragraph', 'text'].includes(genericToken.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      const token = anyToken as MarkedToken;\n\n      switch (token.type) {\n        case 'space': {\n          out += this.renderer.space(token);\n          continue;\n        }\n        case 'hr': {\n          out += this.renderer.hr(token);\n          continue;\n        }\n        case 'heading': {\n          out += this.renderer.heading(token);\n          continue;\n        }\n        case 'code': {\n          out += this.renderer.code(token);\n          continue;\n        }\n        case 'table': {\n          out += this.renderer.table(token);\n          continue;\n        }\n        case 'blockquote': {\n          out += this.renderer.blockquote(token);\n          continue;\n        }\n        case 'list': {\n          out += this.renderer.list(token);\n          continue;\n        }\n        case 'html': {\n          out += this.renderer.html(token);\n          continue;\n        }\n        case 'paragraph': {\n          out += this.renderer.paragraph(token);\n          continue;\n        }\n        case 'text': {\n          let textToken = token;\n          let body = this.renderer.text(textToken);\n          while (i + 1 < tokens.length && tokens[i + 1].type === 'text') {\n            textToken = tokens[++i] as Tokens.Text;\n            body += '\\n' + this.renderer.text(textToken);\n          }\n          if (top) {\n            out += this.renderer.paragraph({\n              type: 'paragraph',\n              raw: body,\n              text: body,\n              tokens: [{ type: 'text', raw: body, text: body, escaped: true }],\n            });\n          } else {\n            out += body;\n          }\n          continue;\n        }\n\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return '';\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n\n    return out;\n  }\n\n  /**\n   * Parse Inline Tokens\n   */\n  parseInline(tokens: Token[], renderer: _Renderer | _TextRenderer = this.renderer): string {\n    let out = '';\n\n    for (let i = 0; i < tokens.length; i++) {\n      const anyToken = tokens[i];\n\n      // Run any renderer extensions\n      if (this.options.extensions?.renderers?.[anyToken.type]) {\n        const ret = this.options.extensions.renderers[anyToken.type].call({ parser: this }, anyToken);\n        if (ret !== false || !['escape', 'html', 'link', 'image', 'strong', 'em', 'codespan', 'br', 'del', 'text'].includes(anyToken.type)) {\n          out += ret || '';\n          continue;\n        }\n      }\n\n      const token = anyToken as MarkedToken;\n\n      switch (token.type) {\n        case 'escape': {\n          out += renderer.text(token);\n          break;\n        }\n        case 'html': {\n          out += renderer.html(token);\n          break;\n        }\n        case 'link': {\n          out += renderer.link(token);\n          break;\n        }\n        case 'image': {\n          out += renderer.image(token);\n          break;\n        }\n        case 'strong': {\n          out += renderer.strong(token);\n          break;\n        }\n        case 'em': {\n          out += renderer.em(token);\n          break;\n        }\n        case 'codespan': {\n          out += renderer.codespan(token);\n          break;\n        }\n        case 'br': {\n          out += renderer.br(token);\n          break;\n        }\n        case 'del': {\n          out += renderer.del(token);\n          break;\n        }\n        case 'text': {\n          out += renderer.text(token);\n          break;\n        }\n        default: {\n          const errMsg = 'Token with \"' + token.type + '\" type was not found.';\n          if (this.options.silent) {\n            console.error(errMsg);\n            return '';\n          } else {\n            throw new Error(errMsg);\n          }\n        }\n      }\n    }\n    return out;\n  }\n}\n","import { _defaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport type { MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, TokensList } from './Tokens.ts';\n\nexport class _Hooks {\n  options: MarkedOptions;\n  block?: boolean;\n\n  constructor(options?: MarkedOptions) {\n    this.options = options || _defaults;\n  }\n\n  static passThroughHooks = new Set([\n    'preprocess',\n    'postprocess',\n    'processAllTokens',\n  ]);\n\n  /**\n   * Process markdown before marked\n   */\n  preprocess(markdown: string) {\n    return markdown;\n  }\n\n  /**\n   * Process HTML after marked is finished\n   */\n  postprocess(html: string) {\n    return html;\n  }\n\n  /**\n   * Process all tokens before walk tokens\n   */\n  processAllTokens(tokens: Token[] | TokensList) {\n    return tokens;\n  }\n\n  /**\n   * Provide function to tokenize markdown\n   */\n  provideLexer() {\n    return this.block ? _Lexer.lex : _Lexer.lexInline;\n  }\n\n  /**\n   * Provide function to parse tokens\n   */\n  provideParser() {\n    return this.block ? _Parser.parse : _Parser.parseInline;\n  }\n}\n","import { _getDefaults } from './defaults.ts';\nimport { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { escape } from './helpers.ts';\nimport type { MarkedExtension, MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, Tokens, TokensList } from './Tokens.ts';\n\nexport type MaybePromise = void | Promise<void>;\n\ntype UnknownFunction = (...args: unknown[]) => unknown;\ntype GenericRendererFunction = (...args: unknown[]) => string | false;\n\nexport class Marked {\n  defaults = _getDefaults();\n  options = this.setOptions;\n\n  parse = this.parseMarkdown(true);\n  parseInline = this.parseMarkdown(false);\n\n  Parser = _Parser;\n  Renderer = _Renderer;\n  TextRenderer = _TextRenderer;\n  Lexer = _Lexer;\n  Tokenizer = _Tokenizer;\n  Hooks = _Hooks;\n\n  constructor(...args: MarkedExtension[]) {\n    this.use(...args);\n  }\n\n  /**\n   * Run callback for every token\n   */\n  walkTokens(tokens: Token[] | TokensList, callback: (token: Token) => MaybePromise | MaybePromise[]) {\n    let values: MaybePromise[] = [];\n    for (const token of tokens) {\n      values = values.concat(callback.call(this, token));\n      switch (token.type) {\n        case 'table': {\n          const tableToken = token as Tokens.Table;\n          for (const cell of tableToken.header) {\n            values = values.concat(this.walkTokens(cell.tokens, callback));\n          }\n          for (const row of tableToken.rows) {\n            for (const cell of row) {\n              values = values.concat(this.walkTokens(cell.tokens, callback));\n            }\n          }\n          break;\n        }\n        case 'list': {\n          const listToken = token as Tokens.List;\n          values = values.concat(this.walkTokens(listToken.items, callback));\n          break;\n        }\n        default: {\n          const genericToken = token as Tokens.Generic;\n          if (this.defaults.extensions?.childTokens?.[genericToken.type]) {\n            this.defaults.extensions.childTokens[genericToken.type].forEach((childTokens) => {\n              const tokens = genericToken[childTokens].flat(Infinity) as Token[] | TokensList;\n              values = values.concat(this.walkTokens(tokens, callback));\n            });\n          } else if (genericToken.tokens) {\n            values = values.concat(this.walkTokens(genericToken.tokens, callback));\n          }\n        }\n      }\n    }\n    return values;\n  }\n\n  use(...args: MarkedExtension[]) {\n    const extensions: MarkedOptions['extensions'] = this.defaults.extensions || { renderers: {}, childTokens: {} };\n\n    args.forEach((pack) => {\n      // copy options to new object\n      const opts = { ...pack } as MarkedOptions;\n\n      // set async to true if it was set to true before\n      opts.async = this.defaults.async || opts.async || false;\n\n      // ==-- Parse \"addon\" extensions --== //\n      if (pack.extensions) {\n        pack.extensions.forEach((ext) => {\n          if (!ext.name) {\n            throw new Error('extension name required');\n          }\n          if ('renderer' in ext) { // Renderer extensions\n            const prevRenderer = extensions.renderers[ext.name];\n            if (prevRenderer) {\n              // Replace extension with func to run new extension but fall back if false\n              extensions.renderers[ext.name] = function(...args) {\n                let ret = ext.renderer.apply(this, args);\n                if (ret === false) {\n                  ret = prevRenderer.apply(this, args);\n                }\n                return ret;\n              };\n            } else {\n              extensions.renderers[ext.name] = ext.renderer;\n            }\n          }\n          if ('tokenizer' in ext) { // Tokenizer Extensions\n            if (!ext.level || (ext.level !== 'block' && ext.level !== 'inline')) {\n              throw new Error(\"extension level must be 'block' or 'inline'\");\n            }\n            const extLevel = extensions[ext.level];\n            if (extLevel) {\n              extLevel.unshift(ext.tokenizer);\n            } else {\n              extensions[ext.level] = [ext.tokenizer];\n            }\n            if (ext.start) { // Function to check for start of token\n              if (ext.level === 'block') {\n                if (extensions.startBlock) {\n                  extensions.startBlock.push(ext.start);\n                } else {\n                  extensions.startBlock = [ext.start];\n                }\n              } else if (ext.level === 'inline') {\n                if (extensions.startInline) {\n                  extensions.startInline.push(ext.start);\n                } else {\n                  extensions.startInline = [ext.start];\n                }\n              }\n            }\n          }\n          if ('childTokens' in ext && ext.childTokens) { // Child tokens to be visited by walkTokens\n            extensions.childTokens[ext.name] = ext.childTokens;\n          }\n        });\n        opts.extensions = extensions;\n      }\n\n      // ==-- Parse \"overwrite\" extensions --== //\n      if (pack.renderer) {\n        const renderer = this.defaults.renderer || new _Renderer(this.defaults);\n        for (const prop in pack.renderer) {\n          if (!(prop in renderer)) {\n            throw new Error(`renderer '${prop}' does not exist`);\n          }\n          if (['options', 'parser'].includes(prop)) {\n            // ignore options property\n            continue;\n          }\n          const rendererProp = prop as Exclude<keyof _Renderer, 'options' | 'parser'>;\n          const rendererFunc = pack.renderer[rendererProp] as GenericRendererFunction;\n          const prevRenderer = renderer[rendererProp] as GenericRendererFunction;\n          // Replace renderer with func to run extension, but fall back if false\n          renderer[rendererProp] = (...args: unknown[]) => {\n            let ret = rendererFunc.apply(renderer, args);\n            if (ret === false) {\n              ret = prevRenderer.apply(renderer, args);\n            }\n            return ret || '';\n          };\n        }\n        opts.renderer = renderer;\n      }\n      if (pack.tokenizer) {\n        const tokenizer = this.defaults.tokenizer || new _Tokenizer(this.defaults);\n        for (const prop in pack.tokenizer) {\n          if (!(prop in tokenizer)) {\n            throw new Error(`tokenizer '${prop}' does not exist`);\n          }\n          if (['options', 'rules', 'lexer'].includes(prop)) {\n            // ignore options, rules, and lexer properties\n            continue;\n          }\n          const tokenizerProp = prop as Exclude<keyof _Tokenizer, 'options' | 'rules' | 'lexer'>;\n          const tokenizerFunc = pack.tokenizer[tokenizerProp] as UnknownFunction;\n          const prevTokenizer = tokenizer[tokenizerProp] as UnknownFunction;\n          // Replace tokenizer with func to run extension, but fall back if false\n          // @ts-expect-error cannot type tokenizer function dynamically\n          tokenizer[tokenizerProp] = (...args: unknown[]) => {\n            let ret = tokenizerFunc.apply(tokenizer, args);\n            if (ret === false) {\n              ret = prevTokenizer.apply(tokenizer, args);\n            }\n            return ret;\n          };\n        }\n        opts.tokenizer = tokenizer;\n      }\n\n      // ==-- Parse Hooks extensions --== //\n      if (pack.hooks) {\n        const hooks = this.defaults.hooks || new _Hooks();\n        for (const prop in pack.hooks) {\n          if (!(prop in hooks)) {\n            throw new Error(`hook '${prop}' does not exist`);\n          }\n          if (['options', 'block'].includes(prop)) {\n            // ignore options and block properties\n            continue;\n          }\n          const hooksProp = prop as Exclude<keyof _Hooks, 'options' | 'block'>;\n          const hooksFunc = pack.hooks[hooksProp] as UnknownFunction;\n          const prevHook = hooks[hooksProp] as UnknownFunction;\n          if (_Hooks.passThroughHooks.has(prop)) {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (arg: unknown) => {\n              if (this.defaults.async) {\n                return Promise.resolve(hooksFunc.call(hooks, arg)).then(ret => {\n                  return prevHook.call(hooks, ret);\n                });\n              }\n\n              const ret = hooksFunc.call(hooks, arg);\n              return prevHook.call(hooks, ret);\n            };\n          } else {\n            // @ts-expect-error cannot type hook function dynamically\n            hooks[hooksProp] = (...args: unknown[]) => {\n              let ret = hooksFunc.apply(hooks, args);\n              if (ret === false) {\n                ret = prevHook.apply(hooks, args);\n              }\n              return ret;\n            };\n          }\n        }\n        opts.hooks = hooks;\n      }\n\n      // ==-- Parse WalkTokens extensions --== //\n      if (pack.walkTokens) {\n        const walkTokens = this.defaults.walkTokens;\n        const packWalktokens = pack.walkTokens;\n        opts.walkTokens = function(token) {\n          let values: MaybePromise[] = [];\n          values.push(packWalktokens.call(this, token));\n          if (walkTokens) {\n            values = values.concat(walkTokens.call(this, token));\n          }\n          return values;\n        };\n      }\n\n      this.defaults = { ...this.defaults, ...opts };\n    });\n\n    return this;\n  }\n\n  setOptions(opt: MarkedOptions) {\n    this.defaults = { ...this.defaults, ...opt };\n    return this;\n  }\n\n  lexer(src: string, options?: MarkedOptions) {\n    return _Lexer.lex(src, options ?? this.defaults);\n  }\n\n  parser(tokens: Token[], options?: MarkedOptions) {\n    return _Parser.parse(tokens, options ?? this.defaults);\n  }\n\n  private parseMarkdown(blockType: boolean) {\n    type overloadedParse = {\n      (src: string, options: MarkedOptions & { async: true }): Promise<string>;\n      (src: string, options: MarkedOptions & { async: false }): string;\n      (src: string, options?: MarkedOptions | null): string | Promise<string>;\n    };\n\n    // eslint-disable-next-line @typescript-eslint/no-explicit-any\n    const parse: overloadedParse = (src: string, options?: MarkedOptions | null): any => {\n      const origOpt = { ...options };\n      const opt = { ...this.defaults, ...origOpt };\n\n      const throwError = this.onError(!!opt.silent, !!opt.async);\n\n      // throw error if an extension set async to true but parse was called with async: false\n      if (this.defaults.async === true && origOpt.async === false) {\n        return throwError(new Error('marked(): The async option was set to true by an extension. Remove async: false from the parse options object to return a Promise.'));\n      }\n\n      // throw error in case of non string input\n      if (typeof src === 'undefined' || src === null) {\n        return throwError(new Error('marked(): input parameter is undefined or null'));\n      }\n      if (typeof src !== 'string') {\n        return throwError(new Error('marked(): input parameter is of type '\n          + Object.prototype.toString.call(src) + ', string expected'));\n      }\n\n      if (opt.hooks) {\n        opt.hooks.options = opt;\n        opt.hooks.block = blockType;\n      }\n\n      const lexer = opt.hooks ? opt.hooks.provideLexer() : (blockType ? _Lexer.lex : _Lexer.lexInline);\n      const parser = opt.hooks ? opt.hooks.provideParser() : (blockType ? _Parser.parse : _Parser.parseInline);\n\n      if (opt.async) {\n        return Promise.resolve(opt.hooks ? opt.hooks.preprocess(src) : src)\n          .then(src => lexer(src, opt))\n          .then(tokens => opt.hooks ? opt.hooks.processAllTokens(tokens) : tokens)\n          .then(tokens => opt.walkTokens ? Promise.all(this.walkTokens(tokens, opt.walkTokens)).then(() => tokens) : tokens)\n          .then(tokens => parser(tokens, opt))\n          .then(html => opt.hooks ? opt.hooks.postprocess(html) : html)\n          .catch(throwError);\n      }\n\n      try {\n        if (opt.hooks) {\n          src = opt.hooks.preprocess(src) as string;\n        }\n        let tokens = lexer(src, opt);\n        if (opt.hooks) {\n          tokens = opt.hooks.processAllTokens(tokens);\n        }\n        if (opt.walkTokens) {\n          this.walkTokens(tokens, opt.walkTokens);\n        }\n        let html = parser(tokens, opt);\n        if (opt.hooks) {\n          html = opt.hooks.postprocess(html) as string;\n        }\n        return html;\n      } catch (e) {\n        return throwError(e as Error);\n      }\n    };\n\n    return parse;\n  }\n\n  private onError(silent: boolean, async: boolean) {\n    return (e: Error): string | Promise<string> => {\n      e.message += '\\nPlease report this to https://github.com/markedjs/marked.';\n\n      if (silent) {\n        const msg = '<p>An error occurred:</p><pre>'\n          + escape(e.message + '', true)\n          + '</pre>';\n        if (async) {\n          return Promise.resolve(msg);\n        }\n        return msg;\n      }\n\n      if (async) {\n        return Promise.reject(e);\n      }\n      throw e;\n    };\n  }\n}\n","import { _Lexer } from './Lexer.ts';\nimport { _Parser } from './Parser.ts';\nimport { _Tokenizer } from './Tokenizer.ts';\nimport { _Renderer } from './Renderer.ts';\nimport { _TextRenderer } from './TextRenderer.ts';\nimport { _Hooks } from './Hooks.ts';\nimport { Marked } from './Instance.ts';\nimport {\n  _getDefaults,\n  changeDefaults,\n  _defaults,\n} from './defaults.ts';\nimport type { MarkedExtension, MarkedOptions } from './MarkedOptions.ts';\nimport type { Token, TokensList } from './Tokens.ts';\nimport type { MaybePromise } from './Instance.ts';\n\nconst markedInstance = new Marked();\n\n/**\n * Compiles markdown to HTML asynchronously.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options, having async: true\n * @return Promise of string of compiled HTML\n */\nexport function marked(src: string, options: MarkedOptions & { async: true }): Promise<string>;\n\n/**\n * Compiles markdown to HTML.\n *\n * @param src String of markdown source to be compiled\n * @param options Optional hash of options\n * @return String of compiled HTML. Will be a Promise of string if async is set to true by any extensions.\n */\nexport function marked(src: string, options: MarkedOptions & { async: false }): string;\nexport function marked(src: string, options: MarkedOptions & { async: true }): Promise<string>;\nexport function marked(src: string, options?: MarkedOptions | null): string | Promise<string>;\nexport function marked(src: string, opt?: MarkedOptions | null): string | Promise<string> {\n  return markedInstance.parse(src, opt);\n}\n\n/**\n * Sets the default options.\n *\n * @param options Hash of options\n */\nmarked.options =\nmarked.setOptions = function(options: MarkedOptions) {\n  markedInstance.setOptions(options);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\n/**\n * Gets the original marked default options.\n */\nmarked.getDefaults = _getDefaults;\n\nmarked.defaults = _defaults;\n\n/**\n * Use Extension\n */\n\nmarked.use = function(...args: MarkedExtension[]) {\n  markedInstance.use(...args);\n  marked.defaults = markedInstance.defaults;\n  changeDefaults(marked.defaults);\n  return marked;\n};\n\n/**\n * Run callback for every token\n */\n\nmarked.walkTokens = function(tokens: Token[] | TokensList, callback: (token: Token) => MaybePromise | MaybePromise[]) {\n  return markedInstance.walkTokens(tokens, callback);\n};\n\n/**\n * Compiles markdown to HTML without enclosing `p` tag.\n *\n * @param src String of markdown source to be compiled\n * @param options Hash of options\n * @return String of compiled HTML\n */\nmarked.parseInline = markedInstance.parseInline;\n\n/**\n * Expose\n */\nmarked.Parser = _Parser;\nmarked.parser = _Parser.parse;\nmarked.Renderer = _Renderer;\nmarked.TextRenderer = _TextRenderer;\nmarked.Lexer = _Lexer;\nmarked.lexer = _Lexer.lex;\nmarked.Tokenizer = _Tokenizer;\nmarked.Hooks = _Hooks;\nmarked.parse = marked;\n\nexport const options = marked.options;\nexport const setOptions = marked.setOptions;\nexport const use = marked.use;\nexport const walkTokens = marked.walkTokens;\nexport const parseInline = marked.parseInline;\nexport const parse = marked;\nexport const parser = _Parser.parse;\nexport const lexer = _Lexer.lex;\nexport { _defaults as defaults, _getDefaults as getDefaults } from './defaults.ts';\nexport { _Lexer as Lexer } from './Lexer.ts';\nexport { _Parser as Parser } from './Parser.ts';\nexport { _Tokenizer as Tokenizer } from './Tokenizer.ts';\nexport { _Renderer as Renderer } from './Renderer.ts';\nexport { _TextRenderer as TextRenderer } from './TextRenderer.ts';\nexport { _Hooks as Hooks } from './Hooks.ts';\nexport { Marked } from './Instance.ts';\nexport type * from './MarkedOptions.ts';\nexport type * from './Tokens.ts';\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;AAKO,SAASA,aAAA,EAA8B;EAC5C,OAAO;IACLC,KAAA,EAAO;IACPC,MAAA,EAAQ;IACRC,UAAA,EAAY;IACZC,GAAA,EAAK;IACLC,KAAA,EAAO;IACPC,QAAA,EAAU;IACVC,QAAA,EAAU;IACVC,MAAA,EAAQ;IACRC,SAAA,EAAW;IACXC,UAAA,EAAY;EACd;AACF;AAEO,IAAIC,SAAA,GAAYX,YAAA,CAAa;AAE7B,SAASY,eAAeC,WAAA,EAA4B;EACzDF,SAAA,GAAYE,WAAA;AACd;;;ACxBA,IAAMC,QAAA,GAAW;EAAEC,IAAA,EAAMA,CAAA,KAAM;AAAK;AAEpC,SAASC,KAAKC,KAAA,EAAwBC,GAAA,GAAM,IAAI;EAC9C,IAAIC,MAAA,GAAS,OAAOF,KAAA,KAAU,WAAWA,KAAA,GAAQA,KAAA,CAAME,MAAA;EACvD,MAAMC,GAAA,GAAM;IACVC,OAAA,EAASA,CAACC,IAAA,EAAuBC,GAAA,KAAyB;MACxD,IAAIC,SAAA,GAAY,OAAOD,GAAA,KAAQ,WAAWA,GAAA,GAAMA,GAAA,CAAIJ,MAAA;MACpDK,SAAA,GAAYA,SAAA,CAAUH,OAAA,CAAQI,KAAA,CAAMC,KAAA,EAAO,IAAI;MAC/CP,MAAA,GAASA,MAAA,CAAOE,OAAA,CAAQC,IAAA,EAAME,SAAS;MACvC,OAAOJ,GAAA;IACT;IACAO,QAAA,EAAUA,CAAA,KAAM;MACd,OAAO,IAAIC,MAAA,CAAOT,MAAA,EAAQD,GAAG;IAC/B;EACF;EACA,OAAOE,GAAA;AACT;AAEO,IAAMK,KAAA,GAAQ;EACnBI,gBAAA,EAAkB;EAClBC,iBAAA,EAAmB;EACnBC,sBAAA,EAAwB;EACxBC,cAAA,EAAgB;EAChBC,UAAA,EAAY;EACZC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,YAAA,EAAc;EACdC,iBAAA,EAAmB;EACnBC,aAAA,EAAe;EACfC,mBAAA,EAAqB;EACrBC,SAAA,EAAW;EACXC,eAAA,EAAiB;EACjBC,eAAA,EAAiB;EACjBC,uBAAA,EAAyB;EACzBC,wBAAA,EAA0B;EAC1BC,eAAA,EAAiB;EACjBC,kBAAA,EAAoB;EACpBC,UAAA,EAAY;EACZC,eAAA,EAAiB;EACjBC,OAAA,EAAS;EACTC,YAAA,EAAc;EACdC,cAAA,EAAgB;EAChBC,eAAA,EAAiB;EACjBC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,gBAAA,EAAkB;EAClBC,cAAA,EAAgB;EAChBC,SAAA,EAAW;EACXC,OAAA,EAAS;EACTC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,iBAAA,EAAmB;EACnBC,eAAA,EAAiB;EACjBC,iBAAA,EAAmB;EACnBC,mBAAA,EAAqB;EACrBC,UAAA,EAAY;EACZC,aAAA,EAAe;EACfC,kBAAA,EAAoB;EACpBC,qBAAA,EAAuB;EACvBC,YAAA,EAAc;EACd3C,KAAA,EAAO;EACP4C,aAAA,EAAe;EACfC,QAAA,EAAU;EACVC,SAAA,EAAW;EACXC,SAAA,EAAW;EACXC,cAAA,EAAgB;EAChBC,SAAA,EAAW;EACXC,aAAA,EAAe;EACfC,aAAA,EAAe;EACfC,aAAA,EAAgBC,IAAA,IAAiB,IAAInD,MAAA,CAAO,WAAWmD,IAAI,8BAA+B;EAC1FC,eAAA,EAAkBC,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,oDAAqD;EACpIG,OAAA,EAAUH,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,oDAAoD;EAC3HI,gBAAA,EAAmBJ,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,iBAAiB;EACjGK,iBAAA,EAAoBL,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,IAAI;EACrFM,cAAA,EAAiBN,MAAA,IAAmB,IAAIrD,MAAA,CAAO,QAAQsD,IAAA,CAAKC,GAAA,CAAI,GAAGF,MAAA,GAAS,CAAC,CAAC,sBAAsB,GAAG;AACzG;AAMA,IAAMO,OAAA,GAAU;AAChB,IAAMC,SAAA,GAAY;AAClB,IAAMC,MAAA,GAAS;AACf,IAAMC,EAAA,GAAK;AACX,IAAMC,OAAA,GAAU;AAChB,IAAMC,MAAA,GAAS;AACf,IAAMC,YAAA,GAAe;AACrB,IAAMC,QAAA,GAAW/E,IAAA,CAAK8E,YAAY,EAC/BzE,OAAA,CAAQ,SAASwE,MAAM,EACvBxE,OAAA,CAAQ,cAAc,mBAAmB,EACzCA,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,eAAe,SAAS,EAChCA,OAAA,CAAQ,YAAY,cAAc,EAClCA,OAAA,CAAQ,SAAS,mBAAmB,EACpCA,OAAA,CAAQ,YAAY,EAAE,EACtBM,QAAA,CAAS;AACZ,IAAMqE,WAAA,GAAchF,IAAA,CAAK8E,YAAY,EAClCzE,OAAA,CAAQ,SAASwE,MAAM,EACvBxE,OAAA,CAAQ,cAAc,mBAAmB,EACzCA,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,eAAe,SAAS,EAChCA,OAAA,CAAQ,YAAY,cAAc,EAClCA,OAAA,CAAQ,SAAS,mBAAmB,EACpCA,OAAA,CAAQ,UAAU,mCAAmC,EACrDM,QAAA,CAAS;AACZ,IAAMsE,UAAA,GAAa;AACnB,IAAMC,SAAA,GAAY;AAClB,IAAMC,WAAA,GAAc;AACpB,IAAMC,GAAA,GAAMpF,IAAA,CAAK,6GAA6G,EAC3HK,OAAA,CAAQ,SAAS8E,WAAW,EAC5B9E,OAAA,CAAQ,SAAS,8DAA8D,EAC/EM,QAAA,CAAS;AAEZ,IAAM0E,IAAA,GAAOrF,IAAA,CAAK,sCAAsC,EACrDK,OAAA,CAAQ,SAASwE,MAAM,EACvBlE,QAAA,CAAS;AAEZ,IAAM2E,IAAA,GAAO;AAMb,IAAMC,QAAA,GAAW;AACjB,IAAMC,IAAA,GAAOxF,IAAA,CACX,6dASK,GAAG,EACPK,OAAA,CAAQ,WAAWkF,QAAQ,EAC3BlF,OAAA,CAAQ,OAAOiF,IAAI,EACnBjF,OAAA,CAAQ,aAAa,0EAA0E,EAC/FM,QAAA,CAAS;AAEZ,IAAM8E,SAAA,GAAYzF,IAAA,CAAKiF,UAAU,EAC9B5E,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,aAAa,EAAE,EACvBA,OAAA,CAAQ,UAAU,EAAE,EACpBA,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,UAAU,gDAAgD,EAClEA,OAAA,CAAQ,QAAQ,wBAAwB,EACxCA,OAAA,CAAQ,QAAQ,6DAA6D,EAC7EA,OAAA,CAAQ,OAAOiF,IAAI,EACnB3E,QAAA,CAAS;AAEZ,IAAM+E,UAAA,GAAa1F,IAAA,CAAK,yCAAyC,EAC9DK,OAAA,CAAQ,aAAaoF,SAAS,EAC9B9E,QAAA,CAAS;AAMZ,IAAMgF,WAAA,GAAc;EAClBD,UAAA;EACAE,IAAA,EAAMnB,SAAA;EACNW,GAAA;EACAV,MAAA;EACAE,OAAA;EACAD,EAAA;EACAa,IAAA;EACAT,QAAA;EACAM,IAAA;EACAb,OAAA;EACAiB,SAAA;EACAI,KAAA,EAAO/F,QAAA;EACPgG,IAAA,EAAMZ;AACR;AAQA,IAAMa,QAAA,GAAW/F,IAAA,CACf,6JAEsF,EACrFK,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,QAAQ,wBAAyB,EACzCA,OAAA,CAAQ,UAAU,gDAAgD,EAClEA,OAAA,CAAQ,QAAQ,wBAAwB,EACxCA,OAAA,CAAQ,QAAQ,6DAA6D,EAC7EA,OAAA,CAAQ,OAAOiF,IAAI,EACnB3E,QAAA,CAAS;AAEZ,IAAMqF,QAAA,GAAsC;EAC1C,GAAGL,WAAA;EACHZ,QAAA,EAAUC,WAAA;EACVa,KAAA,EAAOE,QAAA;EACPN,SAAA,EAAWzF,IAAA,CAAKiF,UAAU,EACvB5E,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,uBAAuB,EAC1CA,OAAA,CAAQ,aAAa,EAAE,EACvBA,OAAA,CAAQ,SAAS0F,QAAQ,EACzB1F,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,UAAU,gDAAgD,EAClEA,OAAA,CAAQ,QAAQ,wBAAwB,EACxCA,OAAA,CAAQ,QAAQ,6DAA6D,EAC7EA,OAAA,CAAQ,OAAOiF,IAAI,EACnB3E,QAAA,CAAS;AACd;AAMA,IAAMsF,aAAA,GAA2C;EAC/C,GAAGN,WAAA;EACHH,IAAA,EAAMxF,IAAA,CACJ,wIAEwE,EACvEK,OAAA,CAAQ,WAAWkF,QAAQ,EAC3BlF,OAAA,CAAQ,QAAQ,mKAGkB,EAClCM,QAAA,CAAS;EACZyE,GAAA,EAAK;EACLR,OAAA,EAAS;EACTF,MAAA,EAAQ5E,QAAA;EAAA;EACRiF,QAAA,EAAU;EACVU,SAAA,EAAWzF,IAAA,CAAKiF,UAAU,EACvB5E,OAAA,CAAQ,MAAMsE,EAAE,EAChBtE,OAAA,CAAQ,WAAW,iBAAiB,EACpCA,OAAA,CAAQ,YAAY0E,QAAQ,EAC5B1E,OAAA,CAAQ,UAAU,EAAE,EACpBA,OAAA,CAAQ,cAAc,SAAS,EAC/BA,OAAA,CAAQ,WAAW,EAAE,EACrBA,OAAA,CAAQ,SAAS,EAAE,EACnBA,OAAA,CAAQ,SAAS,EAAE,EACnBA,OAAA,CAAQ,QAAQ,EAAE,EAClBM,QAAA,CAAS;AACd;AAMA,IAAMuF,MAAA,GAAS;AACf,IAAMC,UAAA,GAAa;AACnB,IAAMC,EAAA,GAAK;AACX,IAAMC,UAAA,GAAa;AAGnB,IAAMC,YAAA,GAAe;AACrB,IAAMC,mBAAA,GAAsB;AAC5B,IAAMC,sBAAA,GAAyB;AAC/B,IAAMC,WAAA,GAAczG,IAAA,CAAK,yBAAyB,GAAG,EAClDK,OAAA,CAAQ,eAAekG,mBAAmB,EAAE5F,QAAA,CAAS;AAGxD,IAAM+F,uBAAA,GAA0B;AAChC,IAAMC,8BAAA,GAAiC;AACvC,IAAMC,iCAAA,GAAoC;AAG1C,IAAMC,SAAA,GAAY;AAElB,IAAMC,kBAAA,GAAqB;AAE3B,IAAMC,cAAA,GAAiB/G,IAAA,CAAK8G,kBAAA,EAAoB,GAAG,EAChDzG,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAMqG,iBAAA,GAAoBhH,IAAA,CAAK8G,kBAAA,EAAoB,GAAG,EACnDzG,OAAA,CAAQ,UAAUqG,uBAAuB,EACzC/F,QAAA,CAAS;AAEZ,IAAMsG,qBAAA,GACJ;AASF,IAAMC,iBAAA,GAAoBlH,IAAA,CAAKiH,qBAAA,EAAuB,IAAI,EACvD5G,OAAA,CAAQ,kBAAkBmG,sBAAsB,EAChDnG,OAAA,CAAQ,eAAekG,mBAAmB,EAC1ClG,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAMwG,oBAAA,GAAuBnH,IAAA,CAAKiH,qBAAA,EAAuB,IAAI,EAC1D5G,OAAA,CAAQ,kBAAkBuG,iCAAiC,EAC3DvG,OAAA,CAAQ,eAAesG,8BAA8B,EACrDtG,OAAA,CAAQ,UAAUqG,uBAAuB,EACzC/F,QAAA,CAAS;AAGZ,IAAMyG,iBAAA,GAAoBpH,IAAA,CACxB,oNAMiC,IAAI,EACpCK,OAAA,CAAQ,kBAAkBmG,sBAAsB,EAChDnG,OAAA,CAAQ,eAAekG,mBAAmB,EAC1ClG,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAM0G,cAAA,GAAiBrH,IAAA,CAAK,aAAa,IAAI,EAC1CK,OAAA,CAAQ,UAAUiG,YAAY,EAC9B3F,QAAA,CAAS;AAEZ,IAAM2G,QAAA,GAAWtH,IAAA,CAAK,qCAAqC,EACxDK,OAAA,CAAQ,UAAU,8BAA8B,EAChDA,OAAA,CAAQ,SAAS,8IAA8I,EAC/JM,QAAA,CAAS;AAEZ,IAAM4G,cAAA,GAAiBvH,IAAA,CAAKuF,QAAQ,EAAElF,OAAA,CAAQ,aAAa,KAAK,EAAEM,QAAA,CAAS;AAC3E,IAAM6G,GAAA,GAAMxH,IAAA,CACV,0JAKsC,EACrCK,OAAA,CAAQ,WAAWkH,cAAc,EACjClH,OAAA,CAAQ,aAAa,6EAA6E,EAClGM,QAAA,CAAS;AAEZ,IAAM8G,YAAA,GAAe;AAErB,IAAMC,IAAA,GAAO1H,IAAA,CAAK,mEAAmE,EAClFK,OAAA,CAAQ,SAASoH,YAAY,EAC7BpH,OAAA,CAAQ,QAAQ,yCAAyC,EACzDA,OAAA,CAAQ,SAAS,6DAA6D,EAC9EM,QAAA,CAAS;AAEZ,IAAMgH,OAAA,GAAU3H,IAAA,CAAK,yBAAyB,EAC3CK,OAAA,CAAQ,SAASoH,YAAY,EAC7BpH,OAAA,CAAQ,OAAO8E,WAAW,EAC1BxE,QAAA,CAAS;AAEZ,IAAMiH,MAAA,GAAS5H,IAAA,CAAK,uBAAuB,EACxCK,OAAA,CAAQ,OAAO8E,WAAW,EAC1BxE,QAAA,CAAS;AAEZ,IAAMkH,aAAA,GAAgB7H,IAAA,CAAK,yBAAyB,GAAG,EACpDK,OAAA,CAAQ,WAAWsH,OAAO,EAC1BtH,OAAA,CAAQ,UAAUuH,MAAM,EACxBjH,QAAA,CAAS;AAMZ,IAAMmH,YAAA,GAAe;EACnBC,UAAA,EAAYjI,QAAA;EAAA;EACZuH,cAAA;EACAC,QAAA;EACAT,SAAA;EACAT,EAAA;EACAR,IAAA,EAAMO,UAAA;EACN6B,GAAA,EAAKlI,QAAA;EACLiH,cAAA;EACAG,iBAAA;EACAE,iBAAA;EACAlB,MAAA;EACAwB,IAAA;EACAE,MAAA;EACAnB,WAAA;EACAkB,OAAA;EACAE,aAAA;EACAL,GAAA;EACA1B,IAAA,EAAMO,UAAA;EACN4B,GAAA,EAAKnI;AACP;AAQA,IAAMoI,cAAA,GAA6C;EACjD,GAAGJ,YAAA;EACHJ,IAAA,EAAM1H,IAAA,CAAK,yBAAyB,EACjCK,OAAA,CAAQ,SAASoH,YAAY,EAC7B9G,QAAA,CAAS;EACZgH,OAAA,EAAS3H,IAAA,CAAK,+BAA+B,EAC1CK,OAAA,CAAQ,SAASoH,YAAY,EAC7B9G,QAAA,CAAS;AACd;AAMA,IAAMwH,SAAA,GAAwC;EAC5C,GAAGL,YAAA;EACHZ,iBAAA,EAAmBC,oBAAA;EACnBJ,cAAA,EAAgBC,iBAAA;EAChBiB,GAAA,EAAKjI,IAAA,CAAK,oEAAoE,GAAG,EAC9EK,OAAA,CAAQ,SAAS,2EAA2E,EAC5FM,QAAA,CAAS;EACZoH,UAAA,EAAY;EACZC,GAAA,EAAK;EACLlC,IAAA,EAAM;AACR;AAMA,IAAMsC,YAAA,GAA2C;EAC/C,GAAGD,SAAA;EACH/B,EAAA,EAAIpG,IAAA,CAAKoG,EAAE,EAAE/F,OAAA,CAAQ,QAAQ,GAAG,EAAEM,QAAA,CAAS;EAC3CmF,IAAA,EAAM9F,IAAA,CAAKmI,SAAA,CAAUrC,IAAI,EACtBzF,OAAA,CAAQ,QAAQ,eAAe,EAC/BA,OAAA,CAAQ,WAAW,GAAG,EACtBM,QAAA,CAAS;AACd;AAMO,IAAM0H,KAAA,GAAQ;EACnBC,MAAA,EAAQ3C,WAAA;EACRvG,GAAA,EAAK4G,QAAA;EACL1G,QAAA,EAAU2G;AACZ;AAEO,IAAMsC,MAAA,GAAS;EACpBD,MAAA,EAAQR,YAAA;EACR1I,GAAA,EAAK+I,SAAA;EACLjJ,MAAA,EAAQkJ,YAAA;EACR9I,QAAA,EAAU4I;AACZ;;;ACzbA,IAAMM,kBAAA,GAAkD;EACtD,KAAK;EACL,KAAK;EACL,KAAK;EACL,KAAK;EACL,KAAK;AACP;AACA,IAAMC,oBAAA,GAAwBC,EAAA,IAAeF,kBAAA,CAAmBE,EAAE;AAE3D,SAASC,QAAOC,KAAA,EAAcC,MAAA,EAAkB;EACrD,IAAIA,MAAA,EAAQ;IACV,IAAIpI,KAAA,CAAMwC,UAAA,CAAW6F,IAAA,CAAKF,KAAI,GAAG;MAC/B,OAAOA,KAAA,CAAKvI,OAAA,CAAQI,KAAA,CAAMyC,aAAA,EAAeuF,oBAAoB;IAC/D;EACF,OAAO;IACL,IAAIhI,KAAA,CAAM0C,kBAAA,CAAmB2F,IAAA,CAAKF,KAAI,GAAG;MACvC,OAAOA,KAAA,CAAKvI,OAAA,CAAQI,KAAA,CAAM2C,qBAAA,EAAuBqF,oBAAoB;IACvE;EACF;EAEA,OAAOG,KAAA;AACT;AAgBO,SAASG,SAASC,IAAA,EAAc;EACrC,IAAI;IACFA,IAAA,GAAOC,SAAA,CAAUD,IAAI,EAAE3I,OAAA,CAAQI,KAAA,CAAM6C,aAAA,EAAe,GAAG;EACzD,QAAQ;IACN,OAAO;EACT;EACA,OAAO0F,IAAA;AACT;AAEO,SAASE,WAAWC,QAAA,EAAkBC,KAAA,EAAgB;EAG3D,MAAMC,GAAA,GAAMF,QAAA,CAAS9I,OAAA,CAAQI,KAAA,CAAM8C,QAAA,EAAU,CAAC+F,KAAA,EAAOC,MAAA,EAAQC,GAAA,KAAQ;MACjE,IAAIC,OAAA,GAAU;MACd,IAAIC,IAAA,GAAOH,MAAA;MACX,OAAO,EAAEG,IAAA,IAAQ,KAAKF,GAAA,CAAIE,IAAI,MAAM,MAAMD,OAAA,GAAU,CAACA,OAAA;MACrD,IAAIA,OAAA,EAAS;QAGX,OAAO;MACT,OAAO;QAEL,OAAO;MACT;IACF,CAAC;IACDE,KAAA,GAAQN,GAAA,CAAIO,KAAA,CAAMnJ,KAAA,CAAM+C,SAAS;EACnC,IAAIqG,CAAA,GAAI;EAGR,IAAI,CAACF,KAAA,CAAM,CAAC,EAAEG,IAAA,CAAK,GAAG;IACpBH,KAAA,CAAMI,KAAA,CAAM;EACd;EACA,IAAIJ,KAAA,CAAMK,MAAA,GAAS,KAAK,CAACL,KAAA,CAAMM,EAAA,CAAG,EAAE,GAAGH,IAAA,CAAK,GAAG;IAC7CH,KAAA,CAAMO,GAAA,CAAI;EACZ;EAEA,IAAId,KAAA,EAAO;IACT,IAAIO,KAAA,CAAMK,MAAA,GAASZ,KAAA,EAAO;MACxBO,KAAA,CAAMQ,MAAA,CAAOf,KAAK;IACpB,OAAO;MACL,OAAOO,KAAA,CAAMK,MAAA,GAASZ,KAAA,EAAOO,KAAA,CAAMS,IAAA,CAAK,EAAE;IAC5C;EACF;EAEA,OAAOP,CAAA,GAAIF,KAAA,CAAMK,MAAA,EAAQH,CAAA,IAAK;IAE5BF,KAAA,CAAME,CAAC,IAAIF,KAAA,CAAME,CAAC,EAAEC,IAAA,CAAK,EAAEzJ,OAAA,CAAQI,KAAA,CAAMgD,SAAA,EAAW,GAAG;EACzD;EACA,OAAOkG,KAAA;AACT;AAUO,SAASU,MAAMb,GAAA,EAAac,CAAA,EAAWC,MAAA,EAAkB;EAC9D,MAAMC,CAAA,GAAIhB,GAAA,CAAIQ,MAAA;EACd,IAAIQ,CAAA,KAAM,GAAG;IACX,OAAO;EACT;EAGA,IAAIC,OAAA,GAAU;EAGd,OAAOA,OAAA,GAAUD,CAAA,EAAG;IAClB,MAAME,QAAA,GAAWlB,GAAA,CAAImB,MAAA,CAAOH,CAAA,GAAIC,OAAA,GAAU,CAAC;IAC3C,IAAIC,QAAA,KAAaJ,CAAA,IAAK,CAACC,MAAA,EAAQ;MAC7BE,OAAA;IACF,WAAWC,QAAA,KAAaJ,CAAA,IAAKC,MAAA,EAAQ;MACnCE,OAAA;IACF,OAAO;MACL;IACF;EACF;EAEA,OAAOjB,GAAA,CAAIoB,KAAA,CAAM,GAAGJ,CAAA,GAAIC,OAAO;AACjC;AAEO,SAASI,mBAAmBrB,GAAA,EAAasB,CAAA,EAAW;EACzD,IAAItB,GAAA,CAAIuB,OAAA,CAAQD,CAAA,CAAE,CAAC,CAAC,MAAM,IAAI;IAC5B,OAAO;EACT;EAEA,IAAIE,KAAA,GAAQ;EACZ,SAASnB,CAAA,GAAI,GAAGA,CAAA,GAAIL,GAAA,CAAIQ,MAAA,EAAQH,CAAA,IAAK;IACnC,IAAIL,GAAA,CAAIK,CAAC,MAAM,MAAM;MACnBA,CAAA;IACF,WAAWL,GAAA,CAAIK,CAAC,MAAMiB,CAAA,CAAE,CAAC,GAAG;MAC1BE,KAAA;IACF,WAAWxB,GAAA,CAAIK,CAAC,MAAMiB,CAAA,CAAE,CAAC,GAAG;MAC1BE,KAAA;MACA,IAAIA,KAAA,GAAQ,GAAG;QACb,OAAOnB,CAAA;MACT;IACF;EACF;EACA,IAAImB,KAAA,GAAQ,GAAG;IACb,OAAO;EACT;EAEA,OAAO;AACT;;;ACzIA,SAASC,WAAWC,GAAA,EAAeC,KAAA,EAA2CC,GAAA,EAAaC,MAAA,EAAeC,KAAA,EAA0C;EAClJ,MAAMtC,IAAA,GAAOmC,KAAA,CAAKnC,IAAA;EAClB,MAAMuC,KAAA,GAAQJ,KAAA,CAAKI,KAAA,IAAS;EAC5B,MAAMzF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQiL,KAAA,CAAM7K,KAAA,CAAMK,iBAAA,EAAmB,IAAI;EAE/DuK,MAAA,CAAMG,KAAA,CAAMC,MAAA,GAAS;EACrB,MAAMC,KAAA,GAAoC;IACxCC,IAAA,EAAMT,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAO,CAAC,MAAM,MAAM,UAAU;IAC3CS,GAAA;IACApC,IAAA;IACAuC,KAAA;IACAzF,IAAA;IACA8F,MAAA,EAAQP,MAAA,CAAMQ,YAAA,CAAa/F,IAAI;EACjC;EACAuF,MAAA,CAAMG,KAAA,CAAMC,MAAA,GAAS;EACrB,OAAOC,KAAA;AACT;AAEA,SAAS3K,uBAAuBqK,GAAA,EAAatF,IAAA,EAAcwF,KAAA,EAAc;EACvE,MAAMQ,iBAAA,GAAoBV,GAAA,CAAI9B,KAAA,CAAMgC,KAAA,CAAM7K,KAAA,CAAMM,sBAAsB;EAEtE,IAAI+K,iBAAA,KAAsB,MAAM;IAC9B,OAAOhG,IAAA;EACT;EAEA,MAAMiG,YAAA,GAAeD,iBAAA,CAAkB,CAAC;EAExC,OAAOhG,IAAA,CACJ8D,KAAA,CAAM,IAAI,EACVoC,GAAA,CAAIC,IAAA,IAAQ;IACX,MAAMC,iBAAA,GAAoBD,IAAA,CAAK3C,KAAA,CAAMgC,KAAA,CAAM7K,KAAA,CAAMO,cAAc;IAC/D,IAAIkL,iBAAA,KAAsB,MAAM;MAC9B,OAAOD,IAAA;IACT;IAEA,MAAM,CAACE,YAAY,IAAID,iBAAA;IAEvB,IAAIC,YAAA,CAAanC,MAAA,IAAU+B,YAAA,CAAa/B,MAAA,EAAQ;MAC9C,OAAOiC,IAAA,CAAKrB,KAAA,CAAMmB,YAAA,CAAa/B,MAAM;IACvC;IAEA,OAAOiC,IAAA;EACT,CAAC,EACAG,IAAA,CAAK,IAAI;AACd;AAKO,IAAMC,UAAA,GAAN,MAAMA,UAAA,CAAW;EAGtB;EAEAC,YAAYC,QAAA,EAAyB;IAAAC,eAAA;IAAAA,eAAA;IAHrC;IAAAA,eAAA;IAIE,KAAKC,OAAA,GAAUF,QAAA,IAAW5M,SAAA;EAC5B;EAEA+M,MAAMC,GAAA,EAAuC;IAC3C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM7D,OAAA,CAAQzE,IAAA,CAAK4M,GAAG;IAC7C,IAAIzB,GAAA,IAAOA,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS,GAAG;MAC5B,OAAO;QACL2B,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;MACZ;IACF;EACF;EAEAtF,KAAK+G,GAAA,EAAsC;IACzC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMzC,IAAA,CAAK7F,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,MAAMpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMI,gBAAA,EAAkB,EAAE;MACjE,OAAO;QACL8K,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACV0B,cAAA,EAAgB;QAChB9G,IAAA,EAAM,CAAC,KAAK2G,OAAA,CAAQnN,QAAA,GAChB+K,KAAA,CAAMvE,IAAA,EAAM,IAAI,IAChBA;MACN;IACF;EACF;EAEApB,OAAOiI,GAAA,EAAsC;IAC3C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM3D,MAAA,CAAO3E,IAAA,CAAK4M,GAAG;IAC5C,IAAIzB,GAAA,EAAK;MACP,MAAME,GAAA,GAAMF,GAAA,CAAI,CAAC;MACjB,MAAMpF,IAAA,GAAO/E,sBAAA,CAAuBqK,GAAA,EAAKF,GAAA,CAAI,CAAC,KAAK,IAAI,KAAKI,KAAK;MAEjE,OAAO;QACLK,IAAA,EAAM;QACNP,GAAA;QACAyB,IAAA,EAAM3B,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK,EAAEzJ,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI6D,GAAA,CAAI,CAAC;QACpFpF;MACF;IACF;EACF;EAEAlB,QAAQ+H,GAAA,EAAyC;IAC/C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMzD,OAAA,CAAQ7E,IAAA,CAAK4M,GAAG;IAC7C,IAAIzB,GAAA,EAAK;MACP,IAAIpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK;MAGvB,IAAI,KAAKwB,KAAA,CAAM7K,KAAA,CAAMQ,UAAA,CAAW6H,IAAA,CAAKhD,IAAI,GAAG;QAC1C,MAAMgH,OAAA,GAAUzC,KAAA,CAAMvE,IAAA,EAAM,GAAG;QAC/B,IAAI,KAAK2G,OAAA,CAAQnN,QAAA,EAAU;UACzBwG,IAAA,GAAOgH,OAAA,CAAQhD,IAAA,CAAK;QACtB,WAAW,CAACgD,OAAA,IAAW,KAAKxB,KAAA,CAAM7K,KAAA,CAAMU,eAAA,CAAgB2H,IAAA,CAAKgE,OAAO,GAAG;UAErEhH,IAAA,GAAOgH,OAAA,CAAQhD,IAAA,CAAK;QACtB;MACF;MAEA,OAAO;QACL6B,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACV6B,KAAA,EAAO7B,GAAA,CAAI,CAAC,EAAElB,MAAA;QACdlE,IAAA;QACA8F,MAAA,EAAQ,KAAKoB,KAAA,CAAMzE,MAAA,CAAOzC,IAAI;MAChC;IACF;EACF;EAEAnB,GAAGgI,GAAA,EAAoC;IACrC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM1D,EAAA,CAAG5E,IAAA,CAAK4M,GAAG;IACxC,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKf,KAAA,CAAMa,GAAA,CAAI,CAAC,GAAG,IAAI;MACzB;IACF;EACF;EAEAxF,WAAWiH,GAAA,EAA4C;IACrD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM3C,UAAA,CAAW3F,IAAA,CAAK4M,GAAG;IAChD,IAAIzB,GAAA,EAAK;MACP,IAAI+B,KAAA,GAAQ5C,KAAA,CAAMa,GAAA,CAAI,CAAC,GAAG,IAAI,EAAEtB,KAAA,CAAM,IAAI;MAC1C,IAAIwB,GAAA,GAAM;MACV,IAAItF,IAAA,GAAO;MACX,MAAM8F,MAAA,GAAkB,EAAC;MAEzB,OAAOqB,KAAA,CAAMjD,MAAA,GAAS,GAAG;QACvB,IAAIkD,YAAA,GAAe;QACnB,MAAMC,YAAA,GAAe,EAAC;QAEtB,IAAItD,CAAA;QACJ,KAAKA,CAAA,GAAI,GAAGA,CAAA,GAAIoD,KAAA,CAAMjD,MAAA,EAAQH,CAAA,IAAK;UAEjC,IAAI,KAAKyB,KAAA,CAAM7K,KAAA,CAAMiB,eAAA,CAAgBoH,IAAA,CAAKmE,KAAA,CAAMpD,CAAC,CAAC,GAAG;YACnDsD,YAAA,CAAa/C,IAAA,CAAK6C,KAAA,CAAMpD,CAAC,CAAC;YAC1BqD,YAAA,GAAe;UACjB,WAAW,CAACA,YAAA,EAAc;YACxBC,YAAA,CAAa/C,IAAA,CAAK6C,KAAA,CAAMpD,CAAC,CAAC;UAC5B,OAAO;YACL;UACF;QACF;QACAoD,KAAA,GAAQA,KAAA,CAAMrC,KAAA,CAAMf,CAAC;QAErB,MAAMuD,UAAA,GAAaD,YAAA,CAAaf,IAAA,CAAK,IAAI;QACzC,MAAMiB,WAAA,GAAcD,UAAA,CAEjB/M,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMkB,uBAAA,EAAyB,UAAU,EAC5DtB,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMmB,wBAAA,EAA0B,EAAE;QACxDwJ,GAAA,GAAMA,GAAA,GAAM,GAAGA,GAAG;AAAA,EAAKgC,UAAU,KAAKA,UAAA;QACtCtH,IAAA,GAAOA,IAAA,GAAO,GAAGA,IAAI;AAAA,EAAKuH,WAAW,KAAKA,WAAA;QAI1C,MAAMC,GAAA,GAAM,KAAKN,KAAA,CAAMxB,KAAA,CAAM8B,GAAA;QAC7B,KAAKN,KAAA,CAAMxB,KAAA,CAAM8B,GAAA,GAAM;QACvB,KAAKN,KAAA,CAAMO,WAAA,CAAYF,WAAA,EAAazB,MAAA,EAAQ,IAAI;QAChD,KAAKoB,KAAA,CAAMxB,KAAA,CAAM8B,GAAA,GAAMA,GAAA;QAGvB,IAAIL,KAAA,CAAMjD,MAAA,KAAW,GAAG;UACtB;QACF;QAEA,MAAMwD,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAE9B,IAAIuD,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UAE9B;QACF,WAAW6B,SAAA,EAAW7B,IAAA,KAAS,cAAc;UAE3C,MAAM8B,QAAA,GAAWD,SAAA;UACjB,MAAME,OAAA,GAAUD,QAAA,CAASrC,GAAA,GAAM,OAAO6B,KAAA,CAAMb,IAAA,CAAK,IAAI;UACrD,MAAMuB,QAAA,GAAW,KAAKjI,UAAA,CAAWgI,OAAO;UACxC9B,MAAA,CAAOA,MAAA,CAAO5B,MAAA,GAAS,CAAC,IAAI2D,QAAA;UAE5BvC,GAAA,GAAMA,GAAA,CAAIwC,SAAA,CAAU,GAAGxC,GAAA,CAAIpB,MAAA,GAASyD,QAAA,CAASrC,GAAA,CAAIpB,MAAM,IAAI2D,QAAA,CAASvC,GAAA;UACpEtF,IAAA,GAAOA,IAAA,CAAK8H,SAAA,CAAU,GAAG9H,IAAA,CAAKkE,MAAA,GAASyD,QAAA,CAAS3H,IAAA,CAAKkE,MAAM,IAAI2D,QAAA,CAAS7H,IAAA;UACxE;QACF,WAAW0H,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UAErC,MAAM8B,QAAA,GAAWD,SAAA;UACjB,MAAME,OAAA,GAAUD,QAAA,CAASrC,GAAA,GAAM,OAAO6B,KAAA,CAAMb,IAAA,CAAK,IAAI;UACrD,MAAMuB,QAAA,GAAW,KAAKtI,IAAA,CAAKqI,OAAO;UAClC9B,MAAA,CAAOA,MAAA,CAAO5B,MAAA,GAAS,CAAC,IAAI2D,QAAA;UAE5BvC,GAAA,GAAMA,GAAA,CAAIwC,SAAA,CAAU,GAAGxC,GAAA,CAAIpB,MAAA,GAASwD,SAAA,CAAUpC,GAAA,CAAIpB,MAAM,IAAI2D,QAAA,CAASvC,GAAA;UACrEtF,IAAA,GAAOA,IAAA,CAAK8H,SAAA,CAAU,GAAG9H,IAAA,CAAKkE,MAAA,GAASyD,QAAA,CAASrC,GAAA,CAAIpB,MAAM,IAAI2D,QAAA,CAASvC,GAAA;UACvE6B,KAAA,GAAQS,OAAA,CAAQE,SAAA,CAAUhC,MAAA,CAAO3B,EAAA,CAAG,EAAE,EAAGmB,GAAA,CAAIpB,MAAM,EAAEJ,KAAA,CAAM,IAAI;UAC/D;QACF;MACF;MAEA,OAAO;QACL+B,IAAA,EAAM;QACNP,GAAA;QACAQ,MAAA;QACA9F;MACF;IACF;EACF;EAEAT,KAAKsH,GAAA,EAAsC;IACzC,IAAIzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMhD,IAAA,CAAKtF,IAAA,CAAK4M,GAAG;IACxC,IAAIzB,GAAA,EAAK;MACP,IAAInH,IAAA,GAAOmH,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK;MACvB,MAAM+D,SAAA,GAAY9J,IAAA,CAAKiG,MAAA,GAAS;MAEhC,MAAM8D,KAAA,GAAoB;QACxBnC,IAAA,EAAM;QACNP,GAAA,EAAK;QACL2C,OAAA,EAASF,SAAA;QACTG,KAAA,EAAOH,SAAA,GAAY,CAAC9J,IAAA,CAAK6G,KAAA,CAAM,GAAG,EAAE,IAAI;QACxCqD,KAAA,EAAO;QACPC,KAAA,EAAO;MACT;MAEAnK,IAAA,GAAO8J,SAAA,GAAY,aAAa9J,IAAA,CAAK6G,KAAA,CAAM,EAAE,CAAC,KAAK,KAAK7G,IAAI;MAE5D,IAAI,KAAK0I,OAAA,CAAQnN,QAAA,EAAU;QACzByE,IAAA,GAAO8J,SAAA,GAAY9J,IAAA,GAAO;MAC5B;MAGA,MAAMoK,SAAA,GAAY,KAAK7C,KAAA,CAAM7K,KAAA,CAAMqD,aAAA,CAAcC,IAAI;MACrD,IAAIqK,iBAAA,GAAoB;MAExB,OAAOzB,GAAA,EAAK;QACV,IAAI0B,QAAA,GAAW;QACf,IAAIjD,GAAA,GAAM;QACV,IAAIkD,YAAA,GAAe;QACnB,IAAI,EAAEpD,GAAA,GAAMiD,SAAA,CAAUpO,IAAA,CAAK4M,GAAG,IAAI;UAChC;QACF;QAEA,IAAI,KAAKrB,KAAA,CAAMjD,KAAA,CAAM1D,EAAA,CAAGmE,IAAA,CAAK6D,GAAG,GAAG;UACjC;QACF;QAEAvB,GAAA,GAAMF,GAAA,CAAI,CAAC;QACXyB,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUxC,GAAA,CAAIpB,MAAM;QAE9B,IAAIuE,IAAA,GAAOrD,GAAA,CAAI,CAAC,EAAEtB,KAAA,CAAM,MAAM,CAAC,EAAE,CAAC,EAAEvJ,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMoB,eAAA,EAAkB2M,CAAA,IAAc,IAAIC,MAAA,CAAO,IAAID,CAAA,CAAExE,MAAM,CAAC;QACrH,IAAI0E,QAAA,GAAW/B,GAAA,CAAI/C,KAAA,CAAM,MAAM,CAAC,EAAE,CAAC;QACnC,IAAIpI,SAAA,GAAY,CAAC+M,IAAA,CAAKzE,IAAA,CAAK;QAE3B,IAAI7F,MAAA,GAAS;QACb,IAAI,KAAKwI,OAAA,CAAQnN,QAAA,EAAU;UACzB2E,MAAA,GAAS;UACTqK,YAAA,GAAeC,IAAA,CAAKI,SAAA,CAAU;QAChC,WAAWnN,SAAA,EAAW;UACpByC,MAAA,GAASiH,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS;QAC3B,OAAO;UACL/F,MAAA,GAASiH,GAAA,CAAI,CAAC,EAAE0D,MAAA,CAAO,KAAKtD,KAAA,CAAM7K,KAAA,CAAMW,YAAY;UACpD6C,MAAA,GAASA,MAAA,GAAS,IAAI,IAAIA,MAAA;UAC1BqK,YAAA,GAAeC,IAAA,CAAK3D,KAAA,CAAM3G,MAAM;UAChCA,MAAA,IAAUiH,GAAA,CAAI,CAAC,EAAElB,MAAA;QACnB;QAEA,IAAIxI,SAAA,IAAa,KAAK8J,KAAA,CAAM7K,KAAA,CAAMe,SAAA,CAAUsH,IAAA,CAAK4F,QAAQ,GAAG;UAC1DtD,GAAA,IAAOsD,QAAA,GAAW;UAClB/B,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUc,QAAA,CAAS1E,MAAA,GAAS,CAAC;UACvCqE,QAAA,GAAW;QACb;QAEA,IAAI,CAACA,QAAA,EAAU;UACb,MAAMrK,eAAA,GAAkB,KAAKsH,KAAA,CAAM7K,KAAA,CAAMuD,eAAA,CAAgBC,MAAM;UAC/D,MAAMG,OAAA,GAAU,KAAKkH,KAAA,CAAM7K,KAAA,CAAM2D,OAAA,CAAQH,MAAM;UAC/C,MAAMI,gBAAA,GAAmB,KAAKiH,KAAA,CAAM7K,KAAA,CAAM4D,gBAAA,CAAiBJ,MAAM;UACjE,MAAMK,iBAAA,GAAoB,KAAKgH,KAAA,CAAM7K,KAAA,CAAM6D,iBAAA,CAAkBL,MAAM;UACnE,MAAMM,cAAA,GAAiB,KAAK+G,KAAA,CAAM7K,KAAA,CAAM8D,cAAA,CAAeN,MAAM;UAG7D,OAAO0I,GAAA,EAAK;YACV,MAAMkC,OAAA,GAAUlC,GAAA,CAAI/C,KAAA,CAAM,MAAM,CAAC,EAAE,CAAC;YACpC,IAAIkF,mBAAA;YACJJ,QAAA,GAAWG,OAAA;YAGX,IAAI,KAAKpC,OAAA,CAAQnN,QAAA,EAAU;cACzBoP,QAAA,GAAWA,QAAA,CAASrO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMqB,kBAAA,EAAoB,IAAI;cACrEgN,mBAAA,GAAsBJ,QAAA;YACxB,OAAO;cACLI,mBAAA,GAAsBJ,QAAA,CAASrO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMa,aAAA,EAAe,MAAM;YAC/E;YAGA,IAAI+C,gBAAA,CAAiByE,IAAA,CAAK4F,QAAQ,GAAG;cACnC;YACF;YAGA,IAAIpK,iBAAA,CAAkBwE,IAAA,CAAK4F,QAAQ,GAAG;cACpC;YACF;YAGA,IAAInK,cAAA,CAAeuE,IAAA,CAAK4F,QAAQ,GAAG;cACjC;YACF;YAGA,IAAI1K,eAAA,CAAgB8E,IAAA,CAAK4F,QAAQ,GAAG;cAClC;YACF;YAGA,IAAItK,OAAA,CAAQ0E,IAAA,CAAK4F,QAAQ,GAAG;cAC1B;YACF;YAEA,IAAII,mBAAA,CAAoBF,MAAA,CAAO,KAAKtD,KAAA,CAAM7K,KAAA,CAAMW,YAAY,KAAK6C,MAAA,IAAU,CAACyK,QAAA,CAAS5E,IAAA,CAAK,GAAG;cAC3FwE,YAAA,IAAgB,OAAOQ,mBAAA,CAAoBlE,KAAA,CAAM3G,MAAM;YACzD,OAAO;cAEL,IAAIzC,SAAA,EAAW;gBACb;cACF;cAGA,IAAI+M,IAAA,CAAKlO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMa,aAAA,EAAe,MAAM,EAAEsN,MAAA,CAAO,KAAKtD,KAAA,CAAM7K,KAAA,CAAMW,YAAY,KAAK,GAAG;gBACnG;cACF;cACA,IAAIiD,gBAAA,CAAiByE,IAAA,CAAKyF,IAAI,GAAG;gBAC/B;cACF;cACA,IAAIjK,iBAAA,CAAkBwE,IAAA,CAAKyF,IAAI,GAAG;gBAChC;cACF;cACA,IAAInK,OAAA,CAAQ0E,IAAA,CAAKyF,IAAI,GAAG;gBACtB;cACF;cAEAD,YAAA,IAAgB,OAAOI,QAAA;YACzB;YAEA,IAAI,CAAClN,SAAA,IAAa,CAACkN,QAAA,CAAS5E,IAAA,CAAK,GAAG;cAClCtI,SAAA,GAAY;YACd;YAEA4J,GAAA,IAAOyD,OAAA,GAAU;YACjBlC,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUiB,OAAA,CAAQ7E,MAAA,GAAS,CAAC;YACtCuE,IAAA,GAAOO,mBAAA,CAAoBlE,KAAA,CAAM3G,MAAM;UACzC;QACF;QAEA,IAAI,CAAC6J,KAAA,CAAKG,KAAA,EAAO;UAEf,IAAIG,iBAAA,EAAmB;YACrBN,KAAA,CAAKG,KAAA,GAAQ;UACf,WAAW,KAAK3C,KAAA,CAAM7K,KAAA,CAAMgB,eAAA,CAAgBqH,IAAA,CAAKsC,GAAG,GAAG;YACrDgD,iBAAA,GAAoB;UACtB;QACF;QAEA,IAAIW,MAAA,GAAiC;QACrC,IAAIC,SAAA;QAEJ,IAAI,KAAKvC,OAAA,CAAQrN,GAAA,EAAK;UACpB2P,MAAA,GAAS,KAAKzD,KAAA,CAAM7K,KAAA,CAAMsB,UAAA,CAAWhC,IAAA,CAAKuO,YAAY;UACtD,IAAIS,MAAA,EAAQ;YACVC,SAAA,GAAYD,MAAA,CAAO,CAAC,MAAM;YAC1BT,YAAA,GAAeA,YAAA,CAAajO,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMuB,eAAA,EAAiB,EAAE;UAC1E;QACF;QAEA8L,KAAA,CAAKI,KAAA,CAAM9D,IAAA,CAAK;UACduB,IAAA,EAAM;UACNP,GAAA;UACA6D,IAAA,EAAM,CAAC,CAACF,MAAA;UACRG,OAAA,EAASF,SAAA;UACTf,KAAA,EAAO;UACPnI,IAAA,EAAMwI,YAAA;UACN1C,MAAA,EAAQ;QACV,CAAC;QAEDkC,KAAA,CAAK1C,GAAA,IAAOA,GAAA;MACd;MAGA,MAAM+D,QAAA,GAAWrB,KAAA,CAAKI,KAAA,CAAMjE,EAAA,CAAG,EAAE;MACjC,IAAIkF,QAAA,EAAU;QACZA,QAAA,CAAS/D,GAAA,GAAM+D,QAAA,CAAS/D,GAAA,CAAIgE,OAAA,CAAQ;QACpCD,QAAA,CAASrJ,IAAA,GAAOqJ,QAAA,CAASrJ,IAAA,CAAKsJ,OAAA,CAAQ;MACxC,OAAO;QAEL;MACF;MACAtB,KAAA,CAAK1C,GAAA,GAAM0C,KAAA,CAAK1C,GAAA,CAAIgE,OAAA,CAAQ;MAG5B,SAASvF,CAAA,GAAI,GAAGA,CAAA,GAAIiE,KAAA,CAAKI,KAAA,CAAMlE,MAAA,EAAQH,CAAA,IAAK;QAC1C,KAAKmD,KAAA,CAAMxB,KAAA,CAAM8B,GAAA,GAAM;QACvBQ,KAAA,CAAKI,KAAA,CAAMrE,CAAC,EAAE+B,MAAA,GAAS,KAAKoB,KAAA,CAAMO,WAAA,CAAYO,KAAA,CAAKI,KAAA,CAAMrE,CAAC,EAAE/D,IAAA,EAAM,EAAE;QAEpE,IAAI,CAACgI,KAAA,CAAKG,KAAA,EAAO;UAEf,MAAMoB,OAAA,GAAUvB,KAAA,CAAKI,KAAA,CAAMrE,CAAC,EAAE+B,MAAA,CAAO0D,MAAA,CAAOd,CAAA,IAAKA,CAAA,CAAE7C,IAAA,KAAS,OAAO;UACnE,MAAM4D,qBAAA,GAAwBF,OAAA,CAAQrF,MAAA,GAAS,KAAKqF,OAAA,CAAQG,IAAA,CAAKhB,CAAA,IAAK,KAAKlD,KAAA,CAAM7K,KAAA,CAAMwB,OAAA,CAAQ6G,IAAA,CAAK0F,CAAA,CAAEpD,GAAG,CAAC;UAE1G0C,KAAA,CAAKG,KAAA,GAAQsB,qBAAA;QACf;MACF;MAGA,IAAIzB,KAAA,CAAKG,KAAA,EAAO;QACd,SAASpE,CAAA,GAAI,GAAGA,CAAA,GAAIiE,KAAA,CAAKI,KAAA,CAAMlE,MAAA,EAAQH,CAAA,IAAK;UAC1CiE,KAAA,CAAKI,KAAA,CAAMrE,CAAC,EAAEoE,KAAA,GAAQ;QACxB;MACF;MAEA,OAAOH,KAAA;IACT;EACF;EAEAtI,KAAKmH,GAAA,EAAsC;IACzC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM7C,IAAA,CAAKzF,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,MAAMQ,KAAA,GAAqB;QACzBC,IAAA,EAAM;QACNtD,KAAA,EAAO;QACP+C,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVuE,GAAA,EAAKvE,GAAA,CAAI,CAAC,MAAM,SAASA,GAAA,CAAI,CAAC,MAAM,YAAYA,GAAA,CAAI,CAAC,MAAM;QAC3DpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;MACb;MACA,OAAOQ,KAAA;IACT;EACF;EAEAtG,IAAIuH,GAAA,EAAqC;IACvC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMjD,GAAA,CAAIrF,IAAA,CAAK4M,GAAG;IACzC,IAAIzB,GAAA,EAAK;MACP,MAAMwE,IAAA,GAAMxE,GAAA,CAAI,CAAC,EAAEyE,WAAA,CAAY,EAAEtP,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMc,mBAAA,EAAqB,GAAG;MAClF,MAAMyH,IAAA,GAAOkC,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMyB,YAAA,EAAc,IAAI,EAAE7B,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI;MAC5H,MAAMkE,KAAA,GAAQL,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAE0C,SAAA,CAAU,GAAG1C,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS,CAAC,EAAE3J,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI6D,GAAA,CAAI,CAAC;MACrH,OAAO;QACLS,IAAA,EAAM;QACNnE,GAAA,EAAAkI,IAAA;QACAtE,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVlC,IAAA;QACAuC;MACF;IACF;EACF;EAEA1F,MAAM8G,GAAA,EAAuC;IAC3C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMxC,KAAA,CAAM9F,IAAA,CAAK4M,GAAG;IAC3C,IAAI,CAACzB,GAAA,EAAK;MACR;IACF;IAEA,IAAI,CAAC,KAAKI,KAAA,CAAM7K,KAAA,CAAM0B,cAAA,CAAe2G,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;MAEjD;IACF;IAEA,MAAM0E,OAAA,GAAU1G,UAAA,CAAWgC,GAAA,CAAI,CAAC,CAAC;IACjC,MAAM2E,MAAA,GAAS3E,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAM2B,eAAA,EAAiB,EAAE,EAAEwH,KAAA,CAAM,GAAG;IAC7E,MAAMkG,IAAA,GAAO5E,GAAA,CAAI,CAAC,GAAGpB,IAAA,CAAK,IAAIoB,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAM4B,iBAAA,EAAmB,EAAE,EAAEuH,KAAA,CAAM,IAAI,IAAI,EAAC;IAEpG,MAAMmG,IAAA,GAAqB;MACzBpE,IAAA,EAAM;MACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;MACV8E,MAAA,EAAQ,EAAC;MACTC,KAAA,EAAO,EAAC;MACRH,IAAA,EAAM;IACR;IAEA,IAAIF,OAAA,CAAQ5F,MAAA,KAAW6F,MAAA,CAAO7F,MAAA,EAAQ;MAEpC;IACF;IAEA,WAAWiG,KAAA,IAASJ,MAAA,EAAQ;MAC1B,IAAI,KAAKvE,KAAA,CAAM7K,KAAA,CAAM6B,eAAA,CAAgBwG,IAAA,CAAKmH,KAAK,GAAG;QAChDF,IAAA,CAAKE,KAAA,CAAM7F,IAAA,CAAK,OAAO;MACzB,WAAW,KAAKkB,KAAA,CAAM7K,KAAA,CAAM8B,gBAAA,CAAiBuG,IAAA,CAAKmH,KAAK,GAAG;QACxDF,IAAA,CAAKE,KAAA,CAAM7F,IAAA,CAAK,QAAQ;MAC1B,WAAW,KAAKkB,KAAA,CAAM7K,KAAA,CAAM+B,cAAA,CAAesG,IAAA,CAAKmH,KAAK,GAAG;QACtDF,IAAA,CAAKE,KAAA,CAAM7F,IAAA,CAAK,MAAM;MACxB,OAAO;QACL2F,IAAA,CAAKE,KAAA,CAAM7F,IAAA,CAAK,IAAI;MACtB;IACF;IAEA,SAASP,CAAA,GAAI,GAAGA,CAAA,GAAI+F,OAAA,CAAQ5F,MAAA,EAAQH,CAAA,IAAK;MACvCkG,IAAA,CAAKC,MAAA,CAAO5F,IAAA,CAAK;QACftE,IAAA,EAAM8J,OAAA,CAAQ/F,CAAC;QACf+B,MAAA,EAAQ,KAAKoB,KAAA,CAAMzE,MAAA,CAAOqH,OAAA,CAAQ/F,CAAC,CAAC;QACpCmG,MAAA,EAAQ;QACRC,KAAA,EAAOF,IAAA,CAAKE,KAAA,CAAMpG,CAAC;MACrB,CAAC;IACH;IAEA,WAAWR,GAAA,IAAOyG,IAAA,EAAM;MACtBC,IAAA,CAAKD,IAAA,CAAK1F,IAAA,CAAKlB,UAAA,CAAWG,GAAA,EAAK0G,IAAA,CAAKC,MAAA,CAAOhG,MAAM,EAAEgC,GAAA,CAAI,CAACkE,IAAA,EAAMrG,CAAA,KAAM;QAClE,OAAO;UACL/D,IAAA,EAAMoK,IAAA;UACNtE,MAAA,EAAQ,KAAKoB,KAAA,CAAMzE,MAAA,CAAO2H,IAAI;UAC9BF,MAAA,EAAQ;UACRC,KAAA,EAAOF,IAAA,CAAKE,KAAA,CAAMpG,CAAC;QACrB;MACF,CAAC,CAAC;IACJ;IAEA,OAAOkG,IAAA;EACT;EAEAhL,SAAS4H,GAAA,EAAyC;IAChD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMtD,QAAA,CAAShF,IAAA,CAAK4M,GAAG;IAC9C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACV6B,KAAA,EAAO7B,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAO,CAAC,MAAM,MAAM,IAAI;QACtC7E,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXU,MAAA,EAAQ,KAAKoB,KAAA,CAAMzE,MAAA,CAAO2C,GAAA,CAAI,CAAC,CAAC;MAClC;IACF;EACF;EAEAzF,UAAUkH,GAAA,EAA2C;IACnD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAM5C,SAAA,CAAU1F,IAAA,CAAK4M,GAAG;IAC/C,IAAIzB,GAAA,EAAK;MACP,MAAMpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAOO,GAAA,CAAI,CAAC,EAAElB,MAAA,GAAS,CAAC,MAAM,OAC9CkB,GAAA,CAAI,CAAC,EAAEN,KAAA,CAAM,GAAG,EAAE,IAClBM,GAAA,CAAI,CAAC;MACT,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA;QACA8F,MAAA,EAAQ,KAAKoB,KAAA,CAAMzE,MAAA,CAAOzC,IAAI;MAChC;IACF;EACF;EAEAA,KAAK6G,GAAA,EAAsC;IACzC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAMjD,KAAA,CAAMvC,IAAA,CAAK/F,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXU,MAAA,EAAQ,KAAKoB,KAAA,CAAMzE,MAAA,CAAO2C,GAAA,CAAI,CAAC,CAAC;MAClC;IACF;EACF;EAEAhF,OAAOyG,GAAA,EAAwC;IAC7C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOrC,MAAA,CAAOnG,IAAA,CAAK4M,GAAG;IAC7C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;MACb;IACF;EACF;EAEA1D,IAAImF,GAAA,EAAqC;IACvC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOf,GAAA,CAAIzH,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,IAAI,CAAC,KAAK8B,KAAA,CAAMxB,KAAA,CAAMC,MAAA,IAAU,KAAKH,KAAA,CAAM7K,KAAA,CAAMgC,SAAA,CAAUqG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QACvE,KAAK8B,KAAA,CAAMxB,KAAA,CAAMC,MAAA,GAAS;MAC5B,WAAW,KAAKuB,KAAA,CAAMxB,KAAA,CAAMC,MAAA,IAAU,KAAKH,KAAA,CAAM7K,KAAA,CAAMiC,OAAA,CAAQoG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QAC3E,KAAK8B,KAAA,CAAMxB,KAAA,CAAMC,MAAA,GAAS;MAC5B;MACA,IAAI,CAAC,KAAKuB,KAAA,CAAMxB,KAAA,CAAM2E,UAAA,IAAc,KAAK7E,KAAA,CAAM7K,KAAA,CAAMkC,iBAAA,CAAkBmG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QACnF,KAAK8B,KAAA,CAAMxB,KAAA,CAAM2E,UAAA,GAAa;MAChC,WAAW,KAAKnD,KAAA,CAAMxB,KAAA,CAAM2E,UAAA,IAAc,KAAK7E,KAAA,CAAM7K,KAAA,CAAMmC,eAAA,CAAgBkG,IAAA,CAAKoC,GAAA,CAAI,CAAC,CAAC,GAAG;QACvF,KAAK8B,KAAA,CAAMxB,KAAA,CAAM2E,UAAA,GAAa;MAChC;MAEA,OAAO;QACLxE,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVO,MAAA,EAAQ,KAAKuB,KAAA,CAAMxB,KAAA,CAAMC,MAAA;QACzB0E,UAAA,EAAY,KAAKnD,KAAA,CAAMxB,KAAA,CAAM2E,UAAA;QAC7B9H,KAAA,EAAO;QACPvC,IAAA,EAAMoF,GAAA,CAAI,CAAC;MACb;IACF;EACF;EAEAxD,KAAKiF,GAAA,EAAqD;IACxD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOb,IAAA,CAAK3H,IAAA,CAAK4M,GAAG;IAC3C,IAAIzB,GAAA,EAAK;MACP,MAAMkF,UAAA,GAAalF,GAAA,CAAI,CAAC,EAAEpB,IAAA,CAAK;MAC/B,IAAI,CAAC,KAAK2C,OAAA,CAAQnN,QAAA,IAAY,KAAKgM,KAAA,CAAM7K,KAAA,CAAMoC,iBAAA,CAAkBiG,IAAA,CAAKsH,UAAU,GAAG;QAEjF,IAAI,CAAE,KAAK9E,KAAA,CAAM7K,KAAA,CAAMqC,eAAA,CAAgBgG,IAAA,CAAKsH,UAAU,GAAI;UACxD;QACF;QAGA,MAAMC,UAAA,GAAahG,KAAA,CAAM+F,UAAA,CAAWxF,KAAA,CAAM,GAAG,EAAE,GAAG,IAAI;QACtD,KAAKwF,UAAA,CAAWpG,MAAA,GAASqG,UAAA,CAAWrG,MAAA,IAAU,MAAM,GAAG;UACrD;QACF;MACF,OAAO;QAEL,MAAMsG,cAAA,GAAiBzF,kBAAA,CAAmBK,GAAA,CAAI,CAAC,GAAG,IAAI;QACtD,IAAIoF,cAAA,KAAmB,IAAI;UAEzB;QACF;QAEA,IAAIA,cAAA,GAAiB,IAAI;UACvB,MAAMtC,KAAA,GAAQ9C,GAAA,CAAI,CAAC,EAAEH,OAAA,CAAQ,GAAG,MAAM,IAAI,IAAI;UAC9C,MAAMwF,OAAA,GAAUvC,KAAA,GAAQ9C,GAAA,CAAI,CAAC,EAAElB,MAAA,GAASsG,cAAA;UACxCpF,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAE0C,SAAA,CAAU,GAAG0C,cAAc;UAC3CpF,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAE0C,SAAA,CAAU,GAAG2C,OAAO,EAAEzG,IAAA,CAAK;UAC3CoB,GAAA,CAAI,CAAC,IAAI;QACX;MACF;MACA,IAAIlC,IAAA,GAAOkC,GAAA,CAAI,CAAC;MAChB,IAAIK,KAAA,GAAQ;MACZ,IAAI,KAAKkB,OAAA,CAAQnN,QAAA,EAAU;QAEzB,MAAM6L,KAAA,GAAO,KAAKG,KAAA,CAAM7K,KAAA,CAAMsC,iBAAA,CAAkBhD,IAAA,CAAKiJ,IAAI;QAEzD,IAAImC,KAAA,EAAM;UACRnC,IAAA,GAAOmC,KAAA,CAAK,CAAC;UACbI,KAAA,GAAQJ,KAAA,CAAK,CAAC;QAChB;MACF,OAAO;QACLI,KAAA,GAAQL,GAAA,CAAI,CAAC,IAAIA,GAAA,CAAI,CAAC,EAAEN,KAAA,CAAM,GAAG,EAAE,IAAI;MACzC;MAEA5B,IAAA,GAAOA,IAAA,CAAKc,IAAA,CAAK;MACjB,IAAI,KAAKwB,KAAA,CAAM7K,KAAA,CAAMoC,iBAAA,CAAkBiG,IAAA,CAAKE,IAAI,GAAG;QACjD,IAAI,KAAKyD,OAAA,CAAQnN,QAAA,IAAY,CAAE,KAAKgM,KAAA,CAAM7K,KAAA,CAAMqC,eAAA,CAAgBgG,IAAA,CAAKsH,UAAU,GAAI;UAEjFpH,IAAA,GAAOA,IAAA,CAAK4B,KAAA,CAAM,CAAC;QACrB,OAAO;UACL5B,IAAA,GAAOA,IAAA,CAAK4B,KAAA,CAAM,GAAG,EAAE;QACzB;MACF;MACA,OAAOK,UAAA,CAAWC,GAAA,EAAK;QACrBlC,IAAA,EAAMA,IAAA,GAAOA,IAAA,CAAK3I,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAI2B,IAAA;QACpEuC,KAAA,EAAOA,KAAA,GAAQA,KAAA,CAAMlL,OAAA,CAAQ,KAAKiL,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,EAAgB,IAAI,IAAIkE;MACzE,GAAGL,GAAA,CAAI,CAAC,GAAG,KAAK8B,KAAA,EAAO,KAAK1B,KAAK;IACnC;EACF;EAEA3D,QAAQgF,GAAA,EAAa6D,KAAA,EAAoE;IACvF,IAAItF,GAAA;IACJ,KAAKA,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOZ,OAAA,CAAQ5H,IAAA,CAAK4M,GAAG,OACvCzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOX,MAAA,CAAO7H,IAAA,CAAK4M,GAAG,IAAI;MAC/C,MAAM8D,UAAA,IAAcvF,GAAA,CAAI,CAAC,KAAKA,GAAA,CAAI,CAAC,GAAG7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMc,mBAAA,EAAqB,GAAG;MACvF,MAAM4J,KAAA,GAAOqF,KAAA,CAAMC,UAAA,CAAWd,WAAA,CAAY,CAAC;MAC3C,IAAI,CAACxE,KAAA,EAAM;QACT,MAAMrF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAEP,MAAA,CAAO,CAAC;QAC5B,OAAO;UACLgB,IAAA,EAAM;UACNP,GAAA,EAAKtF,IAAA;UACLA;QACF;MACF;MACA,OAAOmF,UAAA,CAAWC,GAAA,EAAKC,KAAA,EAAMD,GAAA,CAAI,CAAC,GAAG,KAAK8B,KAAA,EAAO,KAAK1B,KAAK;IAC7D;EACF;EAEAoF,SAAS/D,GAAA,EAAagE,SAAA,EAAmBC,QAAA,GAAW,IAA2C;IAC7F,IAAItH,KAAA,GAAQ,KAAKgC,KAAA,CAAM/C,MAAA,CAAOxB,cAAA,CAAehH,IAAA,CAAK4M,GAAG;IACrD,IAAI,CAACrD,KAAA,EAAO;IAGZ,IAAIA,KAAA,CAAM,CAAC,KAAKsH,QAAA,CAAStH,KAAA,CAAM,KAAKgC,KAAA,CAAM7K,KAAA,CAAMuC,mBAAmB,GAAG;IAEtE,MAAM6N,QAAA,GAAWvH,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAK;IAEzC,IAAI,CAACuH,QAAA,IAAY,CAACD,QAAA,IAAY,KAAKtF,KAAA,CAAM/C,MAAA,CAAO9B,WAAA,CAAY1G,IAAA,CAAK6Q,QAAQ,GAAG;MAE1E,MAAME,OAAA,GAAU,CAAC,GAAGxH,KAAA,CAAM,CAAC,CAAC,EAAEU,MAAA,GAAS;MACvC,IAAI+G,MAAA;QAAQC,OAAA;QAASC,UAAA,GAAaH,OAAA;QAASI,aAAA,GAAgB;MAE3D,MAAMC,MAAA,GAAS7H,KAAA,CAAM,CAAC,EAAE,CAAC,MAAM,MAAM,KAAKgC,KAAA,CAAM/C,MAAA,CAAOrB,iBAAA,GAAoB,KAAKoE,KAAA,CAAM/C,MAAA,CAAOnB,iBAAA;MAC7F+J,MAAA,CAAOC,SAAA,GAAY;MAGnBT,SAAA,GAAYA,SAAA,CAAU/F,KAAA,CAAM,KAAK+B,GAAA,CAAI3C,MAAA,GAAS8G,OAAO;MAErD,QAAQxH,KAAA,GAAQ6H,MAAA,CAAOpR,IAAA,CAAK4Q,SAAS,MAAM,MAAM;QAC/CI,MAAA,GAASzH,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC;QAE5E,IAAI,CAACyH,MAAA,EAAQ;QAEbC,OAAA,GAAU,CAAC,GAAGD,MAAM,EAAE/G,MAAA;QAEtB,IAAIV,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,GAAG;UACxB2H,UAAA,IAAcD,OAAA;UACd;QACF,WAAW1H,KAAA,CAAM,CAAC,KAAKA,KAAA,CAAM,CAAC,GAAG;UAC/B,IAAIwH,OAAA,GAAU,KAAK,GAAGA,OAAA,GAAUE,OAAA,IAAW,IAAI;YAC7CE,aAAA,IAAiBF,OAAA;YACjB;UACF;QACF;QAEAC,UAAA,IAAcD,OAAA;QAEd,IAAIC,UAAA,GAAa,GAAG;QAGpBD,OAAA,GAAU9M,IAAA,CAAKC,GAAA,CAAI6M,OAAA,EAASA,OAAA,GAAUC,UAAA,GAAaC,aAAa;QAEhE,MAAMG,cAAA,GAAiB,CAAC,GAAG/H,KAAA,CAAM,CAAC,CAAC,EAAE,CAAC,EAAEU,MAAA;QACxC,MAAMoB,GAAA,GAAMuB,GAAA,CAAI/B,KAAA,CAAM,GAAGkG,OAAA,GAAUxH,KAAA,CAAMgI,KAAA,GAAQD,cAAA,GAAiBL,OAAO;QAGzE,IAAI9M,IAAA,CAAKC,GAAA,CAAI2M,OAAA,EAASE,OAAO,IAAI,GAAG;UAClC,MAAMO,KAAA,GAAOnG,GAAA,CAAIR,KAAA,CAAM,GAAG,EAAE;UAC5B,OAAO;YACLe,IAAA,EAAM;YACNP,GAAA;YACAtF,IAAA,EAAAyL,KAAA;YACA3F,MAAA,EAAQ,KAAKoB,KAAA,CAAMnB,YAAA,CAAa0F,KAAI;UACtC;QACF;QAGA,MAAMzL,IAAA,GAAOsF,GAAA,CAAIR,KAAA,CAAM,GAAG,EAAE;QAC5B,OAAO;UACLe,IAAA,EAAM;UACNP,GAAA;UACAtF,IAAA;UACA8F,MAAA,EAAQ,KAAKoB,KAAA,CAAMnB,YAAA,CAAa/F,IAAI;QACtC;MACF;IACF;EACF;EAEA0L,SAAS7E,GAAA,EAA0C;IACjD,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAO3C,IAAA,CAAK7F,IAAA,CAAK4M,GAAG;IAC3C,IAAIzB,GAAA,EAAK;MACP,IAAIpF,IAAA,GAAOoF,GAAA,CAAI,CAAC,EAAE7K,OAAA,CAAQ,KAAKiL,KAAA,CAAM7K,KAAA,CAAMY,iBAAA,EAAmB,GAAG;MACjE,MAAMoQ,gBAAA,GAAmB,KAAKnG,KAAA,CAAM7K,KAAA,CAAMW,YAAA,CAAa0H,IAAA,CAAKhD,IAAI;MAChE,MAAM4L,uBAAA,GAA0B,KAAKpG,KAAA,CAAM7K,KAAA,CAAMS,iBAAA,CAAkB4H,IAAA,CAAKhD,IAAI,KAAK,KAAKwF,KAAA,CAAM7K,KAAA,CAAMU,eAAA,CAAgB2H,IAAA,CAAKhD,IAAI;MAC3H,IAAI2L,gBAAA,IAAoBC,uBAAA,EAAyB;QAC/C5L,IAAA,GAAOA,IAAA,CAAK8H,SAAA,CAAU,GAAG9H,IAAA,CAAKkE,MAAA,GAAS,CAAC;MAC1C;MACA,OAAO;QACL2B,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF;MACF;IACF;EACF;EAEAM,GAAGuG,GAAA,EAAoC;IACrC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOnC,EAAA,CAAGrG,IAAA,CAAK4M,GAAG;IACzC,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;MACZ;IACF;EACF;EAEAlD,IAAI2E,GAAA,EAAqC;IACvC,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOP,GAAA,CAAIjI,IAAA,CAAK4M,GAAG;IAC1C,IAAIzB,GAAA,EAAK;MACP,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXU,MAAA,EAAQ,KAAKoB,KAAA,CAAMnB,YAAA,CAAaX,GAAA,CAAI,CAAC,CAAC;MACxC;IACF;EACF;EAEA5D,SAASqF,GAAA,EAAsC;IAC7C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOjB,QAAA,CAASvH,IAAA,CAAK4M,GAAG;IAC/C,IAAIzB,GAAA,EAAK;MACP,IAAIpF,IAAA,EAAMkD,IAAA;MACV,IAAIkC,GAAA,CAAI,CAAC,MAAM,KAAK;QAClBpF,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZlC,IAAA,GAAO,YAAYlD,IAAA;MACrB,OAAO;QACLA,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZlC,IAAA,GAAOlD,IAAA;MACT;MAEA,OAAO;QACL6F,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA;QACAkD,IAAA;QACA4C,MAAA,EAAQ,CACN;UACED,IAAA,EAAM;UACNP,GAAA,EAAKtF,IAAA;UACLA;QACF;MAEJ;IACF;EACF;EAEAmC,IAAI0E,GAAA,EAAsC;IACxC,IAAIzB,GAAA;IACJ,IAAIA,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAON,GAAA,CAAIlI,IAAA,CAAK4M,GAAG,GAAG;MACzC,IAAI7G,IAAA,EAAMkD,IAAA;MACV,IAAIkC,GAAA,CAAI,CAAC,MAAM,KAAK;QAClBpF,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZlC,IAAA,GAAO,YAAYlD,IAAA;MACrB,OAAO;QAEL,IAAI6L,WAAA;QACJ,GAAG;UACDA,WAAA,GAAczG,GAAA,CAAI,CAAC;UACnBA,GAAA,CAAI,CAAC,IAAI,KAAKI,KAAA,CAAM/C,MAAA,CAAOR,UAAA,CAAWhI,IAAA,CAAKmL,GAAA,CAAI,CAAC,CAAC,IAAI,CAAC,KAAK;QAC7D,SAASyG,WAAA,KAAgBzG,GAAA,CAAI,CAAC;QAC9BpF,IAAA,GAAOoF,GAAA,CAAI,CAAC;QACZ,IAAIA,GAAA,CAAI,CAAC,MAAM,QAAQ;UACrBlC,IAAA,GAAO,YAAYkC,GAAA,CAAI,CAAC;QAC1B,OAAO;UACLlC,IAAA,GAAOkC,GAAA,CAAI,CAAC;QACd;MACF;MACA,OAAO;QACLS,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA;QACAkD,IAAA;QACA4C,MAAA,EAAQ,CACN;UACED,IAAA,EAAM;UACNP,GAAA,EAAKtF,IAAA;UACLA;QACF;MAEJ;IACF;EACF;EAEAO,WAAWsG,GAAA,EAAsC;IAC/C,MAAMzB,GAAA,GAAM,KAAKI,KAAA,CAAM/C,MAAA,CAAOzC,IAAA,CAAK/F,IAAA,CAAK4M,GAAG;IAC3C,IAAIzB,GAAA,EAAK;MACP,MAAMzB,OAAA,GAAU,KAAKuD,KAAA,CAAMxB,KAAA,CAAM2E,UAAA;MACjC,OAAO;QACLxE,IAAA,EAAM;QACNP,GAAA,EAAKF,GAAA,CAAI,CAAC;QACVpF,IAAA,EAAMoF,GAAA,CAAI,CAAC;QACXzB;MACF;IACF;EACF;AACF;;;ACn2BO,IAAMmI,MAAA,GAAN,MAAMC,OAAA,CAAO;EAYlBvF,YAAYC,QAAA,EAAyB;IAAAC,eAAA;IAAAA,eAAA;IAAAA,eAAA;IAAAA,eAAA;IAAAA,eAAA;IAEnC,KAAKZ,MAAA,GAAS,EAAC;IACf,KAAKA,MAAA,CAAO4E,KAAA,GAAQ,eAAAsB,MAAA,CAAOC,MAAA,CAAO,IAAI;IACtC,KAAKtF,OAAA,GAAUF,QAAA,IAAW5M,SAAA;IAC1B,KAAK8M,OAAA,CAAQhN,SAAA,GAAY,KAAKgN,OAAA,CAAQhN,SAAA,IAAa,IAAI4M,UAAA,CAAW;IAClE,KAAK5M,SAAA,GAAY,KAAKgN,OAAA,CAAQhN,SAAA;IAC9B,KAAKA,SAAA,CAAUgN,OAAA,GAAU,KAAKA,OAAA;IAC9B,KAAKhN,SAAA,CAAUuN,KAAA,GAAQ;IACvB,KAAKgF,WAAA,GAAc,EAAC;IACpB,KAAKxG,KAAA,GAAQ;MACXC,MAAA,EAAQ;MACR0E,UAAA,EAAY;MACZ7C,GAAA,EAAK;IACP;IAEA,MAAMhC,KAAA,GAAQ;MACZ7K,KAAA;MACA4H,KAAA,EAAOA,KAAA,CAAMC,MAAA;MACbC,MAAA,EAAQA,MAAA,CAAOD;IACjB;IAEA,IAAI,KAAKmE,OAAA,CAAQnN,QAAA,EAAU;MACzBgM,KAAA,CAAMjD,KAAA,GAAQA,KAAA,CAAM/I,QAAA;MACpBgM,KAAA,CAAM/C,MAAA,GAASA,MAAA,CAAOjJ,QAAA;IACxB,WAAW,KAAKmN,OAAA,CAAQrN,GAAA,EAAK;MAC3BkM,KAAA,CAAMjD,KAAA,GAAQA,KAAA,CAAMjJ,GAAA;MACpB,IAAI,KAAKqN,OAAA,CAAQvN,MAAA,EAAQ;QACvBoM,KAAA,CAAM/C,MAAA,GAASA,MAAA,CAAOrJ,MAAA;MACxB,OAAO;QACLoM,KAAA,CAAM/C,MAAA,GAASA,MAAA,CAAOnJ,GAAA;MACxB;IACF;IACA,KAAKK,SAAA,CAAU6L,KAAA,GAAQA,KAAA;EACzB;EAAA;AAAA;AAAA;EAKA,WAAWA,MAAA,EAAQ;IACjB,OAAO;MACLjD,KAAA;MACAE;IACF;EACF;EAAA;AAAA;AAAA;EAKA,OAAO0J,IAAItF,GAAA,EAAaJ,QAAA,EAAyB;IAC/C,MAAMlB,MAAA,GAAQ,IAAIwG,OAAA,CAAOtF,QAAO;IAChC,OAAOlB,MAAA,CAAM4G,GAAA,CAAItF,GAAG;EACtB;EAAA;AAAA;AAAA;EAKA,OAAOuF,UAAUvF,GAAA,EAAaJ,QAAA,EAAyB;IACrD,MAAMlB,MAAA,GAAQ,IAAIwG,OAAA,CAAOtF,QAAO;IAChC,OAAOlB,MAAA,CAAMQ,YAAA,CAAac,GAAG;EAC/B;EAAA;AAAA;AAAA;EAKAsF,IAAItF,GAAA,EAAa;IACfA,GAAA,GAAMA,GAAA,CAAItM,OAAA,CAAQI,KAAA,CAAMiD,cAAA,EAAgB,IAAI;IAE5C,KAAK6J,WAAA,CAAYZ,GAAA,EAAK,KAAKf,MAAM;IAEjC,SAAS/B,CAAA,GAAI,GAAGA,CAAA,GAAI,KAAKmI,WAAA,CAAYhI,MAAA,EAAQH,CAAA,IAAK;MAChD,MAAMsI,IAAA,GAAO,KAAKH,WAAA,CAAYnI,CAAC;MAC/B,KAAKgC,YAAA,CAAasG,IAAA,CAAKxF,GAAA,EAAKwF,IAAA,CAAKvG,MAAM;IACzC;IACA,KAAKoG,WAAA,GAAc,EAAC;IAEpB,OAAO,KAAKpG,MAAA;EACd;EAOA2B,YAAYZ,GAAA,EAAaf,MAAA,GAAkB,EAAC,EAAGwG,oBAAA,GAAuB,OAAO;IAC3E,IAAI,KAAK3F,OAAA,CAAQnN,QAAA,EAAU;MACzBqN,GAAA,GAAMA,GAAA,CAAItM,OAAA,CAAQI,KAAA,CAAMa,aAAA,EAAe,MAAM,EAAEjB,OAAA,CAAQI,KAAA,CAAMkD,SAAA,EAAW,EAAE;IAC5E;IAEA,OAAOgJ,GAAA,EAAK;MACV,IAAIjB,KAAA;MAEJ,IAAI,KAAKe,OAAA,CAAQtN,UAAA,EAAYkJ,KAAA,EAAOmH,IAAA,CAAM6C,YAAA,IAAiB;QACzD,IAAI3G,KAAA,GAAQ2G,YAAA,CAAaC,IAAA,CAAK;UAAEtF,KAAA,EAAO;QAAK,GAAGL,GAAA,EAAKf,MAAM,GAAG;UAC3De,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;UACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;UACjB,OAAO;QACT;QACA,OAAO;MACT,CAAC,GAAG;QACF;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiN,KAAA,CAAMC,GAAG,GAAG;QACrCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMwD,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIyB,KAAA,CAAMN,GAAA,CAAIpB,MAAA,KAAW,KAAKwD,SAAA,KAAc,QAAW;UAGrDA,SAAA,CAAUpC,GAAA,IAAO;QACnB,OAAO;UACLQ,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUmG,IAAA,CAAK+G,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMwD,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAE9B,IAAIuD,SAAA,EAAW7B,IAAA,KAAS,eAAe6B,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UACjE6B,SAAA,CAAUpC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BoC,SAAA,CAAU1H,IAAA,IAAQ,OAAO4F,KAAA,CAAM5F,IAAA;UAC/B,KAAKkM,WAAA,CAAY/H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMa,SAAA,CAAU1H,IAAA;QAC3C,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiF,MAAA,CAAOiI,GAAG,GAAG;QACtCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUmF,OAAA,CAAQ+H,GAAG,GAAG;QACvCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUkF,EAAA,CAAGgI,GAAG,GAAG;QAClCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiG,UAAA,CAAWiH,GAAG,GAAG;QAC1CA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU4F,IAAA,CAAKsH,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU+F,IAAA,CAAKmH,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU2F,GAAA,CAAIuH,GAAG,GAAG;QACnCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMwD,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIuD,SAAA,EAAW7B,IAAA,KAAS,eAAe6B,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UACjE6B,SAAA,CAAUpC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BoC,SAAA,CAAU1H,IAAA,IAAQ,OAAO4F,KAAA,CAAMN,GAAA;UAC/B,KAAK4G,WAAA,CAAY/H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMa,SAAA,CAAU1H,IAAA;QAC3C,WAAW,CAAC,KAAK8F,MAAA,CAAO4E,KAAA,CAAM9E,KAAA,CAAMlE,GAAG,GAAG;UACxC,KAAKoE,MAAA,CAAO4E,KAAA,CAAM9E,KAAA,CAAMlE,GAAG,IAAI;YAC7BwB,IAAA,EAAM0C,KAAA,CAAM1C,IAAA;YACZuC,KAAA,EAAOG,KAAA,CAAMH;UACf;QACF;QACA;MACF;MAGA,IAAIG,KAAA,GAAQ,KAAKjM,SAAA,CAAUoG,KAAA,CAAM8G,GAAG,GAAG;QACrCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUsF,QAAA,CAAS4H,GAAG,GAAG;QACxCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAIA,IAAI6G,MAAA,GAAS5F,GAAA;MACb,IAAI,KAAKF,OAAA,CAAQtN,UAAA,EAAYqT,UAAA,EAAY;QACvC,IAAIC,UAAA,GAAaC,QAAA;QACjB,MAAMC,OAAA,GAAUhG,GAAA,CAAI/B,KAAA,CAAM,CAAC;QAC3B,IAAIgI,SAAA;QACJ,KAAKnG,OAAA,CAAQtN,UAAA,CAAWqT,UAAA,CAAWK,OAAA,CAASC,aAAA,IAAkB;UAC5DF,SAAA,GAAYE,aAAA,CAAcR,IAAA,CAAK;YAAEtF,KAAA,EAAO;UAAK,GAAG2F,OAAO;UACvD,IAAI,OAAOC,SAAA,KAAc,YAAYA,SAAA,IAAa,GAAG;YACnDH,UAAA,GAAavO,IAAA,CAAKC,GAAA,CAAIsO,UAAA,EAAYG,SAAS;UAC7C;QACF,CAAC;QACD,IAAIH,UAAA,GAAaC,QAAA,IAAYD,UAAA,IAAc,GAAG;UAC5CF,MAAA,GAAS5F,GAAA,CAAIiB,SAAA,CAAU,GAAG6E,UAAA,GAAa,CAAC;QAC1C;MACF;MACA,IAAI,KAAKjH,KAAA,CAAM8B,GAAA,KAAQ5B,KAAA,GAAQ,KAAKjM,SAAA,CAAUgG,SAAA,CAAU8M,MAAM,IAAI;QAChE,MAAM/E,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAImI,oBAAA,IAAwB5E,SAAA,EAAW7B,IAAA,KAAS,aAAa;UAC3D6B,SAAA,CAAUpC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BoC,SAAA,CAAU1H,IAAA,IAAQ,OAAO4F,KAAA,CAAM5F,IAAA;UAC/B,KAAKkM,WAAA,CAAY9H,GAAA,CAAI;UACrB,KAAK8H,WAAA,CAAY/H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMa,SAAA,CAAU1H,IAAA;QAC3C,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA0G,oBAAA,GAAuBG,MAAA,CAAOvI,MAAA,KAAW2C,GAAA,CAAI3C,MAAA;QAC7C2C,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC;MACF;MAGA,IAAI0B,KAAA,GAAQ,KAAKjM,SAAA,CAAUqG,IAAA,CAAK6G,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMwD,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIuD,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UAC9B6B,SAAA,CAAUpC,GAAA,IAAO,OAAOM,KAAA,CAAMN,GAAA;UAC9BoC,SAAA,CAAU1H,IAAA,IAAQ,OAAO4F,KAAA,CAAM5F,IAAA;UAC/B,KAAKkM,WAAA,CAAY9H,GAAA,CAAI;UACrB,KAAK8H,WAAA,CAAY/H,EAAA,CAAG,EAAE,EAAG0C,GAAA,GAAMa,SAAA,CAAU1H,IAAA;QAC3C,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAEA,IAAIiB,GAAA,EAAK;QACP,MAAMoG,MAAA,GAAS,4BAA4BpG,GAAA,CAAIqG,UAAA,CAAW,CAAC;QAC3D,IAAI,KAAKvG,OAAA,CAAQjN,MAAA,EAAQ;UACvByT,OAAA,CAAQC,KAAA,CAAMH,MAAM;UACpB;QACF,OAAO;UACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;QACxB;MACF;IACF;IAEA,KAAKvH,KAAA,CAAM8B,GAAA,GAAM;IACjB,OAAO1B,MAAA;EACT;EAEArD,OAAOoE,GAAA,EAAaf,MAAA,GAAkB,EAAC,EAAG;IACxC,KAAKoG,WAAA,CAAY5H,IAAA,CAAK;MAAEuC,GAAA;MAAKf;IAAO,CAAC;IACrC,OAAOA,MAAA;EACT;EAAA;AAAA;AAAA;EAKAC,aAAac,GAAA,EAAaf,MAAA,GAAkB,EAAC,EAAY;IAEvD,IAAI+E,SAAA,GAAYhE,GAAA;IAChB,IAAIrD,KAAA,GAAgC;IAGpC,IAAI,KAAKsC,MAAA,CAAO4E,KAAA,EAAO;MACrB,MAAMA,KAAA,GAAQsB,MAAA,CAAOsB,IAAA,CAAK,KAAKxH,MAAA,CAAO4E,KAAK;MAC3C,IAAIA,KAAA,CAAMxG,MAAA,GAAS,GAAG;QACpB,QAAQV,KAAA,GAAQ,KAAK7J,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOV,aAAA,CAAc9H,IAAA,CAAK4Q,SAAS,MAAM,MAAM;UAClF,IAAIH,KAAA,CAAM6C,QAAA,CAAS/J,KAAA,CAAM,CAAC,EAAEsB,KAAA,CAAMtB,KAAA,CAAM,CAAC,EAAEgK,WAAA,CAAY,GAAG,IAAI,GAAG,EAAE,CAAC,GAAG;YACrE3C,SAAA,GAAYA,SAAA,CAAU/F,KAAA,CAAM,GAAGtB,KAAA,CAAMgI,KAAK,IACtC,MAAM,IAAI7C,MAAA,CAAOnF,KAAA,CAAM,CAAC,EAAEU,MAAA,GAAS,CAAC,IAAI,MACxC2G,SAAA,CAAU/F,KAAA,CAAM,KAAKnL,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOV,aAAA,CAAcuJ,SAAS;UACzE;QACF;MACF;IACF;IAGA,QAAQ9H,KAAA,GAAQ,KAAK7J,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,CAAetH,IAAA,CAAK4Q,SAAS,MAAM,MAAM;MACnFA,SAAA,GAAYA,SAAA,CAAU/F,KAAA,CAAM,GAAGtB,KAAA,CAAMgI,KAAK,IAAI,OAAOX,SAAA,CAAU/F,KAAA,CAAM,KAAKnL,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAOlB,cAAA,CAAe+J,SAAS;IAC3H;IAGA,QAAQ9H,KAAA,GAAQ,KAAK7J,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAO1B,SAAA,CAAU9G,IAAA,CAAK4Q,SAAS,MAAM,MAAM;MAC9EA,SAAA,GAAYA,SAAA,CAAU/F,KAAA,CAAM,GAAGtB,KAAA,CAAMgI,KAAK,IAAI,MAAM,IAAI7C,MAAA,CAAOnF,KAAA,CAAM,CAAC,EAAEU,MAAA,GAAS,CAAC,IAAI,MAAM2G,SAAA,CAAU/F,KAAA,CAAM,KAAKnL,SAAA,CAAU6L,KAAA,CAAM/C,MAAA,CAAO1B,SAAA,CAAUuK,SAAS;IAC7J;IAEA,IAAImC,YAAA,GAAe;IACnB,IAAI3C,QAAA,GAAW;IACf,OAAOjE,GAAA,EAAK;MACV,IAAI,CAAC4G,YAAA,EAAc;QACjB3C,QAAA,GAAW;MACb;MACA2C,YAAA,GAAe;MAEf,IAAI7H,KAAA;MAGJ,IAAI,KAAKe,OAAA,CAAQtN,UAAA,EAAYoJ,MAAA,EAAQiH,IAAA,CAAM6C,YAAA,IAAiB;QAC1D,IAAI3G,KAAA,GAAQ2G,YAAA,CAAaC,IAAA,CAAK;UAAEtF,KAAA,EAAO;QAAK,GAAGL,GAAA,EAAKf,MAAM,GAAG;UAC3De,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;UACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;UACjB,OAAO;QACT;QACA,OAAO;MACT,CAAC,GAAG;QACF;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUyG,MAAA,CAAOyG,GAAG,GAAG;QACtCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU+H,GAAA,CAAImF,GAAG,GAAG;QACnCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiI,IAAA,CAAKiF,GAAG,GAAG;QACpCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUkI,OAAA,CAAQgF,GAAA,EAAK,KAAKf,MAAA,CAAO4E,KAAK,GAAG;QAC1D7D,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,MAAMwD,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIyB,KAAA,CAAMC,IAAA,KAAS,UAAU6B,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UACvD6B,SAAA,CAAUpC,GAAA,IAAOM,KAAA,CAAMN,GAAA;UACvBoC,SAAA,CAAU1H,IAAA,IAAQ4F,KAAA,CAAM5F,IAAA;QAC1B,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUiR,QAAA,CAAS/D,GAAA,EAAKgE,SAAA,EAAWC,QAAQ,GAAG;QAC7DjE,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU+R,QAAA,CAAS7E,GAAG,GAAG;QACxCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU2G,EAAA,CAAGuG,GAAG,GAAG;QAClCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAUuI,GAAA,CAAI2E,GAAG,GAAG;QACnCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAIA,KAAA,GAAQ,KAAKjM,SAAA,CAAU6H,QAAA,CAASqF,GAAG,GAAG;QACxCA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAGA,IAAI,CAAC,KAAKF,KAAA,CAAMC,MAAA,KAAWC,KAAA,GAAQ,KAAKjM,SAAA,CAAUwI,GAAA,CAAI0E,GAAG,IAAI;QAC3DA,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC4B,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACjB;MACF;MAIA,IAAI6G,MAAA,GAAS5F,GAAA;MACb,IAAI,KAAKF,OAAA,CAAQtN,UAAA,EAAYqU,WAAA,EAAa;QACxC,IAAIf,UAAA,GAAaC,QAAA;QACjB,MAAMC,OAAA,GAAUhG,GAAA,CAAI/B,KAAA,CAAM,CAAC;QAC3B,IAAIgI,SAAA;QACJ,KAAKnG,OAAA,CAAQtN,UAAA,CAAWqU,WAAA,CAAYX,OAAA,CAASC,aAAA,IAAkB;UAC7DF,SAAA,GAAYE,aAAA,CAAcR,IAAA,CAAK;YAAEtF,KAAA,EAAO;UAAK,GAAG2F,OAAO;UACvD,IAAI,OAAOC,SAAA,KAAc,YAAYA,SAAA,IAAa,GAAG;YACnDH,UAAA,GAAavO,IAAA,CAAKC,GAAA,CAAIsO,UAAA,EAAYG,SAAS;UAC7C;QACF,CAAC;QACD,IAAIH,UAAA,GAAaC,QAAA,IAAYD,UAAA,IAAc,GAAG;UAC5CF,MAAA,GAAS5F,GAAA,CAAIiB,SAAA,CAAU,GAAG6E,UAAA,GAAa,CAAC;QAC1C;MACF;MACA,IAAI/G,KAAA,GAAQ,KAAKjM,SAAA,CAAU4G,UAAA,CAAWkM,MAAM,GAAG;QAC7C5F,GAAA,GAAMA,GAAA,CAAIiB,SAAA,CAAUlC,KAAA,CAAMN,GAAA,CAAIpB,MAAM;QACpC,IAAI0B,KAAA,CAAMN,GAAA,CAAIR,KAAA,CAAM,EAAE,MAAM,KAAK;UAC/BgG,QAAA,GAAWlF,KAAA,CAAMN,GAAA,CAAIR,KAAA,CAAM,EAAE;QAC/B;QACA2I,YAAA,GAAe;QACf,MAAM/F,SAAA,GAAY5B,MAAA,CAAO3B,EAAA,CAAG,EAAE;QAC9B,IAAIuD,SAAA,EAAW7B,IAAA,KAAS,QAAQ;UAC9B6B,SAAA,CAAUpC,GAAA,IAAOM,KAAA,CAAMN,GAAA;UACvBoC,SAAA,CAAU1H,IAAA,IAAQ4F,KAAA,CAAM5F,IAAA;QAC1B,OAAO;UACL8F,MAAA,CAAOxB,IAAA,CAAKsB,KAAK;QACnB;QACA;MACF;MAEA,IAAIiB,GAAA,EAAK;QACP,MAAMoG,MAAA,GAAS,4BAA4BpG,GAAA,CAAIqG,UAAA,CAAW,CAAC;QAC3D,IAAI,KAAKvG,OAAA,CAAQjN,MAAA,EAAQ;UACvByT,OAAA,CAAQC,KAAA,CAAMH,MAAM;UACpB;QACF,OAAO;UACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;QACxB;MACF;IACF;IAEA,OAAOnH,MAAA;EACT;AACF;;;ACxcO,IAAM6H,SAAA,GAAN,MAAMA,SAAA,CAAU;EAErB;EACAnH,YAAYC,QAAA,EAAyB;IAAAC,eAAA;IAAAA,eAAA;IACnC,KAAKC,OAAA,GAAUF,QAAA,IAAW5M,SAAA;EAC5B;EAEA+M,MAAMhB,KAAA,EAA6B;IACjC,OAAO;EACT;EAEA9F,KAAK;IAAEE,IAAA;IAAM+G,IAAA;IAAMpD;EAAQ,GAAwB;IACjD,MAAMiK,UAAA,IAAc7G,IAAA,IAAQ,IAAIvD,KAAA,CAAM7I,KAAA,CAAMmD,aAAa,IAAI,CAAC;IAE9D,MAAMgC,IAAA,GAAOE,IAAA,CAAKzF,OAAA,CAAQI,KAAA,CAAMoD,aAAA,EAAe,EAAE,IAAI;IAErD,IAAI,CAAC6P,UAAA,EAAY;MACf,OAAO,iBACFjK,OAAA,GAAU7D,IAAA,GAAO+C,OAAA,CAAO/C,IAAA,EAAM,IAAI,KACnC;IACN;IAEA,OAAO,gCACH+C,OAAA,CAAO+K,UAAU,IACjB,QACCjK,OAAA,GAAU7D,IAAA,GAAO+C,OAAA,CAAO/C,IAAA,EAAM,IAAI,KACnC;EACN;EAEAF,WAAW;IAAEkG;EAAO,GAA8B;IAChD,MAAM+H,IAAA,GAAO,KAAKC,MAAA,CAAOC,KAAA,CAAMjI,MAAM;IACrC,OAAO;AAAA,EAAiB+H,IAAI;AAAA;EAC9B;EAEAnO,KAAK;IAAEM;EAAK,GAAsC;IAChD,OAAOA,IAAA;EACT;EAEAlB,QAAQ;IAAEgH,MAAA;IAAQmB;EAAM,GAA2B;IACjD,OAAO,KAAKA,KAAK,IAAI,KAAK6G,MAAA,CAAOE,WAAA,CAAYlI,MAAM,CAAC,MAAMmB,KAAK;AAAA;EACjE;EAEApI,GAAG+G,KAAA,EAA0B;IAC3B,OAAO;EACT;EAEArG,KAAKqG,KAAA,EAA4B;IAC/B,MAAMqC,OAAA,GAAUrC,KAAA,CAAMqC,OAAA;IACtB,MAAMC,KAAA,GAAQtC,KAAA,CAAMsC,KAAA;IAEpB,IAAI2F,IAAA,GAAO;IACX,SAASI,CAAA,GAAI,GAAGA,CAAA,GAAIrI,KAAA,CAAMwC,KAAA,CAAMlE,MAAA,EAAQ+J,CAAA,IAAK;MAC3C,MAAMhE,IAAA,GAAOrE,KAAA,CAAMwC,KAAA,CAAM6F,CAAC;MAC1BJ,IAAA,IAAQ,KAAKK,QAAA,CAASjE,IAAI;IAC5B;IAEA,MAAMpE,IAAA,GAAOoC,OAAA,GAAU,OAAO;IAC9B,MAAMkG,SAAA,GAAalG,OAAA,IAAWC,KAAA,KAAU,IAAM,aAAaA,KAAA,GAAQ,MAAO;IAC1E,OAAO,MAAMrC,IAAA,GAAOsI,SAAA,GAAY,QAAQN,IAAA,GAAO,OAAOhI,IAAA,GAAO;EAC/D;EAEAqI,SAASjE,IAAA,EAA+B;IACtC,IAAImE,QAAA,GAAW;IACf,IAAInE,IAAA,CAAKd,IAAA,EAAM;MACb,MAAMkF,QAAA,GAAW,KAAKA,QAAA,CAAS;QAAEjF,OAAA,EAAS,CAAC,CAACa,IAAA,CAAKb;MAAQ,CAAC;MAC1D,IAAIa,IAAA,CAAK9B,KAAA,EAAO;QACd,IAAI8B,IAAA,CAAKnE,MAAA,CAAO,CAAC,GAAGD,IAAA,KAAS,aAAa;UACxCoE,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAE9F,IAAA,GAAOqO,QAAA,GAAW,MAAMpE,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAE9F,IAAA;UACtD,IAAIiK,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAEA,MAAA,IAAUmE,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO5B,MAAA,GAAS,KAAK+F,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAED,IAAA,KAAS,QAAQ;YACzGoE,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAE9F,IAAA,GAAOqO,QAAA,GAAW,MAAMxL,OAAA,CAAOoH,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAE9F,IAAI;YACrFiK,IAAA,CAAKnE,MAAA,CAAO,CAAC,EAAEA,MAAA,CAAO,CAAC,EAAEnC,OAAA,GAAU;UACrC;QACF,OAAO;UACLsG,IAAA,CAAKnE,MAAA,CAAOwI,OAAA,CAAQ;YAClBzI,IAAA,EAAM;YACNP,GAAA,EAAK+I,QAAA,GAAW;YAChBrO,IAAA,EAAMqO,QAAA,GAAW;YACjB1K,OAAA,EAAS;UACX,CAAC;QACH;MACF,OAAO;QACLyK,QAAA,IAAYC,QAAA,GAAW;MACzB;IACF;IAEAD,QAAA,IAAY,KAAKN,MAAA,CAAOC,KAAA,CAAM9D,IAAA,CAAKnE,MAAA,EAAQ,CAAC,CAACmE,IAAA,CAAK9B,KAAK;IAEvD,OAAO,OAAOiG,QAAQ;AAAA;EACxB;EAEAC,SAAS;IAAEjF;EAAQ,GAA4B;IAC7C,OAAO,aACFA,OAAA,GAAU,gBAAgB,MAC3B;EACN;EAEAzJ,UAAU;IAAEmG;EAAO,GAA6B;IAC9C,OAAO,MAAM,KAAKgI,MAAA,CAAOE,WAAA,CAAYlI,MAAM,CAAC;AAAA;EAC9C;EAEA/F,MAAM6F,KAAA,EAA6B;IACjC,IAAIsE,MAAA,GAAS;IAGb,IAAIE,IAAA,GAAO;IACX,SAAS6D,CAAA,GAAI,GAAGA,CAAA,GAAIrI,KAAA,CAAMsE,MAAA,CAAOhG,MAAA,EAAQ+J,CAAA,IAAK;MAC5C7D,IAAA,IAAQ,KAAKmE,SAAA,CAAU3I,KAAA,CAAMsE,MAAA,CAAO+D,CAAC,CAAC;IACxC;IACA/D,MAAA,IAAU,KAAKsE,QAAA,CAAS;MAAExO,IAAA,EAAMoK;IAAK,CAAC;IAEtC,IAAIyD,IAAA,GAAO;IACX,SAASI,CAAA,GAAI,GAAGA,CAAA,GAAIrI,KAAA,CAAMoE,IAAA,CAAK9F,MAAA,EAAQ+J,CAAA,IAAK;MAC1C,MAAM1K,GAAA,GAAMqC,KAAA,CAAMoE,IAAA,CAAKiE,CAAC;MAExB7D,IAAA,GAAO;MACP,SAASqE,CAAA,GAAI,GAAGA,CAAA,GAAIlL,GAAA,CAAIW,MAAA,EAAQuK,CAAA,IAAK;QACnCrE,IAAA,IAAQ,KAAKmE,SAAA,CAAUhL,GAAA,CAAIkL,CAAC,CAAC;MAC/B;MAEAZ,IAAA,IAAQ,KAAKW,QAAA,CAAS;QAAExO,IAAA,EAAMoK;MAAK,CAAC;IACtC;IACA,IAAIyD,IAAA,EAAMA,IAAA,GAAO,UAAUA,IAAI;IAE/B,OAAO,uBAEH3D,MAAA,GACA,eACA2D,IAAA,GACA;EACN;EAEAW,SAAS;IAAExO;EAAK,GAA4B;IAC1C,OAAO;AAAA,EAASA,IAAI;AAAA;EACtB;EAEAuO,UAAU3I,KAAA,EAAiC;IACzC,MAAM8I,OAAA,GAAU,KAAKZ,MAAA,CAAOE,WAAA,CAAYpI,KAAA,CAAME,MAAM;IACpD,MAAMD,IAAA,GAAOD,KAAA,CAAMsE,MAAA,GAAS,OAAO;IACnC,MAAMN,IAAA,GAAMhE,KAAA,CAAMuE,KAAA,GACd,IAAItE,IAAI,WAAWD,KAAA,CAAMuE,KAAK,OAC9B,IAAItE,IAAI;IACZ,OAAO+D,IAAA,GAAM8E,OAAA,GAAU,KAAK7I,IAAI;AAAA;EAClC;EAAA;AAAA;AAAA;EAKA8I,OAAO;IAAE7I;EAAO,GAA0B;IACxC,OAAO,WAAW,KAAKgI,MAAA,CAAOE,WAAA,CAAYlI,MAAM,CAAC;EACnD;EAEA8I,GAAG;IAAE9I;EAAO,GAAsB;IAChC,OAAO,OAAO,KAAKgI,MAAA,CAAOE,WAAA,CAAYlI,MAAM,CAAC;EAC/C;EAEA4F,SAAS;IAAE1L;EAAK,GAA4B;IAC1C,OAAO,SAAS6C,OAAA,CAAO7C,IAAA,EAAM,IAAI,CAAC;EACpC;EAEAM,GAAGsF,KAAA,EAA0B;IAC3B,OAAO;EACT;EAEA1D,IAAI;IAAE4D;EAAO,GAAuB;IAClC,OAAO,QAAQ,KAAKgI,MAAA,CAAOE,WAAA,CAAYlI,MAAM,CAAC;EAChD;EAEAlE,KAAK;IAAEsB,IAAA;IAAMuC,KAAA;IAAOK;EAAO,GAAwB;IACjD,MAAM9F,IAAA,GAAO,KAAK8N,MAAA,CAAOE,WAAA,CAAYlI,MAAM;IAC3C,MAAM+I,SAAA,GAAY5L,QAAA,CAASC,IAAI;IAC/B,IAAI2L,SAAA,KAAc,MAAM;MACtB,OAAO7O,IAAA;IACT;IACAkD,IAAA,GAAO2L,SAAA;IACP,IAAIC,GAAA,GAAM,cAAc5L,IAAA,GAAO;IAC/B,IAAIuC,KAAA,EAAO;MACTqJ,GAAA,IAAO,aAAcjM,OAAA,CAAO4C,KAAK,IAAK;IACxC;IACAqJ,GAAA,IAAO,MAAM9O,IAAA,GAAO;IACpB,OAAO8O,GAAA;EACT;EAEAC,MAAM;IAAE7L,IAAA;IAAMuC,KAAA;IAAOzF,IAAA;IAAM8F;EAAO,GAAyB;IACzD,IAAIA,MAAA,EAAQ;MACV9F,IAAA,GAAO,KAAK8N,MAAA,CAAOE,WAAA,CAAYlI,MAAA,EAAQ,KAAKgI,MAAA,CAAOkB,YAAY;IACjE;IACA,MAAMH,SAAA,GAAY5L,QAAA,CAASC,IAAI;IAC/B,IAAI2L,SAAA,KAAc,MAAM;MACtB,OAAOhM,OAAA,CAAO7C,IAAI;IACpB;IACAkD,IAAA,GAAO2L,SAAA;IAEP,IAAIC,GAAA,GAAM,aAAa5L,IAAI,UAAUlD,IAAI;IACzC,IAAIyF,KAAA,EAAO;MACTqJ,GAAA,IAAO,WAAWjM,OAAA,CAAO4C,KAAK,CAAC;IACjC;IACAqJ,GAAA,IAAO;IACP,OAAOA,GAAA;EACT;EAEA9O,KAAK4F,KAAA,EAA6C;IAChD,OAAO,YAAYA,KAAA,IAASA,KAAA,CAAME,MAAA,GAC9B,KAAKgI,MAAA,CAAOE,WAAA,CAAYpI,KAAA,CAAME,MAAM,IACnC,aAAaF,KAAA,IAASA,KAAA,CAAMjC,OAAA,GAAUiC,KAAA,CAAM5F,IAAA,GAAO6C,OAAA,CAAO+C,KAAA,CAAM5F,IAAI;EAC3E;AACF;;;ACpNO,IAAMiP,aAAA,GAAN,MAAoB;EAAA;EAEzBN,OAAO;IAAE3O;EAAK,GAAkB;IAC9B,OAAOA,IAAA;EACT;EAEA4O,GAAG;IAAE5O;EAAK,GAAc;IACtB,OAAOA,IAAA;EACT;EAEA0L,SAAS;IAAE1L;EAAK,GAAoB;IAClC,OAAOA,IAAA;EACT;EAEAkC,IAAI;IAAElC;EAAK,GAAe;IACxB,OAAOA,IAAA;EACT;EAEAN,KAAK;IAAEM;EAAK,GAA6B;IACvC,OAAOA,IAAA;EACT;EAEAA,KAAK;IAAEA;EAAK,GAA6C;IACvD,OAAOA,IAAA;EACT;EAEA4B,KAAK;IAAE5B;EAAK,GAAgB;IAC1B,OAAO,KAAKA,IAAA;EACd;EAEA+O,MAAM;IAAE/O;EAAK,GAAiB;IAC5B,OAAO,KAAKA,IAAA;EACd;EAEAM,GAAA,EAAK;IACH,OAAO;EACT;AACF;;;AClCO,IAAM4O,OAAA,GAAN,MAAMC,QAAA,CAAQ;EAInB3I,YAAYC,QAAA,EAAyB;IAAAC,eAAA;IAAAA,eAAA;IAAAA,eAAA;IACnC,KAAKC,OAAA,GAAUF,QAAA,IAAW5M,SAAA;IAC1B,KAAK8M,OAAA,CAAQlN,QAAA,GAAW,KAAKkN,OAAA,CAAQlN,QAAA,IAAY,IAAIkU,SAAA,CAAU;IAC/D,KAAKlU,QAAA,GAAW,KAAKkN,OAAA,CAAQlN,QAAA;IAC7B,KAAKA,QAAA,CAASkN,OAAA,GAAU,KAAKA,OAAA;IAC7B,KAAKlN,QAAA,CAASqU,MAAA,GAAS;IACvB,KAAKkB,YAAA,GAAe,IAAIC,aAAA,CAAc;EACxC;EAAA;AAAA;AAAA;EAKA,OAAOlB,MAAMjI,MAAA,EAAiBW,QAAA,EAAyB;IACrD,MAAM2I,OAAA,GAAS,IAAID,QAAA,CAAQ1I,QAAO;IAClC,OAAO2I,OAAA,CAAOrB,KAAA,CAAMjI,MAAM;EAC5B;EAAA;AAAA;AAAA;EAKA,OAAOkI,YAAYlI,MAAA,EAAiBW,QAAA,EAAyB;IAC3D,MAAM2I,OAAA,GAAS,IAAID,QAAA,CAAQ1I,QAAO;IAClC,OAAO2I,OAAA,CAAOpB,WAAA,CAAYlI,MAAM;EAClC;EAAA;AAAA;AAAA;EAKAiI,MAAMjI,MAAA,EAAiB0B,GAAA,GAAM,MAAc;IACzC,IAAIsH,GAAA,GAAM;IAEV,SAAS/K,CAAA,GAAI,GAAGA,CAAA,GAAI+B,MAAA,CAAO5B,MAAA,EAAQH,CAAA,IAAK;MACtC,MAAMsL,QAAA,GAAWvJ,MAAA,CAAO/B,CAAC;MAGzB,IAAI,KAAK4C,OAAA,CAAQtN,UAAA,EAAYiW,SAAA,GAAYD,QAAA,CAASxJ,IAAI,GAAG;QACvD,MAAM0J,YAAA,GAAeF,QAAA;QACrB,MAAMG,GAAA,GAAM,KAAK7I,OAAA,CAAQtN,UAAA,CAAWiW,SAAA,CAAUC,YAAA,CAAa1J,IAAI,EAAE2G,IAAA,CAAK;UAAEsB,MAAA,EAAQ;QAAK,GAAGyB,YAAY;QACpG,IAAIC,GAAA,KAAQ,SAAS,CAAC,CAAC,SAAS,MAAM,WAAW,QAAQ,SAAS,cAAc,QAAQ,QAAQ,aAAa,MAAM,EAAEjC,QAAA,CAASgC,YAAA,CAAa1J,IAAI,GAAG;UAChJiJ,GAAA,IAAOU,GAAA,IAAO;UACd;QACF;MACF;MAEA,MAAM5J,KAAA,GAAQyJ,QAAA;MAEd,QAAQzJ,KAAA,CAAMC,IAAA;QACZ,KAAK;UAAS;YACZiJ,GAAA,IAAO,KAAKrV,QAAA,CAASmN,KAAA,CAAMhB,KAAK;YAChC;UACF;QACA,KAAK;UAAM;YACTkJ,GAAA,IAAO,KAAKrV,QAAA,CAASoF,EAAA,CAAG+G,KAAK;YAC7B;UACF;QACA,KAAK;UAAW;YACdkJ,GAAA,IAAO,KAAKrV,QAAA,CAASqF,OAAA,CAAQ8G,KAAK;YAClC;UACF;QACA,KAAK;UAAQ;YACXkJ,GAAA,IAAO,KAAKrV,QAAA,CAASqG,IAAA,CAAK8F,KAAK;YAC/B;UACF;QACA,KAAK;UAAS;YACZkJ,GAAA,IAAO,KAAKrV,QAAA,CAASsG,KAAA,CAAM6F,KAAK;YAChC;UACF;QACA,KAAK;UAAc;YACjBkJ,GAAA,IAAO,KAAKrV,QAAA,CAASmG,UAAA,CAAWgG,KAAK;YACrC;UACF;QACA,KAAK;UAAQ;YACXkJ,GAAA,IAAO,KAAKrV,QAAA,CAAS8F,IAAA,CAAKqG,KAAK;YAC/B;UACF;QACA,KAAK;UAAQ;YACXkJ,GAAA,IAAO,KAAKrV,QAAA,CAASiG,IAAA,CAAKkG,KAAK;YAC/B;UACF;QACA,KAAK;UAAa;YAChBkJ,GAAA,IAAO,KAAKrV,QAAA,CAASkG,SAAA,CAAUiG,KAAK;YACpC;UACF;QACA,KAAK;UAAQ;YACX,IAAI6J,SAAA,GAAY7J,KAAA;YAChB,IAAIiI,IAAA,GAAO,KAAKpU,QAAA,CAASuG,IAAA,CAAKyP,SAAS;YACvC,OAAO1L,CAAA,GAAI,IAAI+B,MAAA,CAAO5B,MAAA,IAAU4B,MAAA,CAAO/B,CAAA,GAAI,CAAC,EAAE8B,IAAA,KAAS,QAAQ;cAC7D4J,SAAA,GAAY3J,MAAA,CAAO,EAAE/B,CAAC;cACtB8J,IAAA,IAAQ,OAAO,KAAKpU,QAAA,CAASuG,IAAA,CAAKyP,SAAS;YAC7C;YACA,IAAIjI,GAAA,EAAK;cACPsH,GAAA,IAAO,KAAKrV,QAAA,CAASkG,SAAA,CAAU;gBAC7BkG,IAAA,EAAM;gBACNP,GAAA,EAAKuI,IAAA;gBACL7N,IAAA,EAAM6N,IAAA;gBACN/H,MAAA,EAAQ,CAAC;kBAAED,IAAA,EAAM;kBAAQP,GAAA,EAAKuI,IAAA;kBAAM7N,IAAA,EAAM6N,IAAA;kBAAMlK,OAAA,EAAS;gBAAK,CAAC;cACjE,CAAC;YACH,OAAO;cACLmL,GAAA,IAAOjB,IAAA;YACT;YACA;UACF;QAEA;UAAS;YACP,MAAMZ,MAAA,GAAS,iBAAiBrH,KAAA,CAAMC,IAAA,GAAO;YAC7C,IAAI,KAAKc,OAAA,CAAQjN,MAAA,EAAQ;cACvByT,OAAA,CAAQC,KAAA,CAAMH,MAAM;cACpB,OAAO;YACT,OAAO;cACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;YACxB;UACF;MACF;IACF;IAEA,OAAO6B,GAAA;EACT;EAAA;AAAA;AAAA;EAKAd,YAAYlI,MAAA,EAAiBrM,QAAA,GAAsC,KAAKA,QAAA,EAAkB;IACxF,IAAIqV,GAAA,GAAM;IAEV,SAAS/K,CAAA,GAAI,GAAGA,CAAA,GAAI+B,MAAA,CAAO5B,MAAA,EAAQH,CAAA,IAAK;MACtC,MAAMsL,QAAA,GAAWvJ,MAAA,CAAO/B,CAAC;MAGzB,IAAI,KAAK4C,OAAA,CAAQtN,UAAA,EAAYiW,SAAA,GAAYD,QAAA,CAASxJ,IAAI,GAAG;QACvD,MAAM2J,GAAA,GAAM,KAAK7I,OAAA,CAAQtN,UAAA,CAAWiW,SAAA,CAAUD,QAAA,CAASxJ,IAAI,EAAE2G,IAAA,CAAK;UAAEsB,MAAA,EAAQ;QAAK,GAAGuB,QAAQ;QAC5F,IAAIG,GAAA,KAAQ,SAAS,CAAC,CAAC,UAAU,QAAQ,QAAQ,SAAS,UAAU,MAAM,YAAY,MAAM,OAAO,MAAM,EAAEjC,QAAA,CAAS8B,QAAA,CAASxJ,IAAI,GAAG;UAClIiJ,GAAA,IAAOU,GAAA,IAAO;UACd;QACF;MACF;MAEA,MAAM5J,KAAA,GAAQyJ,QAAA;MAEd,QAAQzJ,KAAA,CAAMC,IAAA;QACZ,KAAK;UAAU;YACbiJ,GAAA,IAAOrV,QAAA,CAASuG,IAAA,CAAK4F,KAAK;YAC1B;UACF;QACA,KAAK;UAAQ;YACXkJ,GAAA,IAAOrV,QAAA,CAASiG,IAAA,CAAKkG,KAAK;YAC1B;UACF;QACA,KAAK;UAAQ;YACXkJ,GAAA,IAAOrV,QAAA,CAASmI,IAAA,CAAKgE,KAAK;YAC1B;UACF;QACA,KAAK;UAAS;YACZkJ,GAAA,IAAOrV,QAAA,CAASsV,KAAA,CAAMnJ,KAAK;YAC3B;UACF;QACA,KAAK;UAAU;YACbkJ,GAAA,IAAOrV,QAAA,CAASkV,MAAA,CAAO/I,KAAK;YAC5B;UACF;QACA,KAAK;UAAM;YACTkJ,GAAA,IAAOrV,QAAA,CAASmV,EAAA,CAAGhJ,KAAK;YACxB;UACF;QACA,KAAK;UAAY;YACfkJ,GAAA,IAAOrV,QAAA,CAASiS,QAAA,CAAS9F,KAAK;YAC9B;UACF;QACA,KAAK;UAAM;YACTkJ,GAAA,IAAOrV,QAAA,CAAS6G,EAAA,CAAGsF,KAAK;YACxB;UACF;QACA,KAAK;UAAO;YACVkJ,GAAA,IAAOrV,QAAA,CAASyI,GAAA,CAAI0D,KAAK;YACzB;UACF;QACA,KAAK;UAAQ;YACXkJ,GAAA,IAAOrV,QAAA,CAASuG,IAAA,CAAK4F,KAAK;YAC1B;UACF;QACA;UAAS;YACP,MAAMqH,MAAA,GAAS,iBAAiBrH,KAAA,CAAMC,IAAA,GAAO;YAC7C,IAAI,KAAKc,OAAA,CAAQjN,MAAA,EAAQ;cACvByT,OAAA,CAAQC,KAAA,CAAMH,MAAM;cACpB,OAAO;YACT,OAAO;cACL,MAAM,IAAII,KAAA,CAAMJ,MAAM;YACxB;UACF;MACF;IACF;IACA,OAAO6B,GAAA;EACT;AACF;;;ACvMO,IAAMY,MAAA,IAAAC,OAAA,GAAN,MAAMD,MAAA,CAAO;EAIlBlJ,YAAYC,QAAA,EAAyB;IAAAC,eAAA;IAAAA,eAAA;IACnC,KAAKC,OAAA,GAAUF,QAAA,IAAW5M,SAAA;EAC5B;EAMC;AAAA;AAAA;EAKD+V,WAAWC,QAAA,EAAkB;IAC3B,OAAOA,QAAA;EACT;EAAA;AAAA;AAAA;EAKAC,YAAYhN,KAAA,EAAc;IACxB,OAAOA,KAAA;EACT;EAAA;AAAA;AAAA;EAKAiN,iBAAiBjK,MAAA,EAA8B;IAC7C,OAAOA,MAAA;EACT;EAAA;AAAA;AAAA;EAKAkK,aAAA,EAAe;IACb,OAAO,KAAKzN,KAAA,GAAQuJ,MAAA,CAAOK,GAAA,GAAML,MAAA,CAAOM,SAAA;EAC1C;EAAA;AAAA;AAAA;EAKA6D,cAAA,EAAgB;IACd,OAAO,KAAK1N,KAAA,GAAQ2M,OAAA,CAAQnB,KAAA,GAAQmB,OAAA,CAAQlB,WAAA;EAC9C;AACF,GAAAtH,eAAA,CAAAiJ,OAAA,sBAxC4B,mBAAIO,GAAA,CAAI,CAChC,cACA,eACA,mBACD,IAAAP,OAAA,CAoCH;;;ACtCO,IAAMQ,MAAA,GAAN,MAAMA,MAAA,CAAO;EAclB3J,YAAA,GAAe4J,IAAA,EAAyB;IAAA1J,eAAA,mBAb7BxN,YAAA,CAAa;IAAAwN,eAAA,kBACd,KAAK2J,UAAA;IAAA3J,eAAA,gBAEP,KAAK4J,aAAA,CAAc,IAAI;IAAA5J,eAAA,sBACjB,KAAK4J,aAAA,CAAc,KAAK;IAAA5J,eAAA,iBAE7BwI,OAAA;IAAAxI,eAAA,mBACEiH,SAAA;IAAAjH,eAAA,uBACIuI,aAAA;IAAAvI,eAAA,gBACPoF,MAAA;IAAApF,eAAA,oBACIH,UAAA;IAAAG,eAAA,gBACJgJ,MAAA;IAGN,KAAKa,GAAA,CAAI,GAAGH,IAAI;EAClB;EAAA;AAAA;AAAA;EAKAxW,WAAWkM,MAAA,EAA8B0K,QAAA,EAA2D;IAClG,IAAIC,MAAA,GAAyB,EAAC;IAC9B,WAAW7K,KAAA,IAASE,MAAA,EAAQ;MAC1B2K,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAOF,QAAA,CAAShE,IAAA,CAAK,MAAM5G,KAAK,CAAC;MACjD,QAAQA,KAAA,CAAMC,IAAA;QACZ,KAAK;UAAS;YACZ,MAAM8K,UAAA,GAAa/K,KAAA;YACnB,WAAWwE,IAAA,IAAQuG,UAAA,CAAWzG,MAAA,EAAQ;cACpCuG,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAK9W,UAAA,CAAWwQ,IAAA,CAAKtE,MAAA,EAAQ0K,QAAQ,CAAC;YAC/D;YACA,WAAWjN,GAAA,IAAOoN,UAAA,CAAW3G,IAAA,EAAM;cACjC,WAAWI,IAAA,IAAQ7G,GAAA,EAAK;gBACtBkN,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAK9W,UAAA,CAAWwQ,IAAA,CAAKtE,MAAA,EAAQ0K,QAAQ,CAAC;cAC/D;YACF;YACA;UACF;QACA,KAAK;UAAQ;YACX,MAAMI,SAAA,GAAYhL,KAAA;YAClB6K,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAK9W,UAAA,CAAWgX,SAAA,CAAUxI,KAAA,EAAOoI,QAAQ,CAAC;YACjE;UACF;QACA;UAAS;YACP,MAAMjB,YAAA,GAAe3J,KAAA;YACrB,IAAI,KAAKiL,QAAA,CAASxX,UAAA,EAAYyX,WAAA,GAAcvB,YAAA,CAAa1J,IAAI,GAAG;cAC9D,KAAKgL,QAAA,CAASxX,UAAA,CAAWyX,WAAA,CAAYvB,YAAA,CAAa1J,IAAI,EAAEkH,OAAA,CAAS+D,WAAA,IAAgB;gBAC/E,MAAMC,OAAA,GAASxB,YAAA,CAAauB,WAAW,EAAEE,IAAA,CAAKpE,QAAQ;gBACtD6D,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAK9W,UAAA,CAAWmX,OAAA,EAAQP,QAAQ,CAAC;cAC1D,CAAC;YACH,WAAWjB,YAAA,CAAazJ,MAAA,EAAQ;cAC9B2K,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO,KAAK9W,UAAA,CAAW2V,YAAA,CAAazJ,MAAA,EAAQ0K,QAAQ,CAAC;YACvE;UACF;MACF;IACF;IACA,OAAOC,MAAA;EACT;EAEAF,IAAA,GAAOH,IAAA,EAAyB;IAC9B,MAAM/W,UAAA,GAA0C,KAAKwX,QAAA,CAASxX,UAAA,IAAc;MAAEiW,SAAA,EAAW,CAAC;MAAGwB,WAAA,EAAa,CAAC;IAAE;IAE7GV,IAAA,CAAKrD,OAAA,CAASkE,IAAA,IAAS;MAErB,MAAMC,IAAA,GAAO;QAAE,GAAGD;MAAK;MAGvBC,IAAA,CAAK/X,KAAA,GAAQ,KAAK0X,QAAA,CAAS1X,KAAA,IAAS+X,IAAA,CAAK/X,KAAA,IAAS;MAGlD,IAAI8X,IAAA,CAAK5X,UAAA,EAAY;QACnB4X,IAAA,CAAK5X,UAAA,CAAW0T,OAAA,CAASoE,GAAA,IAAQ;UAC/B,IAAI,CAACA,GAAA,CAAI3W,IAAA,EAAM;YACb,MAAM,IAAI6S,KAAA,CAAM,yBAAyB;UAC3C;UACA,IAAI,cAAc8D,GAAA,EAAK;YACrB,MAAMC,YAAA,GAAe/X,UAAA,CAAWiW,SAAA,CAAU6B,GAAA,CAAI3W,IAAI;YAClD,IAAI4W,YAAA,EAAc;cAEhB/X,UAAA,CAAWiW,SAAA,CAAU6B,GAAA,CAAI3W,IAAI,IAAI,aAAY6W,KAAA,EAAM;gBACjD,IAAI7B,GAAA,GAAM2B,GAAA,CAAI1X,QAAA,CAAS6X,KAAA,CAAM,MAAMD,KAAI;gBACvC,IAAI7B,GAAA,KAAQ,OAAO;kBACjBA,GAAA,GAAM4B,YAAA,CAAaE,KAAA,CAAM,MAAMD,KAAI;gBACrC;gBACA,OAAO7B,GAAA;cACT;YACF,OAAO;cACLnW,UAAA,CAAWiW,SAAA,CAAU6B,GAAA,CAAI3W,IAAI,IAAI2W,GAAA,CAAI1X,QAAA;YACvC;UACF;UACA,IAAI,eAAe0X,GAAA,EAAK;YACtB,IAAI,CAACA,GAAA,CAAIjM,KAAA,IAAUiM,GAAA,CAAIjM,KAAA,KAAU,WAAWiM,GAAA,CAAIjM,KAAA,KAAU,UAAW;cACnE,MAAM,IAAImI,KAAA,CAAM,6CAA6C;YAC/D;YACA,MAAMkE,QAAA,GAAWlY,UAAA,CAAW8X,GAAA,CAAIjM,KAAK;YACrC,IAAIqM,QAAA,EAAU;cACZA,QAAA,CAASjD,OAAA,CAAQ6C,GAAA,CAAIxX,SAAS;YAChC,OAAO;cACLN,UAAA,CAAW8X,GAAA,CAAIjM,KAAK,IAAI,CAACiM,GAAA,CAAIxX,SAAS;YACxC;YACA,IAAIwX,GAAA,CAAIjJ,KAAA,EAAO;cACb,IAAIiJ,GAAA,CAAIjM,KAAA,KAAU,SAAS;gBACzB,IAAI7L,UAAA,CAAWqT,UAAA,EAAY;kBACzBrT,UAAA,CAAWqT,UAAA,CAAWpI,IAAA,CAAK6M,GAAA,CAAIjJ,KAAK;gBACtC,OAAO;kBACL7O,UAAA,CAAWqT,UAAA,GAAa,CAACyE,GAAA,CAAIjJ,KAAK;gBACpC;cACF,WAAWiJ,GAAA,CAAIjM,KAAA,KAAU,UAAU;gBACjC,IAAI7L,UAAA,CAAWqU,WAAA,EAAa;kBAC1BrU,UAAA,CAAWqU,WAAA,CAAYpJ,IAAA,CAAK6M,GAAA,CAAIjJ,KAAK;gBACvC,OAAO;kBACL7O,UAAA,CAAWqU,WAAA,GAAc,CAACyD,GAAA,CAAIjJ,KAAK;gBACrC;cACF;YACF;UACF;UACA,IAAI,iBAAiBiJ,GAAA,IAAOA,GAAA,CAAIL,WAAA,EAAa;YAC3CzX,UAAA,CAAWyX,WAAA,CAAYK,GAAA,CAAI3W,IAAI,IAAI2W,GAAA,CAAIL,WAAA;UACzC;QACF,CAAC;QACDI,IAAA,CAAK7X,UAAA,GAAaA,UAAA;MACpB;MAGA,IAAI4X,IAAA,CAAKxX,QAAA,EAAU;QACjB,MAAMA,QAAA,GAAW,KAAKoX,QAAA,CAASpX,QAAA,IAAY,IAAIkU,SAAA,CAAU,KAAKkD,QAAQ;QACtE,WAAWW,IAAA,IAAQP,IAAA,CAAKxX,QAAA,EAAU;UAChC,IAAI,EAAE+X,IAAA,IAAQ/X,QAAA,GAAW;YACvB,MAAM,IAAI4T,KAAA,CAAM,aAAamE,IAAI,kBAAkB;UACrD;UACA,IAAI,CAAC,WAAW,QAAQ,EAAEjE,QAAA,CAASiE,IAAI,GAAG;YAExC;UACF;UACA,MAAMC,YAAA,GAAeD,IAAA;UACrB,MAAME,YAAA,GAAeT,IAAA,CAAKxX,QAAA,CAASgY,YAAY;UAC/C,MAAML,YAAA,GAAe3X,QAAA,CAASgY,YAAY;UAE1ChY,QAAA,CAASgY,YAAY,IAAI,IAAIJ,KAAA,KAAoB;YAC/C,IAAI7B,GAAA,GAAMkC,YAAA,CAAaJ,KAAA,CAAM7X,QAAA,EAAU4X,KAAI;YAC3C,IAAI7B,GAAA,KAAQ,OAAO;cACjBA,GAAA,GAAM4B,YAAA,CAAaE,KAAA,CAAM7X,QAAA,EAAU4X,KAAI;YACzC;YACA,OAAO7B,GAAA,IAAO;UAChB;QACF;QACA0B,IAAA,CAAKzX,QAAA,GAAWA,QAAA;MAClB;MACA,IAAIwX,IAAA,CAAKtX,SAAA,EAAW;QAClB,MAAMA,SAAA,GAAY,KAAKkX,QAAA,CAASlX,SAAA,IAAa,IAAI4M,UAAA,CAAW,KAAKsK,QAAQ;QACzE,WAAWW,IAAA,IAAQP,IAAA,CAAKtX,SAAA,EAAW;UACjC,IAAI,EAAE6X,IAAA,IAAQ7X,SAAA,GAAY;YACxB,MAAM,IAAI0T,KAAA,CAAM,cAAcmE,IAAI,kBAAkB;UACtD;UACA,IAAI,CAAC,WAAW,SAAS,OAAO,EAAEjE,QAAA,CAASiE,IAAI,GAAG;YAEhD;UACF;UACA,MAAMG,aAAA,GAAgBH,IAAA;UACtB,MAAMI,aAAA,GAAgBX,IAAA,CAAKtX,SAAA,CAAUgY,aAAa;UAClD,MAAME,aAAA,GAAgBlY,SAAA,CAAUgY,aAAa;UAG7ChY,SAAA,CAAUgY,aAAa,IAAI,IAAIN,KAAA,KAAoB;YACjD,IAAI7B,GAAA,GAAMoC,aAAA,CAAcN,KAAA,CAAM3X,SAAA,EAAW0X,KAAI;YAC7C,IAAI7B,GAAA,KAAQ,OAAO;cACjBA,GAAA,GAAMqC,aAAA,CAAcP,KAAA,CAAM3X,SAAA,EAAW0X,KAAI;YAC3C;YACA,OAAO7B,GAAA;UACT;QACF;QACA0B,IAAA,CAAKvX,SAAA,GAAYA,SAAA;MACnB;MAGA,IAAIsX,IAAA,CAAK1X,KAAA,EAAO;QACd,MAAMA,KAAA,GAAQ,KAAKsX,QAAA,CAAStX,KAAA,IAAS,IAAImW,MAAA,CAAO;QAChD,WAAW8B,IAAA,IAAQP,IAAA,CAAK1X,KAAA,EAAO;UAC7B,IAAI,EAAEiY,IAAA,IAAQjY,KAAA,GAAQ;YACpB,MAAM,IAAI8T,KAAA,CAAM,SAASmE,IAAI,kBAAkB;UACjD;UACA,IAAI,CAAC,WAAW,OAAO,EAAEjE,QAAA,CAASiE,IAAI,GAAG;YAEvC;UACF;UACA,MAAMM,SAAA,GAAYN,IAAA;UAClB,MAAMO,SAAA,GAAYd,IAAA,CAAK1X,KAAA,CAAMuY,SAAS;UACtC,MAAME,QAAA,GAAWzY,KAAA,CAAMuY,SAAS;UAChC,IAAIpC,MAAA,CAAOuC,gBAAA,CAAiBC,GAAA,CAAIV,IAAI,GAAG;YAErCjY,KAAA,CAAMuY,SAAS,IAAKK,GAAA,IAAiB;cACnC,IAAI,KAAKtB,QAAA,CAAS1X,KAAA,EAAO;gBACvB,OAAOiZ,OAAA,CAAQC,OAAA,CAAQN,SAAA,CAAUvF,IAAA,CAAKjT,KAAA,EAAO4Y,GAAG,CAAC,EAAEG,IAAA,CAAKC,IAAA,IAAO;kBAC7D,OAAOP,QAAA,CAASxF,IAAA,CAAKjT,KAAA,EAAOgZ,IAAG;gBACjC,CAAC;cACH;cAEA,MAAM/C,GAAA,GAAMuC,SAAA,CAAUvF,IAAA,CAAKjT,KAAA,EAAO4Y,GAAG;cACrC,OAAOH,QAAA,CAASxF,IAAA,CAAKjT,KAAA,EAAOiW,GAAG;YACjC;UACF,OAAO;YAELjW,KAAA,CAAMuY,SAAS,IAAI,IAAIT,KAAA,KAAoB;cACzC,IAAI7B,GAAA,GAAMuC,SAAA,CAAUT,KAAA,CAAM/X,KAAA,EAAO8X,KAAI;cACrC,IAAI7B,GAAA,KAAQ,OAAO;gBACjBA,GAAA,GAAMwC,QAAA,CAASV,KAAA,CAAM/X,KAAA,EAAO8X,KAAI;cAClC;cACA,OAAO7B,GAAA;YACT;UACF;QACF;QACA0B,IAAA,CAAK3X,KAAA,GAAQA,KAAA;MACf;MAGA,IAAI0X,IAAA,CAAKrX,UAAA,EAAY;QACnB,MAAM4Y,WAAA,GAAa,KAAK3B,QAAA,CAASjX,UAAA;QACjC,MAAM6Y,cAAA,GAAiBxB,IAAA,CAAKrX,UAAA;QAC5BsX,IAAA,CAAKtX,UAAA,GAAa,UAASgM,KAAA,EAAO;UAChC,IAAI6K,MAAA,GAAyB,EAAC;UAC9BA,MAAA,CAAOnM,IAAA,CAAKmO,cAAA,CAAejG,IAAA,CAAK,MAAM5G,KAAK,CAAC;UAC5C,IAAI4M,WAAA,EAAY;YACd/B,MAAA,GAASA,MAAA,CAAOC,MAAA,CAAO8B,WAAA,CAAWhG,IAAA,CAAK,MAAM5G,KAAK,CAAC;UACrD;UACA,OAAO6K,MAAA;QACT;MACF;MAEA,KAAKI,QAAA,GAAW;QAAE,GAAG,KAAKA,QAAA;QAAU,GAAGK;MAAK;IAC9C,CAAC;IAED,OAAO;EACT;EAEAb,WAAWjW,GAAA,EAAoB;IAC7B,KAAKyW,QAAA,GAAW;MAAE,GAAG,KAAKA,QAAA;MAAU,GAAGzW;IAAI;IAC3C,OAAO;EACT;EAEA8M,MAAML,GAAA,EAAaJ,QAAA,EAAyB;IAC1C,OAAOqF,MAAA,CAAOK,GAAA,CAAItF,GAAA,EAAKJ,QAAA,IAAW,KAAKoK,QAAQ;EACjD;EAEA/C,OAAOhI,MAAA,EAAiBW,QAAA,EAAyB;IAC/C,OAAOyI,OAAA,CAAQnB,KAAA,CAAMjI,MAAA,EAAQW,QAAA,IAAW,KAAKoK,QAAQ;EACvD;EAEQP,cAAcoC,SAAA,EAAoB;IAQxC,MAAMC,MAAA,GAAyB5E,CAAClH,GAAA,EAAaJ,QAAA,KAAwC;MACnF,MAAMmM,OAAA,GAAU;QAAE,GAAGnM;MAAQ;MAC7B,MAAMrM,GAAA,GAAM;QAAE,GAAG,KAAKyW,QAAA;QAAU,GAAG+B;MAAQ;MAE3C,MAAMC,UAAA,GAAa,KAAKC,OAAA,CAAQ,CAAC,CAAC1Y,GAAA,CAAIV,MAAA,EAAQ,CAAC,CAACU,GAAA,CAAIjB,KAAK;MAGzD,IAAI,KAAK0X,QAAA,CAAS1X,KAAA,KAAU,QAAQyZ,OAAA,CAAQzZ,KAAA,KAAU,OAAO;QAC3D,OAAO0Z,UAAA,CAAW,IAAIxF,KAAA,CAAM,oIAAoI,CAAC;MACnK;MAGA,IAAI,OAAOxG,GAAA,KAAQ,eAAeA,GAAA,KAAQ,MAAM;QAC9C,OAAOgM,UAAA,CAAW,IAAIxF,KAAA,CAAM,gDAAgD,CAAC;MAC/E;MACA,IAAI,OAAOxG,GAAA,KAAQ,UAAU;QAC3B,OAAOgM,UAAA,CAAW,IAAIxF,KAAA,CAAM,0CACxBrB,MAAA,CAAO+G,SAAA,CAAUC,QAAA,CAASxG,IAAA,CAAK3F,GAAG,IAAI,mBAAmB,CAAC;MAChE;MAEA,IAAIzM,GAAA,CAAIb,KAAA,EAAO;QACba,GAAA,CAAIb,KAAA,CAAMoN,OAAA,GAAUvM,GAAA;QACpBA,GAAA,CAAIb,KAAA,CAAMgJ,KAAA,GAAQmQ,SAAA;MACpB;MAEA,MAAMnN,MAAA,GAAQnL,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMyW,YAAA,CAAa,IAAK0C,SAAA,GAAY5G,MAAA,CAAOK,GAAA,GAAML,MAAA,CAAOM,SAAA;MACtF,MAAMgD,OAAA,GAAShV,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAM0W,aAAA,CAAc,IAAKyC,SAAA,GAAYxD,OAAA,CAAQnB,KAAA,GAAQmB,OAAA,CAAQlB,WAAA;MAE5F,IAAI5T,GAAA,CAAIjB,KAAA,EAAO;QACb,OAAOiZ,OAAA,CAAQC,OAAA,CAAQjY,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMqW,UAAA,CAAW/I,GAAG,IAAIA,GAAG,EAC/DyL,IAAA,CAAKW,IAAA,IAAO1N,MAAA,CAAM0N,IAAA,EAAK7Y,GAAG,CAAC,EAC3BkY,IAAA,CAAKxM,MAAA,IAAU1L,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMwW,gBAAA,CAAiBjK,MAAM,IAAIA,MAAM,EACtEwM,IAAA,CAAKxM,MAAA,IAAU1L,GAAA,CAAIR,UAAA,GAAawY,OAAA,CAAQc,GAAA,CAAI,KAAKtZ,UAAA,CAAWkM,MAAA,EAAQ1L,GAAA,CAAIR,UAAU,CAAC,EAAE0Y,IAAA,CAAK,MAAMxM,MAAM,IAAIA,MAAM,EAChHwM,IAAA,CAAKxM,MAAA,IAAUsJ,OAAA,CAAOtJ,MAAA,EAAQ1L,GAAG,CAAC,EAClCkY,IAAA,CAAKxP,KAAA,IAAQ1I,GAAA,CAAIb,KAAA,GAAQa,GAAA,CAAIb,KAAA,CAAMuW,WAAA,CAAYhN,KAAI,IAAIA,KAAI,EAC3DqQ,KAAA,CAAMN,UAAU;MACrB;MAEA,IAAI;QACF,IAAIzY,GAAA,CAAIb,KAAA,EAAO;UACbsN,GAAA,GAAMzM,GAAA,CAAIb,KAAA,CAAMqW,UAAA,CAAW/I,GAAG;QAChC;QACA,IAAIf,MAAA,GAASP,MAAA,CAAMsB,GAAA,EAAKzM,GAAG;QAC3B,IAAIA,GAAA,CAAIb,KAAA,EAAO;UACbuM,MAAA,GAAS1L,GAAA,CAAIb,KAAA,CAAMwW,gBAAA,CAAiBjK,MAAM;QAC5C;QACA,IAAI1L,GAAA,CAAIR,UAAA,EAAY;UAClB,KAAKA,UAAA,CAAWkM,MAAA,EAAQ1L,GAAA,CAAIR,UAAU;QACxC;QACA,IAAIkJ,KAAA,GAAOsM,OAAA,CAAOtJ,MAAA,EAAQ1L,GAAG;QAC7B,IAAIA,GAAA,CAAIb,KAAA,EAAO;UACbuJ,KAAA,GAAO1I,GAAA,CAAIb,KAAA,CAAMuW,WAAA,CAAYhN,KAAI;QACnC;QACA,OAAOA,KAAA;MACT,SAASsQ,CAAA,EAAG;QACV,OAAOP,UAAA,CAAWO,CAAU;MAC9B;IACF;IAEA,OAAOT,MAAA;EACT;EAEQG,QAAQpZ,MAAA,EAAiBP,KAAA,EAAgB;IAC/C,OAAQia,CAAA,IAAuC;MAC7CA,CAAA,CAAEC,OAAA,IAAW;MAEb,IAAI3Z,MAAA,EAAQ;QACV,MAAM4Z,GAAA,GAAM,mCACRzQ,OAAA,CAAOuQ,CAAA,CAAEC,OAAA,GAAU,IAAI,IAAI,IAC3B;QACJ,IAAIla,KAAA,EAAO;UACT,OAAOiZ,OAAA,CAAQC,OAAA,CAAQiB,GAAG;QAC5B;QACA,OAAOA,GAAA;MACT;MAEA,IAAIna,KAAA,EAAO;QACT,OAAOiZ,OAAA,CAAQmB,MAAA,CAAOH,CAAC;MACzB;MACA,MAAMA,CAAA;IACR;EACF;AACF;;;ACjVA,IAAMI,cAAA,GAAiB,IAAIrD,MAAA,CAAO;AAqB3B,SAASsD,OAAO5M,GAAA,EAAazM,GAAA,EAAsD;EACxF,OAAOoZ,cAAA,CAAezF,KAAA,CAAMlH,GAAA,EAAKzM,GAAG;AACtC;AAOAqZ,MAAA,CAAO9M,OAAA,GACP8M,MAAA,CAAOpD,UAAA,GAAa,UAAS5J,QAAA,EAAwB;EACnD+M,cAAA,CAAenD,UAAA,CAAW5J,QAAO;EACjCgN,MAAA,CAAO5C,QAAA,GAAW2C,cAAA,CAAe3C,QAAA;EACjC/W,cAAA,CAAe2Z,MAAA,CAAO5C,QAAQ;EAC9B,OAAO4C,MAAA;AACT;AAKAA,MAAA,CAAOC,WAAA,GAAcxa,YAAA;AAErBua,MAAA,CAAO5C,QAAA,GAAWhX,SAAA;AAMlB4Z,MAAA,CAAOlD,GAAA,GAAM,aAAYH,IAAA,EAAyB;EAChDoD,cAAA,CAAejD,GAAA,CAAI,GAAGH,IAAI;EAC1BqD,MAAA,CAAO5C,QAAA,GAAW2C,cAAA,CAAe3C,QAAA;EACjC/W,cAAA,CAAe2Z,MAAA,CAAO5C,QAAQ;EAC9B,OAAO4C,MAAA;AACT;AAMAA,MAAA,CAAO7Z,UAAA,GAAa,UAASkM,MAAA,EAA8B0K,QAAA,EAA2D;EACpH,OAAOgD,cAAA,CAAe5Z,UAAA,CAAWkM,MAAA,EAAQ0K,QAAQ;AACnD;AASAiD,MAAA,CAAOzF,WAAA,GAAcwF,cAAA,CAAexF,WAAA;AAKpCyF,MAAA,CAAOE,MAAA,GAASzE,OAAA;AAChBuE,MAAA,CAAO3F,MAAA,GAASoB,OAAA,CAAQnB,KAAA;AACxB0F,MAAA,CAAOG,QAAA,GAAWjG,SAAA;AAClB8F,MAAA,CAAOI,YAAA,GAAe5E,aAAA;AACtBwE,MAAA,CAAOK,KAAA,GAAQhI,MAAA;AACf2H,MAAA,CAAOvM,KAAA,GAAQ4E,MAAA,CAAOK,GAAA;AACtBsH,MAAA,CAAOM,SAAA,GAAYxN,UAAA;AACnBkN,MAAA,CAAOO,KAAA,GAAQtE,MAAA;AACf+D,MAAA,CAAO1F,KAAA,GAAQ0F,MAAA;AAER,IAAM9M,OAAA,GAAU8M,MAAA,CAAO9M,OAAA;AACvB,IAAM0J,UAAA,GAAaoD,MAAA,CAAOpD,UAAA;AAC1B,IAAME,GAAA,GAAMkD,MAAA,CAAOlD,GAAA;AACnB,IAAM3W,UAAA,GAAa6Z,MAAA,CAAO7Z,UAAA;AAC1B,IAAMoU,WAAA,GAAcyF,MAAA,CAAOzF,WAAA;AAC3B,IAAMD,KAAA,GAAQ0F,MAAA;AACd,IAAM3F,MAAA,GAASoB,OAAA,CAAQnB,KAAA;AACvB,IAAM7G,KAAA,GAAQ4E,MAAA,CAAOK,GAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}